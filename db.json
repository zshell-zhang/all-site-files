{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/indigo/source/css/style.less","path":"css/style.less","modified":0,"renderable":1},{"_id":"themes/indigo/source/img/alipay.jpg","path":"img/alipay.jpg","modified":0,"renderable":1},{"_id":"themes/indigo/source/img/avatar.jpg","path":"img/avatar.jpg","modified":0,"renderable":1},{"_id":"themes/indigo/source/img/brand.jpg","path":"img/brand.jpg","modified":0,"renderable":1},{"_id":"themes/indigo/source/img/img-err.png","path":"img/img-err.png","modified":0,"renderable":1},{"_id":"themes/indigo/source/img/cc.png","path":"img/cc.png","modified":0,"renderable":1},{"_id":"themes/indigo/source/img/img-loading.png","path":"img/img-loading.png","modified":0,"renderable":1},{"_id":"themes/indigo/source/img/wechat.jpg","path":"img/wechat.jpg","modified":0,"renderable":1},{"_id":"themes/indigo/source/js/main.js","path":"js/main.js","modified":0,"renderable":1},{"_id":"themes/indigo/source/js/main.min.js","path":"js/main.min.js","modified":0,"renderable":1},{"_id":"themes/indigo/source/js/search.js","path":"js/search.js","modified":0,"renderable":1},{"_id":"themes/indigo/source/js/search.min.js","path":"js/search.min.js","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Bold.eot","path":"css/fonts/roboto/Roboto-Bold.eot","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Bold.woff2","path":"css/fonts/roboto/Roboto-Bold.woff2","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Light.woff2","path":"css/fonts/roboto/Roboto-Light.woff2","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Light.woff","path":"css/fonts/roboto/Roboto-Light.woff","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Medium.eot","path":"css/fonts/roboto/Roboto-Medium.eot","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Medium.woff","path":"css/fonts/roboto/Roboto-Medium.woff","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Medium.woff2","path":"css/fonts/roboto/Roboto-Medium.woff2","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Regular.eot","path":"css/fonts/roboto/Roboto-Regular.eot","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Light.eot","path":"css/fonts/roboto/Roboto-Light.eot","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Regular.woff","path":"css/fonts/roboto/Roboto-Regular.woff","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Thin.eot","path":"css/fonts/roboto/Roboto-Thin.eot","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Thin.woff","path":"css/fonts/roboto/Roboto-Thin.woff","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.woff2","path":"css/fonts/fontawesome/fontawesome-webfont.woff2","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.woff","path":"css/fonts/fontawesome/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Bold.ttf","path":"css/fonts/roboto/Roboto-Bold.ttf","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Light.ttf","path":"css/fonts/roboto/Roboto-Light.ttf","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Regular.ttf","path":"css/fonts/roboto/Roboto-Regular.ttf","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Thin.ttf","path":"css/fonts/roboto/Roboto-Thin.ttf","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Medium.ttf","path":"css/fonts/roboto/Roboto-Medium.ttf","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Thin.woff2","path":"css/fonts/roboto/Roboto-Thin.woff2","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.eot","path":"css/fonts/fontawesome/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.ttf","path":"css/fonts/fontawesome/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/fontawesome/FontAwesome.otf","path":"css/fonts/fontawesome/FontAwesome.otf","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Bold.woff","path":"css/fonts/roboto/Roboto-Bold.woff","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Regular.woff2","path":"css/fonts/roboto/Roboto-Regular.woff2","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.svg","path":"css/fonts/fontawesome/fontawesome-webfont.svg","modified":0,"renderable":1}],"Cache":[{"_id":"themes/indigo/.editorconfig","hash":"9b0445427777519defe360ea38c61729d847b3d3","modified":1516452688398},{"_id":"themes/indigo/LICENSE","hash":"24944bf7920108f5a4790e6071c32e9102760c37","modified":1516452688398},{"_id":"themes/indigo/README.md","hash":"b188fb95a9c16eb188eeffa6caa0895a14676338","modified":1516452688398},{"_id":"themes/indigo/_config.yml","hash":"150a9c2a43d850e7ea758801ba9d79b93951e9cc","modified":1516605923648},{"_id":"themes/indigo/package.json","hash":"c795e3100ae3655bfa8b39adcca7333a7925b47f","modified":1516452688398},{"_id":"source/_posts/linux-conf--ulimit调参与优化.md","hash":"820bbb1e6797c0ecf0724df759c03b9929d5f6b3","modified":1517064787553},{"_id":"source/_posts/linux-other--du,df使用及其区别.md","hash":"6e99a30240afd38743919f41d5a7ef9caec3e138","modified":1517064787565},{"_id":"source/_posts/linux-other--cli控制字符.md","hash":"d7141a567e9c505e7f0ee4147ea7e3020fa9549d","modified":1515330801679},{"_id":"source/_posts/linux-other--lsof札记.md","hash":"7295032168dfdaac5e85b7ba9b3ed77f0be2ce9b","modified":1516454802069},{"_id":"source/_posts/linux-shell--bash条件判断全梳理.md","hash":"9a193b2a70534b97dd2b2cc5cda2ea45f6bbc521","modified":1516453827025},{"_id":"source/_posts/linux-shell--bash数组与映射.md","hash":"06daf749bafbff6851b24ceaca542243c22706ed","modified":1514992691226},{"_id":"source/_posts/linux-varlog--logrotate配置与运维.md","hash":"a39a616f00080cc05c633330ae95e44a0c6f9713","modified":1517064787577},{"_id":"source/_posts/python--python模块导入_相关基础知识梳理.md","hash":"45f4196c1b02a3453f159a3a8b1a08de439ce8b8","modified":1519523209117},{"_id":"source/_posts/linux-process--linux_signals总体认识.md","hash":"1d5be86de92f3b506f927af7a1ea3675f9c5baa6","modified":1516450214216},{"_id":"source/_posts/rsync--rsyncd配置与运行.md","hash":"26d45c6f6eeb94849062f11e5f957982674aa9cd","modified":1517064787577},{"_id":"source/_posts/saltstack--saltstack_cheat_sheet.md","hash":"226d29e54a2e73fef7045f59ba4544a2a8b7df28","modified":1517064787577},{"_id":"source/_posts/linux-text-sed命令整理.md","hash":"e08002174fcd8da5f0fbb7142a5f43e78a54eb43","modified":1515077927480},{"_id":"source/_posts/tools-maven--assembly_plugin.md","hash":"e2a4c39976fcadcf1b995b8f7d7c73c16cf9f85c","modified":1516454430547},{"_id":"source/_posts/tools-git--git忽略文件的特殊场景.md","hash":"edd55249d881d55b8eda5d3f8a140d5634ab6029","modified":1518432703855},{"_id":"source/_posts/证券-财富先锋--财富先锋2017年各股池成绩单.md","hash":"209d9a3d0632da8d03bb6071455553d449f956d8","modified":1517064787581},{"_id":"source/_posts/linux-shell--bash结束死循环的方法.md","hash":"0387df780421ea28436ae0f1284da10d37c57258","modified":1514907681515},{"_id":"source/_posts/web--一个dev的拙劣前端笔记_使用jQuery_ajax上传文件.md","hash":"c00cd13e4c2c72f89195abab6605236f11bc3d75","modified":1518018209215},{"_id":"source/_posts/python-module--python_module_MySQLdb使用总结.md","hash":"ee32a4e26fbd1cfa93b50c6f3b21214be77c4d2c","modified":1517583257624},{"_id":"themes/indigo/.git/HEAD","hash":"da237e0de55301608e7c572e119ab5c4e43c0e85","modified":1516452688394},{"_id":"themes/indigo/.git/COMMIT_EDITMSG","hash":"64848a80c3e8e2d23f0656fc75b5b5ad9411238a","modified":1516635964059},{"_id":"themes/indigo/.git/config","hash":"10fa4a5734b512eb6bd7f2b1124b74fa407ed59d","modified":1516587720297},{"_id":"themes/indigo/.git/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1516452681642},{"_id":"themes/indigo/.git/packed-refs","hash":"0eaf9e3da58a7d631e569353c932468e1e276bdf","modified":1516587720297},{"_id":"themes/indigo/.git/index","hash":"22df0ba8eab8e402550e35ef36b6b6c1593001f1","modified":1516635964051},{"_id":"themes/indigo/languages/nl-NL","hash":"9085c04491f93066f2369911cc2175b59ae596ad","modified":1516452688398},{"_id":"themes/indigo/languages/zh-CN.yml","hash":"7dc6ae434dde390b6768d244132e23cc78c33817","modified":1516452688398},{"_id":"themes/indigo/languages/ja.yml","hash":"74fd480874bf5e773ba7f9d2a94697cda979091f","modified":1516452688398},{"_id":"themes/indigo/languages/en.yml","hash":"1957d2bfc3a4cef299f4f169b431e9b1128ba162","modified":1516452688398},{"_id":"themes/indigo/languages/zh-TW.yml","hash":"6a9e820be66eb12ae746f2527e0dc1adf927c685","modified":1516452688398},{"_id":"themes/indigo/layout/categories.ejs","hash":"41783d2069d5080566a99e6312aa2113105f8b41","modified":1516452688398},{"_id":"themes/indigo/layout/archive.ejs","hash":"d039719e21f6a6fa2925b00aaa623a180a78c818","modified":1516452688398},{"_id":"themes/indigo/layout/category.ejs","hash":"7ea26a8a935886963eda82f41c7bd5270cf780d9","modified":1516452688398},{"_id":"themes/indigo/layout/index.ejs","hash":"39477807b98b2d2df78f3b82498a11e90be8222c","modified":1516452688398},{"_id":"themes/indigo/layout/layout.ejs","hash":"d52f43fa9572d70cae834e4887c8897b43744805","modified":1516452688398},{"_id":"themes/indigo/layout/post.ejs","hash":"afbf8532dc8d148ca4dff2ca127a3382907cf2f5","modified":1516452688398},{"_id":"themes/indigo/scripts/plugins.js","hash":"e439d717513616bedeed37ba9b05117470809b21","modified":1516452688398},{"_id":"themes/indigo/layout/tags.ejs","hash":"20466446c41409d14a3d42ccaec24a65a045efef","modified":1516452688398},{"_id":"themes/indigo/layout/tag.ejs","hash":"36786a3de7f6cad58209603f7d84ba23addea174","modified":1516452688398},{"_id":"themes/indigo/layout/page.ejs","hash":"4720ec62a1f0deae27da4aa17b2b4e3ae5e028c0","modified":1516546648294},{"_id":"themes/indigo/.git/hooks/applypatch-msg.sample","hash":"4de88eb95a5e93fd27e78b5fb3b5231a8d8917dd","modified":1516452681658},{"_id":"themes/indigo/.git/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1516452681670},{"_id":"themes/indigo/.git/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1516452681658},{"_id":"themes/indigo/.git/hooks/pre-commit.sample","hash":"36aed8976dcc08b5076844f0ec645b18bc37758f","modified":1516452681658},{"_id":"themes/indigo/.git/hooks/pre-push.sample","hash":"5c8518bfd1d1d3d2c1a7194994c0a16d8a313a41","modified":1516452681670},{"_id":"themes/indigo/.git/hooks/pre-rebase.sample","hash":"18be3eb275c1decd3614e139f5a311b75f1b0ab8","modified":1516452681650},{"_id":"themes/indigo/.git/hooks/prepare-commit-msg.sample","hash":"2b6275eda365cad50d167fe3a387c9bc9fedd54f","modified":1516452681650},{"_id":"themes/indigo/.git/hooks/update.sample","hash":"e729cd61b27c128951d139de8e7c63d1a3758dde","modified":1516452681670},{"_id":"themes/indigo/.git/logs/HEAD","hash":"89f0791d815fb1b5b1b8d4b6cef026245ed012c5","modified":1516635964083},{"_id":"themes/indigo/layout/_partial/archive.ejs","hash":"55cd81ef9183426d6d99fd91550fce0a9cc92aa0","modified":1516452688398},{"_id":"themes/indigo/layout/_partial/after-footer.ejs","hash":"9ac30b9439fab69973cf4722dbf2945a18fd3804","modified":1516452688398},{"_id":"themes/indigo/layout/_partial/footer.ejs","hash":"e1a71a30a1c7a664ddf3ba3e7eb3a5b90bc4b33c","modified":1516452688398},{"_id":"themes/indigo/layout/_partial/header.ejs","hash":"6156bf20791e46fc1c5872113276c1c1f5c13773","modified":1516452688398},{"_id":"themes/indigo/layout/_partial/head.ejs","hash":"b197b87b120b09b68aa3d79954ed039816a88664","modified":1516452688398},{"_id":"themes/indigo/layout/_partial/loading.ejs","hash":"bc4cb19b20de55a0332647f4dca9684184383685","modified":1516452688398},{"_id":"themes/indigo/layout/_partial/menu.ejs","hash":"d39afaad6b0dd2a3ae27e6db3e9a6cd6014622fa","modified":1516452688398},{"_id":"themes/indigo/layout/_partial/paginator.ejs","hash":"dc27242927890f130a64400596b9b7ad5fca8972","modified":1516452688398},{"_id":"themes/indigo/layout/_partial/post.ejs","hash":"a87d9b0485b3bf4cdfdad890e5974c43dbaa8240","modified":1516452688398},{"_id":"themes/indigo/.git/hooks/pre-applypatch.sample","hash":"f208287c1a92525de9f5462e905a9d31de1e2d75","modified":1516452681658},{"_id":"themes/indigo/layout/_partial/script.ejs","hash":"439d6315a1b16e32b77a68c3f0cb2961d581086a","modified":1516452688398},{"_id":"themes/indigo/layout/_partial/tags-bar.ejs","hash":"19eff4876d31080a427644f7a43fe172d0c008c6","modified":1516452688398},{"_id":"themes/indigo/source/css/style.less","hash":"f22d4146e0bdb4485d33f20080c67ba05724afea","modified":1516452688414},{"_id":"themes/indigo/.git/info/exclude","hash":"c879df015d97615050afa7b9641e3352a1e701ac","modified":1516452681634},{"_id":"themes/indigo/source/img/alipay.jpg","hash":"6054d9ed2ca7cd1f645b729e05632134467d4daa","modified":1516452688414},{"_id":"themes/indigo/source/img/avatar.jpg","hash":"62a4893b1a32e997dcdb6e467b10559df75221e2","modified":1516452688414},{"_id":"themes/indigo/layout/_partial/search.ejs","hash":"c2091c621b5480ef1e69d72027028cec8e929892","modified":1516452688398},{"_id":"themes/indigo/source/img/brand.jpg","hash":"0e237f1b433851c156e1f1cdaeb044054b3b9879","modified":1516452688414},{"_id":"themes/indigo/layout/_partial/index-item.ejs","hash":"2a2d5c70804260421a71ecaefd554420f456ac8a","modified":1516548317059},{"_id":"themes/indigo/source/img/img-err.png","hash":"23a63ea26eb3c1d5e677d9883cf36cc1a1a1228b","modified":1516452688414},{"_id":"themes/indigo/source/img/cc.png","hash":"ebce75a62b40976a72d43f0bd937d859ac24d87c","modified":1516452688414},{"_id":"themes/indigo/source/img/img-loading.png","hash":"a9cd5cd11866824f31e3d1c5e23badfeb3f73031","modified":1516452688414},{"_id":"themes/indigo/source/img/wechat.jpg","hash":"ef069cc9e80c7553fd60589b0727bbbf8c6de372","modified":1516452688414},{"_id":"themes/indigo/source/js/main.js","hash":"300b2e963683ced162e28afcd24ffc970fc23ac2","modified":1516452688414},{"_id":"themes/indigo/source/js/main.min.js","hash":"8acf4480f8ab859423b8926b9b790c67b5a77276","modified":1516452688414},{"_id":"source/tags/index.md","hash":"fa5259fdd512bf68a3efe41b3a2e1bd5563f7b9c","modified":1517064787593},{"_id":"source/categories/index.md","hash":"06e5f5699a70ddfe688f62b37428a4a61d331d5f","modified":1517064787585},{"_id":"themes/indigo/source/js/search.js","hash":"a1de7e7a2ef8330ebcd9f3a7a4622b3bac44e4f3","modified":1516452688414},{"_id":"themes/indigo/source/js/search.min.js","hash":"a8a450bb8b1ca9ad577052addcbd3393f1af6c6a","modified":1516452688414},{"_id":"source/about/index.md","hash":"ab85a503066c7825b0f9623ea4d307e363961d4c","modified":1517297999984},{"_id":"themes/indigo/.git/objects/16/b6879fc68b8ff55b6d8c7da448a77e395f02c4","hash":"1f6fa4151ef1e7ac78dc790cbba8ee534214ba31","modified":1516587696533},{"_id":"themes/indigo/.git/objects/15/d200815d483b1272674c4074ada23c2d00f799","hash":"cf97abce3d785ca2f07a99c4bb1e5cad4c3be112","modified":1516587696533},{"_id":"themes/indigo/.git/objects/58/5d1098207f8f9e18441b3f85137733afac8c06","hash":"2b236bad33ab6b1d680765e924051bb5cb288a90","modified":1516635964059},{"_id":"themes/indigo/.git/objects/74/1aae1e9ad48b0e2d7381d4a742385cd0e79f4a","hash":"36c3f4dd5eba40fe1c763e79404f5e158414dae3","modified":1516587696533},{"_id":"themes/indigo/.git/objects/6d/28ffc1473171bec692613512e1e4254b55d806","hash":"6e19ba35844b1014fccb7484c6219f4299f06435","modified":1516587696533},{"_id":"themes/indigo/.git/objects/7b/a51b67b16929681adb658e54067313d4d58f27","hash":"8abeff3479c73c42e7090cce3b850dd13192cdc5","modified":1516587696537},{"_id":"themes/indigo/.git/objects/96/4db42225c65c07b09500b5442cfad8fd5e8977","hash":"bda185a0ac9d2239977b8262f0558014b9182a31","modified":1516587696533},{"_id":"themes/indigo/.git/objects/af/668b89d831c625499b69a195cd9842b83dd00d","hash":"11d0456da3e13c63b22d21425e46f49fc60333ac","modified":1516587696533},{"_id":"themes/indigo/.git/objects/d9/2f8ed1da4b240fa5e80aeefac2413c2ca7e113","hash":"4b77baf9e0fcedffa5619e151b454aba137bce93","modified":1516587696533},{"_id":"themes/indigo/.git/objects/31/69b39c0b9772dce73ceb22e4c36a7e55b0155e","hash":"5e7d7bb9116569a90ef7b3a243de4608f20c3356","modified":1516635964051},{"_id":"themes/indigo/.git/objects/43/ba5cadc486138f64f729b49d3f0f507b9ac27f","hash":"d72df1670f544dfa43032947ce88b956d8c95ddf","modified":1516587696533},{"_id":"themes/indigo/.git/refs/heads/card","hash":"ceb6bf680f1cbfa00f000919ff95ddd9e759ee2d","modified":1516635964059},{"_id":"themes/indigo/.git/objects/1b/ca4ce0ce3a45563597f4dbe2e67a9d45117051","hash":"6c4fe7cd8fe457f6d33d58a181e28402ad1c144f","modified":1516587696533},{"_id":"themes/indigo/.git/objects/0c/118b0a6671ebeb9c193574038acb5af02591bf","hash":"c413807bccae1feaa41a11234f4590ead5fac200","modified":1516587696533},{"_id":"themes/indigo/layout/_partial/plugins/baidu.ejs","hash":"e44d526029f122e9c2c74f3a647c35002c818cbe","modified":1516452688398},{"_id":"themes/indigo/layout/_partial/plugins/disqus.ejs","hash":"4a0c01e4195f685f9825fcd016d01249dbdd52ca","modified":1516452688398},{"_id":"themes/indigo/layout/_partial/plugins/dynamic-title.ejs","hash":"23c101d45911eb0846533aaa2d409c43aa5e899a","modified":1516452688398},{"_id":"themes/indigo/layout/_partial/plugins/gitment.ejs","hash":"5723d507eca4390e8e5d18c0770e7953b8c22f5a","modified":1516452688398},{"_id":"themes/indigo/.git/objects/pack/pack-2b82070313f1532f0e9c29725cefa112a1170904.idx","hash":"50bce8f81b677122dc574384f6fd86ae033da2d2","modified":1516452688014},{"_id":"themes/indigo/.git/objects/91/291320cd476bda679dc9888be5d3177c717811","hash":"dc42f8766623391f6ae3a04c87049c350e37fb56","modified":1516635964015},{"_id":"themes/indigo/layout/_partial/plugins/google-analytics.ejs","hash":"a947f4076b54b48d4df5baf2d5b3c39b632c7576","modified":1516452688398},{"_id":"themes/indigo/layout/_partial/plugins/mathjax.ejs","hash":"ea603a057196de53bd6afab1fddb93d11f27eb81","modified":1516452688398},{"_id":"themes/indigo/layout/_partial/plugins/page-visit.ejs","hash":"2decb77bf3c1a064ea6ce1d4e78892c434d9c884","modified":1516452688398},{"_id":"themes/indigo/layout/_partial/plugins/site-visit.ejs","hash":"8fbd0910828f1ab6eba728bdecc9811d623baae2","modified":1516452688398},{"_id":"themes/indigo/layout/_partial/plugins/tajs.ejs","hash":"97b48fe10be1c71d4ff25ccec3bd92d97466c9c5","modified":1516452688398},{"_id":"themes/indigo/layout/_partial/plugins/valine.ejs","hash":"a976ca36bd09aeb2902bf94fcc7a59975ea25148","modified":1516452688398},{"_id":"themes/indigo/layout/_partial/plugins/uyan.ejs","hash":"e370bd04ea5cf1c83e0c20516aff7ba3ca8b2d0b","modified":1516452688398},{"_id":"themes/indigo/layout/_partial/post/category.ejs","hash":"c7476165721a3a5e34d00d8c5c07e1e5474cd800","modified":1516452688398},{"_id":"themes/indigo/layout/_partial/post/comment.ejs","hash":"f2c6a55a88ce694b44c46c8322293172afc00255","modified":1516452688398},{"_id":"themes/indigo/layout/_partial/post/copyright.ejs","hash":"5305ed30ee35cf50f87656737d0ffe85f5bfc16b","modified":1516452688398},{"_id":"themes/indigo/layout/_partial/post/date.ejs","hash":"ea85b46e12d3b9c3612eef7aa76289a663fbc096","modified":1516452688398},{"_id":"themes/indigo/layout/_partial/post/head-meta.ejs","hash":"b0c680ce5b8aaf461a6731b1ff1287bd140c168a","modified":1516452688398},{"_id":"themes/indigo/layout/_partial/post/nav.ejs","hash":"11e7d504f7c7a3c4c052da13cfa8ea4862c9383e","modified":1516452688398},{"_id":"themes/indigo/layout/_partial/post/reward-btn.ejs","hash":"41c242fe3159dc68cec8dd00ab6d2663f5a51179","modified":1516452688398},{"_id":"themes/indigo/layout/_partial/post/share-fab.ejs","hash":"93482ad7d1e01b966f5ee1c5d12b88564e02b349","modified":1516452688398},{"_id":"themes/indigo/layout/_partial/post/reward.ejs","hash":"23719e09689b3afbb19214c6603eb02f896cb9ba","modified":1516452688398},{"_id":"themes/indigo/layout/_partial/post/share.ejs","hash":"8df0d7bf6f8e106cdbdac2dd10a97367aa0695f8","modified":1516452688398},{"_id":"themes/indigo/layout/_partial/post/tag.ejs","hash":"b3dc38652c4a018a37418136478dcd522fc49f79","modified":1516452688398},{"_id":"themes/indigo/layout/_partial/post/title.ejs","hash":"062d56cb88ae2be3a6616b911d4ebeffcbfe3cff","modified":1516452688398},{"_id":"themes/indigo/layout/_partial/post/toc.ejs","hash":"ad287a70724eb7cd8cd2a03a45b68032ee99973d","modified":1516452688398},{"_id":"themes/indigo/layout/_partial/post/updated.ejs","hash":"5caa71745aa340ce57938a930f3b898ee7518d74","modified":1516452688398},{"_id":"themes/indigo/source/css/_partial/archives.less","hash":"7d2a6886265386c640e94ffca3f042675f701a35","modified":1516452688398},{"_id":"themes/indigo/source/css/_partial/article.less","hash":"d476cd3537bcd8a02d055cc223f5c805b8638cc2","modified":1516452688398},{"_id":"themes/indigo/source/css/_partial/gotop.less","hash":"b7db31b9bc563c10b9e3cf3e6d9cfddfeb3e805a","modified":1516452688398},{"_id":"themes/indigo/source/css/_partial/header.less","hash":"90f0948a9182c14b1dac1e9dbed3c883543266f9","modified":1516452688398},{"_id":"themes/indigo/source/css/_partial/highlight.less","hash":"58492b7cdb45fe09b026b2f34e8ae69c2ddb8228","modified":1516452688398},{"_id":"themes/indigo/source/css/_partial/layout.less","hash":"4390ed22abad59c8b28ed1a479a52f15b5f9cf4a","modified":1516452688398},{"_id":"themes/indigo/source/css/_partial/lightbox.less","hash":"9b961eb1d70e7658f42cf2ca895fa5e35a6b6541","modified":1516452688398},{"_id":"themes/indigo/source/css/_partial/loading.less","hash":"f9d06a1e24fb4857fd18d7a0bfbb3a0ab2d1c742","modified":1516452688398},{"_id":"themes/indigo/source/css/_partial/page.less","hash":"e92ccb53e6ac73a51498c6a9672db9d0d2bc7f1a","modified":1516452688398},{"_id":"themes/indigo/source/css/_partial/reward.less","hash":"4857f90bb57fc22ca3f942d8934d86d5e9e82c1e","modified":1516452688398},{"_id":"themes/indigo/source/css/_partial/roboto.less","hash":"2e0469ed8161d5672d903ca1a8027cd65fe007f1","modified":1516452688398},{"_id":"themes/indigo/source/css/_partial/search.less","hash":"1d6641ae7568a0153d24beba9fd9704d2b155f6c","modified":1516452688398},{"_id":"themes/indigo/source/css/_partial/tags.less","hash":"959f4373fda6e45f6a4041a995ed3ea8a05a5170","modified":1516452688398},{"_id":"themes/indigo/source/css/_partial/waves.less","hash":"77bfd0b373b0469eb0176167fb076ccda4edf2a7","modified":1516452688398},{"_id":"themes/indigo/source/css/_plugin/valine.less","hash":"ddbb7647d83f732f9b0d5d817d40a748006949cc","modified":1516452688398},{"_id":"themes/indigo/source/css/_partial/fontawesome.less","hash":"ca30b732d2efbb0cd55a272ecdabc97f895aee78","modified":1516452688398},{"_id":"themes/indigo/.git/logs/refs/heads/card","hash":"89f0791d815fb1b5b1b8d4b6cef026245ed012c5","modified":1516635964075},{"_id":"themes/indigo/source/css/_partial/postlist.less","hash":"1c041bf91106808e5480c60d9ece45431bb503b3","modified":1516452688398},{"_id":"themes/indigo/source/css/_partial/share.less","hash":"27d80bcc96a53dd1e7eaa9a7d746e4b212357302","modified":1516452688398},{"_id":"themes/indigo/source/css/_partial/variable.less","hash":"5400df4c7a1cbe127280827bc2638e98898f2a03","modified":1516464844372},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Bold.eot","hash":"a76cd602f5188b9fbd4ba7443dcb9c064e3dbf10","modified":1516452688406},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Bold.woff2","hash":"933b866d09c2b087707a98dab64b3888865eeb96","modified":1516452688406},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Light.woff2","hash":"bbdc28b887400fcb340b504ec2904993af42a5d7","modified":1516452688410},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Light.woff","hash":"6300f659be9e834ab263efe2fb3c581d48b1e7b2","modified":1516452688410},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Medium.eot","hash":"1517f4b6e1c5d0e5198f937557253aac8fab0416","modified":1516452688410},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Medium.woff","hash":"d45f84922131364989ad6578c7a06b6b4fc22c34","modified":1516452688410},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Medium.woff2","hash":"6cc1b73571af9e827c4e7e91418f476703cd4c4b","modified":1516452688410},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Regular.eot","hash":"77ae3e980ec03863ebe2587a8ef9ddfd06941db0","modified":1516452688410},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Light.eot","hash":"42fe156996197e5eb0c0264c5d1bb3b4681f4595","modified":1516452688410},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Regular.woff","hash":"74734dde8d94e7268170f9b994dedfbdcb5b3a15","modified":1516452688410},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Thin.eot","hash":"0790a51a848dbe7292c98f9d0459218bf1a8ffdd","modified":1516452688410},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Thin.woff","hash":"fbc3e71d456c96667d8082ab910e3946ef89240b","modified":1516452688414},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1516452688406},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1516452688406},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Bold.ttf","hash":"47327df0f35e7cd7c8645874897a7449697544ae","modified":1516452688406},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Light.ttf","hash":"e321c183e2b75ee19813892b7bac8d7c411cb88a","modified":1516452688410},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Regular.ttf","hash":"824b5480c977a8166e177e5357d13164ccc45f47","modified":1516452688410},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Thin.ttf","hash":"173ed64528b4d010a76d8d38deb1d7e7eed58eda","modified":1516452688414},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Medium.ttf","hash":"6060ca726b9760b76f7c347dce9d2fa1fe42ec92","modified":1516452688410},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Thin.woff2","hash":"2449e3dac5ddb7c3da8bb07450493b62d052758c","modified":1516452688414},{"_id":"themes/indigo/.git/logs/refs/remotes/origin/HEAD","hash":"b1fe6008f9e344bce371feed9c33b2b2bd7da195","modified":1516452688394},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1516452688402},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1516452688406},{"_id":"themes/indigo/source/css/fonts/fontawesome/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1516452688402},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Bold.woff","hash":"ee99cd87a59a9a5d4092c83232bb3eec67547425","modified":1516452688406},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Regular.woff2","hash":"ed1558b0541f5e01ce48c7db1588371b990eec19","modified":1516452688410},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1516452688406},{"_id":"themes/indigo/.git/objects/pack/pack-2b82070313f1532f0e9c29725cefa112a1170904.pack","hash":"02118906e88641860f0144ef671bb94e5d13718c","modified":1516452688014}],"Category":[{"name":"linux","_id":"cje24mxtn0002j1jxj90g2ae2"},{"name":"other","parent":"cje24mxtn0002j1jxj90g2ae2","_id":"cje24mxu4000hj1jxcteeydhf"},{"name":"conf","parent":"cje24mxtn0002j1jxj90g2ae2","_id":"cje24mxu8000mj1jx9414sur9"},{"name":"shell","parent":"cje24mxtn0002j1jxj90g2ae2","_id":"cje24mxud000rj1jxmfvnp7j6"},{"name":"varlog","parent":"cje24mxtn0002j1jxj90g2ae2","_id":"cje24mxun001cj1jxxrff4ihu"},{"name":"python","_id":"cje24mxup001ij1jx2lrg0b19"},{"name":"process","parent":"cje24mxtn0002j1jxj90g2ae2","_id":"cje24mxus001sj1jxnmrmlpf7"},{"name":"rsync","_id":"cje24mxut001xj1jxry2fcarf"},{"name":"saltstack","_id":"cje24mxuu0021j1jxd4xi5a4k"},{"name":"text","parent":"cje24mxtn0002j1jxj90g2ae2","_id":"cje24mxuu0027j1jxquydklsv"},{"name":"tools","_id":"cje24mxuv002cj1jxi1gveuvc"},{"name":"证券","_id":"cje24mxuy002lj1jxs5y2b1c7"},{"name":"web","_id":"cje24mxuz002oj1jxa4qphb3d"},{"name":"maven","parent":"cje24mxuv002cj1jxi1gveuvc","_id":"cje24mxv2002sj1jxrczv87mp"},{"name":"git","parent":"cje24mxuv002cj1jxi1gveuvc","_id":"cje24mxv3002wj1jxs18kw17h"},{"name":"财富先锋","parent":"cje24mxuy002lj1jxs5y2b1c7","_id":"cje24mxv40030j1jxmvnh6llc"},{"name":"module","parent":"cje24mxup001ij1jx2lrg0b19","_id":"cje24mxv50034j1jxx5cq7pxf"}],"Data":[],"Page":[{"title":"tags","date":"2016-07-05T13:58:26.000Z","layout":"tags","comment":false,"_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2016-07-05 21:58:26\nlayout: tags\ncomment: false\n---\n","updated":"2018-01-27T14:53:07.593Z","path":"tags/index.html","comments":1,"_id":"cje24mxwy003aj1jxzapefq45","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"categories","date":"2016-08-01T11:40:08.000Z","layout":"categories","comments":0,"_content":"\n","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2016-08-01 19:40:08\nlayout: categories\ncomments: false\n---\n\n","updated":"2018-01-27T14:53:07.585Z","path":"categories/index.html","_id":"cje24mxx0003bj1jxw3ojpu9o","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"about me","date":"2016-07-05T07:21:04.000Z","_content":"\n> 我坠入了一个全栈式陷阱: 在T型技术理论的指导下, 不断在那一条横上筑底, 然未能找到合适的支点累起那一道竖;\n时不我待, 毕竟技术不是股市, 横有多长, 竖未必有多高;\n\n## **联系方式**\n\n**微信** : &nbsp;XaaService\n\n**手机** : 18513585440\n\n**邮箱** : zshell.zhang@qunar.com  \n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;xaaservice@gmail.com\n\n## **职业状态**\n\n2016.06: 毕业;\n2016.07 - 2018.04: 去哪儿网 dev;\n\n","source":"about/index.md","raw":"---\ntitle: about me\ndate: 2016-07-05 15:21:04\n---\n\n> 我坠入了一个全栈式陷阱: 在T型技术理论的指导下, 不断在那一条横上筑底, 然未能找到合适的支点累起那一道竖;\n时不我待, 毕竟技术不是股市, 横有多长, 竖未必有多高;\n\n## **联系方式**\n\n**微信** : &nbsp;XaaService\n\n**手机** : 18513585440\n\n**邮箱** : zshell.zhang@qunar.com  \n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;xaaservice@gmail.com\n\n## **职业状态**\n\n2016.06: 毕业;\n2016.07 - 2018.04: 去哪儿网 dev;\n\n","updated":"2018-01-30T07:39:59.984Z","path":"about/index.html","comments":1,"layout":"page","_id":"cje24mxxb003cj1jx97cfgpwy","content":"<blockquote>\n<p>我坠入了一个全栈式陷阱: 在T型技术理论的指导下, 不断在那一条横上筑底, 然未能找到合适的支点累起那一道竖;<br>时不我待, 毕竟技术不是股市, 横有多长, 竖未必有多高;</p>\n</blockquote>\n<h2 id=\"联系方式\"><a href=\"#联系方式\" class=\"headerlink\" title=\"联系方式\"></a><strong>联系方式</strong></h2><p><strong>微信</strong> : &nbsp;XaaService</p>\n<p><strong>手机</strong> : 18513585440</p>\n<p><strong>邮箱</strong> : zshell.zhang@qunar.com<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;xaaservice@gmail.com</p>\n<h2 id=\"职业状态\"><a href=\"#职业状态\" class=\"headerlink\" title=\"职业状态\"></a><strong>职业状态</strong></h2><p>2016.06: 毕业;<br>2016.07 - 2018.04: 去哪儿网 dev;</p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>我坠入了一个全栈式陷阱: 在T型技术理论的指导下, 不断在那一条横上筑底, 然未能找到合适的支点累起那一道竖;<br>时不我待, 毕竟技术不是股市, 横有多长, 竖未必有多高;</p>\n</blockquote>\n<h2 id=\"联系方式\"><a href=\"#联系方式\" class=\"headerlink\" title=\"联系方式\"></a><strong>联系方式</strong></h2><p><strong>微信</strong> : &nbsp;XaaService</p>\n<p><strong>手机</strong> : 18513585440</p>\n<p><strong>邮箱</strong> : zshell.zhang@qunar.com<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;xaaservice@gmail.com</p>\n<h2 id=\"职业状态\"><a href=\"#职业状态\" class=\"headerlink\" title=\"职业状态\"></a><strong>职业状态</strong></h2><p>2016.06: 毕业;<br>2016.07 - 2018.04: 去哪儿网 dev;</p>\n"}],"Post":[{"title":"ulimit 调参与优化","date":"2017-10-28T15:23:05.000Z","_content":"\n> ulimit 未正确设置是很多线上故障的根源: \n`Too many open files`;\n`java.lang.OutOfMemoryError: unable to create new native thread`;\n对于生产环境来说, ulimit 的调参优化至关重要;\n本文详细介绍并梳理一下与 ulimit 相关的林林总总;\n\n<!--more-->\n\n------\n\nulimit 是 linux 对于每个通过 PAM 登录的用户 ( 每个进程 ) 的资源最大使用限制的设置;\n注意, 这里仅仅对通过 PAM 登陆的用户起作用, 而对于那些随系统启动而启动的 daemon service, ulimit 是不会去限制其资源使用的;\n在 `/etc/security/limits.conf` 文件中的第一段注释如下:\n> This file sets the resource limits for the users logged in via PAM.\nIt does not affect resource limits of the system services.\n\n关于 linux PAM 相关的内容, 可以前往另外一篇文章: [pam 认证与配置]();\n\n## **ulimit 基本信息**\n``` bash\n# 查看所有 ulimit 设置\n> ulimit -a\ncore file size          (blocks, -c) 0\ndata seg size           (kbytes, -d) unlimited\nscheduling priority             (-e) 0\nfile size               (blocks, -f) unlimited\npending signals                 (-i) 15018\nmax locked memory       (kbytes, -l) 64             # 每个进程可以锁住而不被 swap 出去的内存\nmax memory size         (kbytes, -m) unlimited      # 每个进程可使用的最大内存大小\nopen files                      (-n) 1024           # 每个进程可打开的文件数\npipe size            (512 bytes, -p) 8\nPOSIX message queues     (bytes, -q) 819200\nreal-time priority              (-r) 0\nstack size              (kbytes, -s) 8192           # 每个进程可使用的最大堆栈大小\ncpu time               (seconds, -t) unlimited\nmax user processes              (-u) 4096           # 每个用户的最大进程数\nvirtual memory          (kbytes, -v) unlimited\nfile locks                      (-x) unlimited\n```\n\n## **ulimit 需要优化的场景及待优化参数**\nlinux 默认的 ulimit 限制, 是出于安全考虑, 设置的有些保守; 实际的生产环境下, 往往需要对其作出适当的调整, 方可发挥机器的最大性能;\n### **场景1: tomcat web 容器 **\n一台 4C4G60G 的标准虚拟主机, 其上部署了一个 tomcat 实例, 启动 catalina 进程的是 tomcat:tomcat 用户;\n如果该服务是一个网络 IO 密集的应用, 需要打开的 socket file 远不止 1024, ulimit 设置的 max open files 就会限制其性能; 另外, 该主机只部署了这一个服务, tomcat 用户是唯一一个需要占用大量资源的用户, ulimit 对单个用户的限制便会造成机器资源闲置, 极低的使用率, 降低 web 服务的性能;\n所以, 可以对该机器的 ulimit 作出如下调整:\n``` bash\n1. max memory size -> unlimit\n2. open files -> 65536\n3. stack size -> unlimit\n```\n另外, 我们还遇到一种特殊的情况, 用标准配置虚拟机跑 dubbo 的服务治理: 当时发现, 如果服务注册到 zookeeper 的数量达到一定级别, 线上就会报 `java.lang.OutOfMemoryError: unable to create new native thread` 的异常;\n最后确定问题的原因是 `ulimit -u` max user processes 的数量配置过低, 增大后解决问题:\n``` bash\n4. max user processes -> 65535\n```\n具体的情况可以参见这篇文章: [dubbo 服务治理系统设计]();\n\n### **场景2: elasticsearch data node**\n32C64G4T 的配置, 为确保指针压缩特性被打开, 一般我们都会控制 jvm 的最大堆内存与最小堆内存: '-Xmx30g -Xms30g', 并希望能锁住所有的内存, 避免堆内存被 swap 到磁盘, 降低了搜索性能; 这种场景下我们当然不希望 ulimit 限制了 max memory size 以及 max locked memory;\n所以, 可以对该机器的 ulimit 作出如下调整:\n```\n1. max locked memory -> unlimit\n2. max memory size -> unlimit\n3. open files -> 65536\n4. stack size -> unlimit\n```\n对于 max locked memory, elasticsearch.yml 本身有一个配置项 `bootstrap.mlockall`/`bootstrap.memory_lock` = true, 其背后实现就是通过类似于 ulimit -l unlimit 的方法完成的; 只是, elasticsearch 试图自己主动改变该配置能生效的前提, 是 ulimit 配置文件里要允许其这样设置, 具体的逻辑请看本文下下节: [ulimit 的永久修改](#ulimit-的永久修改);\n\n&nbsp;\n另外, 还有其他的一些场景, 可能需要调整其他参数以作优化, 此处不一而论;\n以上是需要调整 ulimit 参数的场景举例, 下面的内容是关于如何 临时/永久 修改 ulimit 设置;\n\n## **ulimit 当前 session 下的临时修改**\nulimit 的临时调整, 只对当前 session 下的当前用户, 以及当前用户所起的进程生效;\n其调整方法也已经在 `ulimit -a` 中被注明了:\n``` bash\n# max locked mem\nulimit -l unlimit\n# max mem size\nulimit -m unlimit\n# open files\nulimit -n 65536\n# max user processes\nulimit -u 65536\n...\n```\n\n## **ulimit 的永久修改**\n上一节的方法, 只能在当前 session 下对当前用户作临时调整, 而 要想对 ulimit 作永久调整, 需要修改一些配置文件:\n\n1. `/etc/security/limits.conf`;\n2. `/etc/security/limits.d 目录`;\n\n这些文件用于持久化每个用户的资源限制设置;\n其中, `/etc/security/limits.conf` 自不必说, 这是配置 ulimit 的主要文件:\n``` bash\ndomain  限制的目标:\n        username    用户名;\n        @groupname  组名, 需加 '@' 前缀;\n        *           通配所有用户/组;\n        %groupname  这种写法只能用于限制 某个 group 的 maxlogin limit, 即最大登陆用户数限制;\n        \ntype    限制的属性:\n        `soft` 对 domain 给出的用户设置默认值; \n        `hard` 限制 domain 给出的用户自己所能设置的最大值; \n        `-` 将 soft 与 hard 都设为相同的值;\n        \nitem    限制的资源类型, 与 ulimit 所限制的资源类型大致相同:\n        - core - limits the core file size (KB)\n        - data - max data size (KB)\n        - fsize - maximum filesize (KB)\n        - memlock - max locked-in-memory address space (KB)\n        - nofile - max number of open file descriptors\n        - rss - max resident set size (KB)\n        - stack - max stack size (KB)\n        - cpu - max CPU time (MIN)\n        - nproc - max number of processes\n        - as - address space limit (KB)\n        - maxlogins - max number of logins for this user\n        - maxsyslogins - max number of logins on the system\n        - priority - the priority to run user process with\n        - locks - max number of file locks the user can hold\n        - sigpending - max number of pending signals\n        - msgqueue - max memory used by POSIX message queues (bytes)\n        - nice - max nice priority allowed to raise to values: [-20, 19]\n        - rtprio - max realtime priority\n\nvalue   限制的具体值;\n```\n以下是一个具体的例子:\n``` bash\n#<domain>        <type>     <item>     <value>\n*                 soft      nproc       65536\n*                 hard      nproc       65536\n*                 -         nofile      65536\n%guest            -         maxlogins   10\nelastic           -         memlock     unlimit\n@dev              hard      fsize       10737418240\n```\n如上所示, 系统允许 elastic 用户的最大 memlock 为 unlimit, 如果这个值被设置为了一个比较小的值, 那么上上节 elasticsearch 试图将其改成 unlimit 便会失败;\n\n&nbsp;\n而对于 `/etc/security/limits.d` 目录的作用,  `/etc/security/limits.conf` 文件中的第二段与第三段有如下注释:\n\n> Also note that configuration files in /etc/security/limits.d directory,\nwhich are read in alphabetical order, override the settings in this\nfile in case the domain is the same or more specific.\n&nbsp;\nThat means for example that setting a limit for wildcard domain here\ncan be overriden with a wildcard setting in a config file in the\nsubdirectory, but a user specific setting here can be overriden only\nwith a user specific setting in the subdirectory.\n\n也就是说, limits.conf 配置文件, 可以在用户级别上被 limits.d 目录下的配置文件覆盖;\n举一个例子, 在 redhat/centos 各发行版本中, limits.d 目录下就有一个文件 `20-nproc.conf`:\n``` bash\n# Default limit for number of user's processes to prevent\n# accidental fork bombs.\n# See rhbz #432903 for reasoning.\n*          soft    nproc     4096\nroot       soft    nproc     unlimited\n```\n这里面对除了 root 用户之外的所有用户作了一个最大进程/线程数目的 soft 限制;\n如果修改 limits.conf 文件:\n``` bash\n*          hard    nproc     65535\n```\n这时会发现, 除非自己试图 `ulimit -u` 修改 max processes, 否则这个值会依然被限制为 4096;\n而要想将该值默认放到 65535, 就必须修改 `20-nproc.conf` 文件方才生效;\n\n### **永久修改生效的必要条件**\n\n## **站内相关文章**\n- [pam 认证与配置]()\n- [dubbo 服务治理系统设计]()\n\n## **参考链接**\n- [ulimit 命令详解](http://www.cnblogs.com/zengkefu/p/5649407.html)\n- [linux /etc/security/limits.conf的相关说明](http://blog.csdn.net/taijianyu/article/details/5976319)\n\n","source":"_posts/linux-conf--ulimit调参与优化.md","raw":"---\ntitle: ulimit 调参与优化\ndate: 2017-10-28 23:23:05\ncategories:\n - linux\n - conf\ntags:\n - linux:conf\n---\n\n> ulimit 未正确设置是很多线上故障的根源: \n`Too many open files`;\n`java.lang.OutOfMemoryError: unable to create new native thread`;\n对于生产环境来说, ulimit 的调参优化至关重要;\n本文详细介绍并梳理一下与 ulimit 相关的林林总总;\n\n<!--more-->\n\n------\n\nulimit 是 linux 对于每个通过 PAM 登录的用户 ( 每个进程 ) 的资源最大使用限制的设置;\n注意, 这里仅仅对通过 PAM 登陆的用户起作用, 而对于那些随系统启动而启动的 daemon service, ulimit 是不会去限制其资源使用的;\n在 `/etc/security/limits.conf` 文件中的第一段注释如下:\n> This file sets the resource limits for the users logged in via PAM.\nIt does not affect resource limits of the system services.\n\n关于 linux PAM 相关的内容, 可以前往另外一篇文章: [pam 认证与配置]();\n\n## **ulimit 基本信息**\n``` bash\n# 查看所有 ulimit 设置\n> ulimit -a\ncore file size          (blocks, -c) 0\ndata seg size           (kbytes, -d) unlimited\nscheduling priority             (-e) 0\nfile size               (blocks, -f) unlimited\npending signals                 (-i) 15018\nmax locked memory       (kbytes, -l) 64             # 每个进程可以锁住而不被 swap 出去的内存\nmax memory size         (kbytes, -m) unlimited      # 每个进程可使用的最大内存大小\nopen files                      (-n) 1024           # 每个进程可打开的文件数\npipe size            (512 bytes, -p) 8\nPOSIX message queues     (bytes, -q) 819200\nreal-time priority              (-r) 0\nstack size              (kbytes, -s) 8192           # 每个进程可使用的最大堆栈大小\ncpu time               (seconds, -t) unlimited\nmax user processes              (-u) 4096           # 每个用户的最大进程数\nvirtual memory          (kbytes, -v) unlimited\nfile locks                      (-x) unlimited\n```\n\n## **ulimit 需要优化的场景及待优化参数**\nlinux 默认的 ulimit 限制, 是出于安全考虑, 设置的有些保守; 实际的生产环境下, 往往需要对其作出适当的调整, 方可发挥机器的最大性能;\n### **场景1: tomcat web 容器 **\n一台 4C4G60G 的标准虚拟主机, 其上部署了一个 tomcat 实例, 启动 catalina 进程的是 tomcat:tomcat 用户;\n如果该服务是一个网络 IO 密集的应用, 需要打开的 socket file 远不止 1024, ulimit 设置的 max open files 就会限制其性能; 另外, 该主机只部署了这一个服务, tomcat 用户是唯一一个需要占用大量资源的用户, ulimit 对单个用户的限制便会造成机器资源闲置, 极低的使用率, 降低 web 服务的性能;\n所以, 可以对该机器的 ulimit 作出如下调整:\n``` bash\n1. max memory size -> unlimit\n2. open files -> 65536\n3. stack size -> unlimit\n```\n另外, 我们还遇到一种特殊的情况, 用标准配置虚拟机跑 dubbo 的服务治理: 当时发现, 如果服务注册到 zookeeper 的数量达到一定级别, 线上就会报 `java.lang.OutOfMemoryError: unable to create new native thread` 的异常;\n最后确定问题的原因是 `ulimit -u` max user processes 的数量配置过低, 增大后解决问题:\n``` bash\n4. max user processes -> 65535\n```\n具体的情况可以参见这篇文章: [dubbo 服务治理系统设计]();\n\n### **场景2: elasticsearch data node**\n32C64G4T 的配置, 为确保指针压缩特性被打开, 一般我们都会控制 jvm 的最大堆内存与最小堆内存: '-Xmx30g -Xms30g', 并希望能锁住所有的内存, 避免堆内存被 swap 到磁盘, 降低了搜索性能; 这种场景下我们当然不希望 ulimit 限制了 max memory size 以及 max locked memory;\n所以, 可以对该机器的 ulimit 作出如下调整:\n```\n1. max locked memory -> unlimit\n2. max memory size -> unlimit\n3. open files -> 65536\n4. stack size -> unlimit\n```\n对于 max locked memory, elasticsearch.yml 本身有一个配置项 `bootstrap.mlockall`/`bootstrap.memory_lock` = true, 其背后实现就是通过类似于 ulimit -l unlimit 的方法完成的; 只是, elasticsearch 试图自己主动改变该配置能生效的前提, 是 ulimit 配置文件里要允许其这样设置, 具体的逻辑请看本文下下节: [ulimit 的永久修改](#ulimit-的永久修改);\n\n&nbsp;\n另外, 还有其他的一些场景, 可能需要调整其他参数以作优化, 此处不一而论;\n以上是需要调整 ulimit 参数的场景举例, 下面的内容是关于如何 临时/永久 修改 ulimit 设置;\n\n## **ulimit 当前 session 下的临时修改**\nulimit 的临时调整, 只对当前 session 下的当前用户, 以及当前用户所起的进程生效;\n其调整方法也已经在 `ulimit -a` 中被注明了:\n``` bash\n# max locked mem\nulimit -l unlimit\n# max mem size\nulimit -m unlimit\n# open files\nulimit -n 65536\n# max user processes\nulimit -u 65536\n...\n```\n\n## **ulimit 的永久修改**\n上一节的方法, 只能在当前 session 下对当前用户作临时调整, 而 要想对 ulimit 作永久调整, 需要修改一些配置文件:\n\n1. `/etc/security/limits.conf`;\n2. `/etc/security/limits.d 目录`;\n\n这些文件用于持久化每个用户的资源限制设置;\n其中, `/etc/security/limits.conf` 自不必说, 这是配置 ulimit 的主要文件:\n``` bash\ndomain  限制的目标:\n        username    用户名;\n        @groupname  组名, 需加 '@' 前缀;\n        *           通配所有用户/组;\n        %groupname  这种写法只能用于限制 某个 group 的 maxlogin limit, 即最大登陆用户数限制;\n        \ntype    限制的属性:\n        `soft` 对 domain 给出的用户设置默认值; \n        `hard` 限制 domain 给出的用户自己所能设置的最大值; \n        `-` 将 soft 与 hard 都设为相同的值;\n        \nitem    限制的资源类型, 与 ulimit 所限制的资源类型大致相同:\n        - core - limits the core file size (KB)\n        - data - max data size (KB)\n        - fsize - maximum filesize (KB)\n        - memlock - max locked-in-memory address space (KB)\n        - nofile - max number of open file descriptors\n        - rss - max resident set size (KB)\n        - stack - max stack size (KB)\n        - cpu - max CPU time (MIN)\n        - nproc - max number of processes\n        - as - address space limit (KB)\n        - maxlogins - max number of logins for this user\n        - maxsyslogins - max number of logins on the system\n        - priority - the priority to run user process with\n        - locks - max number of file locks the user can hold\n        - sigpending - max number of pending signals\n        - msgqueue - max memory used by POSIX message queues (bytes)\n        - nice - max nice priority allowed to raise to values: [-20, 19]\n        - rtprio - max realtime priority\n\nvalue   限制的具体值;\n```\n以下是一个具体的例子:\n``` bash\n#<domain>        <type>     <item>     <value>\n*                 soft      nproc       65536\n*                 hard      nproc       65536\n*                 -         nofile      65536\n%guest            -         maxlogins   10\nelastic           -         memlock     unlimit\n@dev              hard      fsize       10737418240\n```\n如上所示, 系统允许 elastic 用户的最大 memlock 为 unlimit, 如果这个值被设置为了一个比较小的值, 那么上上节 elasticsearch 试图将其改成 unlimit 便会失败;\n\n&nbsp;\n而对于 `/etc/security/limits.d` 目录的作用,  `/etc/security/limits.conf` 文件中的第二段与第三段有如下注释:\n\n> Also note that configuration files in /etc/security/limits.d directory,\nwhich are read in alphabetical order, override the settings in this\nfile in case the domain is the same or more specific.\n&nbsp;\nThat means for example that setting a limit for wildcard domain here\ncan be overriden with a wildcard setting in a config file in the\nsubdirectory, but a user specific setting here can be overriden only\nwith a user specific setting in the subdirectory.\n\n也就是说, limits.conf 配置文件, 可以在用户级别上被 limits.d 目录下的配置文件覆盖;\n举一个例子, 在 redhat/centos 各发行版本中, limits.d 目录下就有一个文件 `20-nproc.conf`:\n``` bash\n# Default limit for number of user's processes to prevent\n# accidental fork bombs.\n# See rhbz #432903 for reasoning.\n*          soft    nproc     4096\nroot       soft    nproc     unlimited\n```\n这里面对除了 root 用户之外的所有用户作了一个最大进程/线程数目的 soft 限制;\n如果修改 limits.conf 文件:\n``` bash\n*          hard    nproc     65535\n```\n这时会发现, 除非自己试图 `ulimit -u` 修改 max processes, 否则这个值会依然被限制为 4096;\n而要想将该值默认放到 65535, 就必须修改 `20-nproc.conf` 文件方才生效;\n\n### **永久修改生效的必要条件**\n\n## **站内相关文章**\n- [pam 认证与配置]()\n- [dubbo 服务治理系统设计]()\n\n## **参考链接**\n- [ulimit 命令详解](http://www.cnblogs.com/zengkefu/p/5649407.html)\n- [linux /etc/security/limits.conf的相关说明](http://blog.csdn.net/taijianyu/article/details/5976319)\n\n","slug":"linux-conf--ulimit调参与优化","published":1,"updated":"2018-01-27T14:53:07.553Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cje24mxte0000j1jx8urpkd78","content":"<blockquote>\n<p>ulimit 未正确设置是很多线上故障的根源:<br><code>Too many open files</code>;<br><code>java.lang.OutOfMemoryError: unable to create new native thread</code>;<br>对于生产环境来说, ulimit 的调参优化至关重要;<br>本文详细介绍并梳理一下与 ulimit 相关的林林总总;</p>\n</blockquote>\n<a id=\"more\"></a>\n<hr>\n<p>ulimit 是 linux 对于每个通过 PAM 登录的用户 ( 每个进程 ) 的资源最大使用限制的设置;<br>注意, 这里仅仅对通过 PAM 登陆的用户起作用, 而对于那些随系统启动而启动的 daemon service, ulimit 是不会去限制其资源使用的;<br>在 <code>/etc/security/limits.conf</code> 文件中的第一段注释如下:</p>\n<blockquote>\n<p>This file sets the resource limits for the users logged in via PAM.<br>It does not affect resource limits of the system services.</p>\n</blockquote>\n<p>关于 linux PAM 相关的内容, 可以前往另外一篇文章: <a href=\"\">pam 认证与配置</a>;</p>\n<h2 id=\"ulimit-基本信息\"><a href=\"#ulimit-基本信息\" class=\"headerlink\" title=\"ulimit 基本信息\"></a><strong>ulimit 基本信息</strong></h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 查看所有 ulimit 设置</span></span><br><span class=\"line\">&gt; <span class=\"built_in\">ulimit</span> -a</span><br><span class=\"line\">core file size          (blocks, -c) 0</span><br><span class=\"line\">data seg size           (kbytes, -d) unlimited</span><br><span class=\"line\">scheduling priority             (-e) 0</span><br><span class=\"line\">file size               (blocks, -f) unlimited</span><br><span class=\"line\">pending signals                 (-i) 15018</span><br><span class=\"line\">max locked memory       (kbytes, -l) 64             <span class=\"comment\"># 每个进程可以锁住而不被 swap 出去的内存</span></span><br><span class=\"line\">max memory size         (kbytes, -m) unlimited      <span class=\"comment\"># 每个进程可使用的最大内存大小</span></span><br><span class=\"line\">open files                      (-n) 1024           <span class=\"comment\"># 每个进程可打开的文件数</span></span><br><span class=\"line\">pipe size            (512 bytes, -p) 8</span><br><span class=\"line\">POSIX message queues     (bytes, -q) 819200</span><br><span class=\"line\">real-time priority              (-r) 0</span><br><span class=\"line\">stack size              (kbytes, -s) 8192           <span class=\"comment\"># 每个进程可使用的最大堆栈大小</span></span><br><span class=\"line\">cpu time               (seconds, -t) unlimited</span><br><span class=\"line\">max user processes              (-u) 4096           <span class=\"comment\"># 每个用户的最大进程数</span></span><br><span class=\"line\">virtual memory          (kbytes, -v) unlimited</span><br><span class=\"line\">file locks                      (-x) unlimited</span><br></pre></td></tr></table></figure>\n<h2 id=\"ulimit-需要优化的场景及待优化参数\"><a href=\"#ulimit-需要优化的场景及待优化参数\" class=\"headerlink\" title=\"ulimit 需要优化的场景及待优化参数\"></a><strong>ulimit 需要优化的场景及待优化参数</strong></h2><p>linux 默认的 ulimit 限制, 是出于安全考虑, 设置的有些保守; 实际的生产环境下, 往往需要对其作出适当的调整, 方可发挥机器的最大性能;</p>\n<h3 id=\"场景1-tomcat-web-容器\"><a href=\"#场景1-tomcat-web-容器\" class=\"headerlink\" title=\"场景1: tomcat web 容器 \"></a><strong>场景1: tomcat web 容器 </strong></h3><p>一台 4C4G60G 的标准虚拟主机, 其上部署了一个 tomcat 实例, 启动 catalina 进程的是 tomcat:tomcat 用户;<br>如果该服务是一个网络 IO 密集的应用, 需要打开的 socket file 远不止 1024, ulimit 设置的 max open files 就会限制其性能; 另外, 该主机只部署了这一个服务, tomcat 用户是唯一一个需要占用大量资源的用户, ulimit 对单个用户的限制便会造成机器资源闲置, 极低的使用率, 降低 web 服务的性能;<br>所以, 可以对该机器的 ulimit 作出如下调整:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1. max memory size -&gt; <span class=\"built_in\">unlimit</span></span><br><span class=\"line\">2. open files -&gt; 65536</span><br><span class=\"line\">3. stack size -&gt; <span class=\"built_in\">unlimit</span></span><br></pre></td></tr></table></figure></p>\n<p>另外, 我们还遇到一种特殊的情况, 用标准配置虚拟机跑 dubbo 的服务治理: 当时发现, 如果服务注册到 zookeeper 的数量达到一定级别, 线上就会报 <code>java.lang.OutOfMemoryError: unable to create new native thread</code> 的异常;<br>最后确定问题的原因是 <code>ulimit -u</code> max user processes 的数量配置过低, 增大后解决问题:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">4. max user processes -&gt; 65535</span><br></pre></td></tr></table></figure></p>\n<p>具体的情况可以参见这篇文章: <a href=\"\">dubbo 服务治理系统设计</a>;</p>\n<h3 id=\"场景2-elasticsearch-data-node\"><a href=\"#场景2-elasticsearch-data-node\" class=\"headerlink\" title=\"场景2: elasticsearch data node\"></a><strong>场景2: elasticsearch data node</strong></h3><p>32C64G4T 的配置, 为确保指针压缩特性被打开, 一般我们都会控制 jvm 的最大堆内存与最小堆内存: ‘-Xmx30g -Xms30g’, 并希望能锁住所有的内存, 避免堆内存被 swap 到磁盘, 降低了搜索性能; 这种场景下我们当然不希望 ulimit 限制了 max memory size 以及 max locked memory;<br>所以, 可以对该机器的 ulimit 作出如下调整:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1. max locked memory -&gt; unlimit</span><br><span class=\"line\">2. max memory size -&gt; unlimit</span><br><span class=\"line\">3. open files -&gt; 65536</span><br><span class=\"line\">4. stack size -&gt; unlimit</span><br></pre></td></tr></table></figure></p>\n<p>对于 max locked memory, elasticsearch.yml 本身有一个配置项 <code>bootstrap.mlockall</code>/<code>bootstrap.memory_lock</code> = true, 其背后实现就是通过类似于 ulimit -l unlimit 的方法完成的; 只是, elasticsearch 试图自己主动改变该配置能生效的前提, 是 ulimit 配置文件里要允许其这样设置, 具体的逻辑请看本文下下节: <a href=\"#ulimit-的永久修改\">ulimit 的永久修改</a>;</p>\n<p>&nbsp;<br>另外, 还有其他的一些场景, 可能需要调整其他参数以作优化, 此处不一而论;<br>以上是需要调整 ulimit 参数的场景举例, 下面的内容是关于如何 临时/永久 修改 ulimit 设置;</p>\n<h2 id=\"ulimit-当前-session-下的临时修改\"><a href=\"#ulimit-当前-session-下的临时修改\" class=\"headerlink\" title=\"ulimit 当前 session 下的临时修改\"></a><strong>ulimit 当前 session 下的临时修改</strong></h2><p>ulimit 的临时调整, 只对当前 session 下的当前用户, 以及当前用户所起的进程生效;<br>其调整方法也已经在 <code>ulimit -a</code> 中被注明了:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># max locked mem</span></span><br><span class=\"line\"><span class=\"built_in\">ulimit</span> -l <span class=\"built_in\">unlimit</span></span><br><span class=\"line\"><span class=\"comment\"># max mem size</span></span><br><span class=\"line\"><span class=\"built_in\">ulimit</span> -m <span class=\"built_in\">unlimit</span></span><br><span class=\"line\"><span class=\"comment\"># open files</span></span><br><span class=\"line\"><span class=\"built_in\">ulimit</span> -n 65536</span><br><span class=\"line\"><span class=\"comment\"># max user processes</span></span><br><span class=\"line\"><span class=\"built_in\">ulimit</span> -u 65536</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"ulimit-的永久修改\"><a href=\"#ulimit-的永久修改\" class=\"headerlink\" title=\"ulimit 的永久修改\"></a><strong>ulimit 的永久修改</strong></h2><p>上一节的方法, 只能在当前 session 下对当前用户作临时调整, 而 要想对 ulimit 作永久调整, 需要修改一些配置文件:</p>\n<ol>\n<li><code>/etc/security/limits.conf</code>;</li>\n<li><code>/etc/security/limits.d 目录</code>;</li>\n</ol>\n<p>这些文件用于持久化每个用户的资源限制设置;<br>其中, <code>/etc/security/limits.conf</code> 自不必说, 这是配置 ulimit 的主要文件:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">domain  限制的目标:</span><br><span class=\"line\">        username    用户名;</span><br><span class=\"line\">        @groupname  组名, 需加 <span class=\"string\">'@'</span> 前缀;</span><br><span class=\"line\">        *           通配所有用户/组;</span><br><span class=\"line\">        %groupname  这种写法只能用于限制 某个 group 的 maxlogin <span class=\"built_in\">limit</span>, 即最大登陆用户数限制;</span><br><span class=\"line\">        </span><br><span class=\"line\"><span class=\"built_in\">type</span>    限制的属性:</span><br><span class=\"line\">        `soft` 对 domain 给出的用户设置默认值; </span><br><span class=\"line\">        `hard` 限制 domain 给出的用户自己所能设置的最大值; </span><br><span class=\"line\">        `-` 将 soft 与 hard 都设为相同的值;</span><br><span class=\"line\">        </span><br><span class=\"line\">item    限制的资源类型, 与 <span class=\"built_in\">ulimit</span> 所限制的资源类型大致相同:</span><br><span class=\"line\">        - core - limits the core file size (KB)</span><br><span class=\"line\">        - data - max data size (KB)</span><br><span class=\"line\">        - fsize - maximum filesize (KB)</span><br><span class=\"line\">        - memlock - max locked-in-memory address space (KB)</span><br><span class=\"line\">        - nofile - max number of open file descriptors</span><br><span class=\"line\">        - rss - max resident <span class=\"built_in\">set</span> size (KB)</span><br><span class=\"line\">        - stack - max stack size (KB)</span><br><span class=\"line\">        - cpu - max CPU time (MIN)</span><br><span class=\"line\">        - nproc - max number of processes</span><br><span class=\"line\">        - as - address space <span class=\"built_in\">limit</span> (KB)</span><br><span class=\"line\">        - maxlogins - max number of logins <span class=\"keyword\">for</span> this user</span><br><span class=\"line\">        - maxsyslogins - max number of logins on the system</span><br><span class=\"line\">        - priority - the priority to run user process with</span><br><span class=\"line\">        - locks - max number of file locks the user can hold</span><br><span class=\"line\">        - sigpending - max number of pending signals</span><br><span class=\"line\">        - msgqueue - max memory used by POSIX message queues (bytes)</span><br><span class=\"line\">        - nice - max nice priority allowed to raise to values: [-20, 19]</span><br><span class=\"line\">        - rtprio - max realtime priority</span><br><span class=\"line\"></span><br><span class=\"line\">value   限制的具体值;</span><br></pre></td></tr></table></figure></p>\n<p>以下是一个具体的例子:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#&lt;domain&gt;        &lt;type&gt;     &lt;item&gt;     &lt;value&gt;</span></span><br><span class=\"line\">*                 soft      nproc       65536</span><br><span class=\"line\">*                 hard      nproc       65536</span><br><span class=\"line\">*                 -         nofile      65536</span><br><span class=\"line\">%guest            -         maxlogins   10</span><br><span class=\"line\">elastic           -         memlock     <span class=\"built_in\">unlimit</span></span><br><span class=\"line\">@dev              hard      fsize       10737418240</span><br></pre></td></tr></table></figure></p>\n<p>如上所示, 系统允许 elastic 用户的最大 memlock 为 unlimit, 如果这个值被设置为了一个比较小的值, 那么上上节 elasticsearch 试图将其改成 unlimit 便会失败;</p>\n<p>&nbsp;<br>而对于 <code>/etc/security/limits.d</code> 目录的作用,  <code>/etc/security/limits.conf</code> 文件中的第二段与第三段有如下注释:</p>\n<blockquote>\n<p>Also note that configuration files in /etc/security/limits.d directory,<br>which are read in alphabetical order, override the settings in this<br>file in case the domain is the same or more specific.<br>&nbsp;<br>That means for example that setting a limit for wildcard domain here<br>can be overriden with a wildcard setting in a config file in the<br>subdirectory, but a user specific setting here can be overriden only<br>with a user specific setting in the subdirectory.</p>\n</blockquote>\n<p>也就是说, limits.conf 配置文件, 可以在用户级别上被 limits.d 目录下的配置文件覆盖;<br>举一个例子, 在 redhat/centos 各发行版本中, limits.d 目录下就有一个文件 <code>20-nproc.conf</code>:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Default limit for number of user's processes to prevent</span></span><br><span class=\"line\"><span class=\"comment\"># accidental fork bombs.</span></span><br><span class=\"line\"><span class=\"comment\"># See rhbz #432903 for reasoning.</span></span><br><span class=\"line\">*          soft    nproc     4096</span><br><span class=\"line\">root       soft    nproc     unlimited</span><br></pre></td></tr></table></figure></p>\n<p>这里面对除了 root 用户之外的所有用户作了一个最大进程/线程数目的 soft 限制;<br>如果修改 limits.conf 文件:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">*          hard    nproc     65535</span><br></pre></td></tr></table></figure></p>\n<p>这时会发现, 除非自己试图 <code>ulimit -u</code> 修改 max processes, 否则这个值会依然被限制为 4096;<br>而要想将该值默认放到 65535, 就必须修改 <code>20-nproc.conf</code> 文件方才生效;</p>\n<h3 id=\"永久修改生效的必要条件\"><a href=\"#永久修改生效的必要条件\" class=\"headerlink\" title=\"永久修改生效的必要条件\"></a><strong>永久修改生效的必要条件</strong></h3><h2 id=\"站内相关文章\"><a href=\"#站内相关文章\" class=\"headerlink\" title=\"站内相关文章\"></a><strong>站内相关文章</strong></h2><ul>\n<li><a href=\"\">pam 认证与配置</a></li>\n<li><a href=\"\">dubbo 服务治理系统设计</a></li>\n</ul>\n<h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a><strong>参考链接</strong></h2><ul>\n<li><a href=\"http://www.cnblogs.com/zengkefu/p/5649407.html\" target=\"_blank\" rel=\"noopener\">ulimit 命令详解</a></li>\n<li><a href=\"http://blog.csdn.net/taijianyu/article/details/5976319\" target=\"_blank\" rel=\"noopener\">linux /etc/security/limits.conf的相关说明</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>ulimit 未正确设置是很多线上故障的根源:<br><code>Too many open files</code>;<br><code>java.lang.OutOfMemoryError: unable to create new native thread</code>;<br>对于生产环境来说, ulimit 的调参优化至关重要;<br>本文详细介绍并梳理一下与 ulimit 相关的林林总总;</p>\n</blockquote>","more":"<hr>\n<p>ulimit 是 linux 对于每个通过 PAM 登录的用户 ( 每个进程 ) 的资源最大使用限制的设置;<br>注意, 这里仅仅对通过 PAM 登陆的用户起作用, 而对于那些随系统启动而启动的 daemon service, ulimit 是不会去限制其资源使用的;<br>在 <code>/etc/security/limits.conf</code> 文件中的第一段注释如下:</p>\n<blockquote>\n<p>This file sets the resource limits for the users logged in via PAM.<br>It does not affect resource limits of the system services.</p>\n</blockquote>\n<p>关于 linux PAM 相关的内容, 可以前往另外一篇文章: <a href=\"\">pam 认证与配置</a>;</p>\n<h2 id=\"ulimit-基本信息\"><a href=\"#ulimit-基本信息\" class=\"headerlink\" title=\"ulimit 基本信息\"></a><strong>ulimit 基本信息</strong></h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 查看所有 ulimit 设置</span></span><br><span class=\"line\">&gt; <span class=\"built_in\">ulimit</span> -a</span><br><span class=\"line\">core file size          (blocks, -c) 0</span><br><span class=\"line\">data seg size           (kbytes, -d) unlimited</span><br><span class=\"line\">scheduling priority             (-e) 0</span><br><span class=\"line\">file size               (blocks, -f) unlimited</span><br><span class=\"line\">pending signals                 (-i) 15018</span><br><span class=\"line\">max locked memory       (kbytes, -l) 64             <span class=\"comment\"># 每个进程可以锁住而不被 swap 出去的内存</span></span><br><span class=\"line\">max memory size         (kbytes, -m) unlimited      <span class=\"comment\"># 每个进程可使用的最大内存大小</span></span><br><span class=\"line\">open files                      (-n) 1024           <span class=\"comment\"># 每个进程可打开的文件数</span></span><br><span class=\"line\">pipe size            (512 bytes, -p) 8</span><br><span class=\"line\">POSIX message queues     (bytes, -q) 819200</span><br><span class=\"line\">real-time priority              (-r) 0</span><br><span class=\"line\">stack size              (kbytes, -s) 8192           <span class=\"comment\"># 每个进程可使用的最大堆栈大小</span></span><br><span class=\"line\">cpu time               (seconds, -t) unlimited</span><br><span class=\"line\">max user processes              (-u) 4096           <span class=\"comment\"># 每个用户的最大进程数</span></span><br><span class=\"line\">virtual memory          (kbytes, -v) unlimited</span><br><span class=\"line\">file locks                      (-x) unlimited</span><br></pre></td></tr></table></figure>\n<h2 id=\"ulimit-需要优化的场景及待优化参数\"><a href=\"#ulimit-需要优化的场景及待优化参数\" class=\"headerlink\" title=\"ulimit 需要优化的场景及待优化参数\"></a><strong>ulimit 需要优化的场景及待优化参数</strong></h2><p>linux 默认的 ulimit 限制, 是出于安全考虑, 设置的有些保守; 实际的生产环境下, 往往需要对其作出适当的调整, 方可发挥机器的最大性能;</p>\n<h3 id=\"场景1-tomcat-web-容器\"><a href=\"#场景1-tomcat-web-容器\" class=\"headerlink\" title=\"场景1: tomcat web 容器 \"></a><strong>场景1: tomcat web 容器 </strong></h3><p>一台 4C4G60G 的标准虚拟主机, 其上部署了一个 tomcat 实例, 启动 catalina 进程的是 tomcat:tomcat 用户;<br>如果该服务是一个网络 IO 密集的应用, 需要打开的 socket file 远不止 1024, ulimit 设置的 max open files 就会限制其性能; 另外, 该主机只部署了这一个服务, tomcat 用户是唯一一个需要占用大量资源的用户, ulimit 对单个用户的限制便会造成机器资源闲置, 极低的使用率, 降低 web 服务的性能;<br>所以, 可以对该机器的 ulimit 作出如下调整:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1. max memory size -&gt; <span class=\"built_in\">unlimit</span></span><br><span class=\"line\">2. open files -&gt; 65536</span><br><span class=\"line\">3. stack size -&gt; <span class=\"built_in\">unlimit</span></span><br></pre></td></tr></table></figure></p>\n<p>另外, 我们还遇到一种特殊的情况, 用标准配置虚拟机跑 dubbo 的服务治理: 当时发现, 如果服务注册到 zookeeper 的数量达到一定级别, 线上就会报 <code>java.lang.OutOfMemoryError: unable to create new native thread</code> 的异常;<br>最后确定问题的原因是 <code>ulimit -u</code> max user processes 的数量配置过低, 增大后解决问题:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">4. max user processes -&gt; 65535</span><br></pre></td></tr></table></figure></p>\n<p>具体的情况可以参见这篇文章: <a href=\"\">dubbo 服务治理系统设计</a>;</p>\n<h3 id=\"场景2-elasticsearch-data-node\"><a href=\"#场景2-elasticsearch-data-node\" class=\"headerlink\" title=\"场景2: elasticsearch data node\"></a><strong>场景2: elasticsearch data node</strong></h3><p>32C64G4T 的配置, 为确保指针压缩特性被打开, 一般我们都会控制 jvm 的最大堆内存与最小堆内存: ‘-Xmx30g -Xms30g’, 并希望能锁住所有的内存, 避免堆内存被 swap 到磁盘, 降低了搜索性能; 这种场景下我们当然不希望 ulimit 限制了 max memory size 以及 max locked memory;<br>所以, 可以对该机器的 ulimit 作出如下调整:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1. max locked memory -&gt; unlimit</span><br><span class=\"line\">2. max memory size -&gt; unlimit</span><br><span class=\"line\">3. open files -&gt; 65536</span><br><span class=\"line\">4. stack size -&gt; unlimit</span><br></pre></td></tr></table></figure></p>\n<p>对于 max locked memory, elasticsearch.yml 本身有一个配置项 <code>bootstrap.mlockall</code>/<code>bootstrap.memory_lock</code> = true, 其背后实现就是通过类似于 ulimit -l unlimit 的方法完成的; 只是, elasticsearch 试图自己主动改变该配置能生效的前提, 是 ulimit 配置文件里要允许其这样设置, 具体的逻辑请看本文下下节: <a href=\"#ulimit-的永久修改\">ulimit 的永久修改</a>;</p>\n<p>&nbsp;<br>另外, 还有其他的一些场景, 可能需要调整其他参数以作优化, 此处不一而论;<br>以上是需要调整 ulimit 参数的场景举例, 下面的内容是关于如何 临时/永久 修改 ulimit 设置;</p>\n<h2 id=\"ulimit-当前-session-下的临时修改\"><a href=\"#ulimit-当前-session-下的临时修改\" class=\"headerlink\" title=\"ulimit 当前 session 下的临时修改\"></a><strong>ulimit 当前 session 下的临时修改</strong></h2><p>ulimit 的临时调整, 只对当前 session 下的当前用户, 以及当前用户所起的进程生效;<br>其调整方法也已经在 <code>ulimit -a</code> 中被注明了:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># max locked mem</span></span><br><span class=\"line\"><span class=\"built_in\">ulimit</span> -l <span class=\"built_in\">unlimit</span></span><br><span class=\"line\"><span class=\"comment\"># max mem size</span></span><br><span class=\"line\"><span class=\"built_in\">ulimit</span> -m <span class=\"built_in\">unlimit</span></span><br><span class=\"line\"><span class=\"comment\"># open files</span></span><br><span class=\"line\"><span class=\"built_in\">ulimit</span> -n 65536</span><br><span class=\"line\"><span class=\"comment\"># max user processes</span></span><br><span class=\"line\"><span class=\"built_in\">ulimit</span> -u 65536</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"ulimit-的永久修改\"><a href=\"#ulimit-的永久修改\" class=\"headerlink\" title=\"ulimit 的永久修改\"></a><strong>ulimit 的永久修改</strong></h2><p>上一节的方法, 只能在当前 session 下对当前用户作临时调整, 而 要想对 ulimit 作永久调整, 需要修改一些配置文件:</p>\n<ol>\n<li><code>/etc/security/limits.conf</code>;</li>\n<li><code>/etc/security/limits.d 目录</code>;</li>\n</ol>\n<p>这些文件用于持久化每个用户的资源限制设置;<br>其中, <code>/etc/security/limits.conf</code> 自不必说, 这是配置 ulimit 的主要文件:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">domain  限制的目标:</span><br><span class=\"line\">        username    用户名;</span><br><span class=\"line\">        @groupname  组名, 需加 <span class=\"string\">'@'</span> 前缀;</span><br><span class=\"line\">        *           通配所有用户/组;</span><br><span class=\"line\">        %groupname  这种写法只能用于限制 某个 group 的 maxlogin <span class=\"built_in\">limit</span>, 即最大登陆用户数限制;</span><br><span class=\"line\">        </span><br><span class=\"line\"><span class=\"built_in\">type</span>    限制的属性:</span><br><span class=\"line\">        `soft` 对 domain 给出的用户设置默认值; </span><br><span class=\"line\">        `hard` 限制 domain 给出的用户自己所能设置的最大值; </span><br><span class=\"line\">        `-` 将 soft 与 hard 都设为相同的值;</span><br><span class=\"line\">        </span><br><span class=\"line\">item    限制的资源类型, 与 <span class=\"built_in\">ulimit</span> 所限制的资源类型大致相同:</span><br><span class=\"line\">        - core - limits the core file size (KB)</span><br><span class=\"line\">        - data - max data size (KB)</span><br><span class=\"line\">        - fsize - maximum filesize (KB)</span><br><span class=\"line\">        - memlock - max locked-in-memory address space (KB)</span><br><span class=\"line\">        - nofile - max number of open file descriptors</span><br><span class=\"line\">        - rss - max resident <span class=\"built_in\">set</span> size (KB)</span><br><span class=\"line\">        - stack - max stack size (KB)</span><br><span class=\"line\">        - cpu - max CPU time (MIN)</span><br><span class=\"line\">        - nproc - max number of processes</span><br><span class=\"line\">        - as - address space <span class=\"built_in\">limit</span> (KB)</span><br><span class=\"line\">        - maxlogins - max number of logins <span class=\"keyword\">for</span> this user</span><br><span class=\"line\">        - maxsyslogins - max number of logins on the system</span><br><span class=\"line\">        - priority - the priority to run user process with</span><br><span class=\"line\">        - locks - max number of file locks the user can hold</span><br><span class=\"line\">        - sigpending - max number of pending signals</span><br><span class=\"line\">        - msgqueue - max memory used by POSIX message queues (bytes)</span><br><span class=\"line\">        - nice - max nice priority allowed to raise to values: [-20, 19]</span><br><span class=\"line\">        - rtprio - max realtime priority</span><br><span class=\"line\"></span><br><span class=\"line\">value   限制的具体值;</span><br></pre></td></tr></table></figure></p>\n<p>以下是一个具体的例子:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#&lt;domain&gt;        &lt;type&gt;     &lt;item&gt;     &lt;value&gt;</span></span><br><span class=\"line\">*                 soft      nproc       65536</span><br><span class=\"line\">*                 hard      nproc       65536</span><br><span class=\"line\">*                 -         nofile      65536</span><br><span class=\"line\">%guest            -         maxlogins   10</span><br><span class=\"line\">elastic           -         memlock     <span class=\"built_in\">unlimit</span></span><br><span class=\"line\">@dev              hard      fsize       10737418240</span><br></pre></td></tr></table></figure></p>\n<p>如上所示, 系统允许 elastic 用户的最大 memlock 为 unlimit, 如果这个值被设置为了一个比较小的值, 那么上上节 elasticsearch 试图将其改成 unlimit 便会失败;</p>\n<p>&nbsp;<br>而对于 <code>/etc/security/limits.d</code> 目录的作用,  <code>/etc/security/limits.conf</code> 文件中的第二段与第三段有如下注释:</p>\n<blockquote>\n<p>Also note that configuration files in /etc/security/limits.d directory,<br>which are read in alphabetical order, override the settings in this<br>file in case the domain is the same or more specific.<br>&nbsp;<br>That means for example that setting a limit for wildcard domain here<br>can be overriden with a wildcard setting in a config file in the<br>subdirectory, but a user specific setting here can be overriden only<br>with a user specific setting in the subdirectory.</p>\n</blockquote>\n<p>也就是说, limits.conf 配置文件, 可以在用户级别上被 limits.d 目录下的配置文件覆盖;<br>举一个例子, 在 redhat/centos 各发行版本中, limits.d 目录下就有一个文件 <code>20-nproc.conf</code>:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Default limit for number of user's processes to prevent</span></span><br><span class=\"line\"><span class=\"comment\"># accidental fork bombs.</span></span><br><span class=\"line\"><span class=\"comment\"># See rhbz #432903 for reasoning.</span></span><br><span class=\"line\">*          soft    nproc     4096</span><br><span class=\"line\">root       soft    nproc     unlimited</span><br></pre></td></tr></table></figure></p>\n<p>这里面对除了 root 用户之外的所有用户作了一个最大进程/线程数目的 soft 限制;<br>如果修改 limits.conf 文件:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">*          hard    nproc     65535</span><br></pre></td></tr></table></figure></p>\n<p>这时会发现, 除非自己试图 <code>ulimit -u</code> 修改 max processes, 否则这个值会依然被限制为 4096;<br>而要想将该值默认放到 65535, 就必须修改 <code>20-nproc.conf</code> 文件方才生效;</p>\n<h3 id=\"永久修改生效的必要条件\"><a href=\"#永久修改生效的必要条件\" class=\"headerlink\" title=\"永久修改生效的必要条件\"></a><strong>永久修改生效的必要条件</strong></h3><h2 id=\"站内相关文章\"><a href=\"#站内相关文章\" class=\"headerlink\" title=\"站内相关文章\"></a><strong>站内相关文章</strong></h2><ul>\n<li><a href=\"\">pam 认证与配置</a></li>\n<li><a href=\"\">dubbo 服务治理系统设计</a></li>\n</ul>\n<h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a><strong>参考链接</strong></h2><ul>\n<li><a href=\"http://www.cnblogs.com/zengkefu/p/5649407.html\" target=\"_blank\" rel=\"noopener\">ulimit 命令详解</a></li>\n<li><a href=\"http://blog.csdn.net/taijianyu/article/details/5976319\" target=\"_blank\" rel=\"noopener\">linux /etc/security/limits.conf的相关说明</a></li>\n</ul>"},{"title":"du / df 使用及其区别","date":"2017-04-07T14:58:04.000Z","_content":"\n> 本文主要是整理 磁盘使用量 相关的命令, 如 du, df 等;\n接着, 一般性得总结这两个命令在实际工作中的应用;\n然后再以 du, df 命令的区别为例, 讨论命令背后的逻辑, 工作中存在的问题, 最后引申出问题解决的工具: lsof;\n\n<!--more-->\n\n------\n\n## **du命令**\n> estimate disk file space usage. --- man du\n\n### **du 的常用选项**\n``` bash\n# 不加任何选项, 默认是 列举指定路径下, 每一个目录(递归所有的子目录)的大小\nsudo du /target_path\n# 列举指定路径下所有的文件(包括目录与文件)的大小\nsudo du -a /target_path\n# 以 human-readable 的形式, 列举目标路径的文件磁盘占用总大小(将该路径下所有子文件大小求和)\nsudo du -s /target_path\n# 以指定路径下所有的子一级路径为 target, 以 human-readable 的方式列举其中每一个下的所有子文件大小之和\n# (诊断 磁盘满问题 最常用的方式)\nsudo du -sh /target_path/*\n# 除了其余选项该有的输出之外, 最后一行另附一个给定 target_path 下的 total 总和\n# 理论上这与目标路径不含通配符的 -sh 输出结果是相同的\nsudo du -c /target_path\n```\n\n## **df 命令**\n> file system disk space usage. --- man df\n\n### **df 的常用选项**\n``` bash\n# 显示给定的路径所挂载的磁盘分区的大小及使用量等\ndf /target_path\n# 以 MB 最小单位显示大小及使用量\ndf --block-size=1m /target_path\ndf -B 1m /target_path\n# 以 human-readable 的方式显示 当前挂载的所有可用健康的文件系统 的大小, 使用量等情况\ndf -h # 1024\ndf -H # 1000\n# 显示所有的文件系统, 包括 伪文件系统, 重复的, 不可访问的文件系统 (pseudo, duplicate, inaccessible)\ndf -a\n# 过滤 nfs 远程文件系统后的本地文件系统\ndf -l\n```\n&nbsp;\n**一般性总结:**\ndf 命令主要关心的是磁盘分区的 size, 而不是具体某文件的占用大小; \n所以 df 命令的主要运用场景是: `df -h`, 判断所挂载的每个分区的使用率, 是不是满了;\n作为先决判断依据, 如果发现磁盘满了, 再接着使用 `du -sh` 等命令进一步排查;\n&nbsp;\n\n## **du 与 df 命令的区别**\n### **df 命令与 du 命令的工作原理**\ndf 命令使用 系统调用 `statfs`, 获取磁盘分区的超级块 (super block) 使用情况;\ndu 命令使用 系统调用 `fstat`, 获取待统计文件的大小;\n### **df 命令与 du 命令可接受范围内不一致**\n[**问题场景**]: *du -s 与 df 核算精确结果总有差异;*\n&nbsp;\n[**原因**]: du -s 命令通过将指定文件系统中所有的目录, 符号链接和文件使用的块数累加得到该文件系统使用的总块数, 这是上层用户级的数据;\ndf 命令通过查看文件系统磁盘块分配图得出总块数与剩余块数, 这是直接从底层获取的数据;\n所以, 一些元数据信息(inode, super blocks 等)不会被上层的 du 命令计入在内, 而 df 命令由于直接获取的底层超级块的信息, 则会将其计入在内;\n&nbsp;\n[**结论**]: *这种差异属于系统性的差异, 是由命令的特点决定的, 无法改变;*\n### **df 命令与 du 命令显著不一致**\n[**问题场景**]: *当一个被某进程持有其句柄的文件被删除后, 进程不释放句柄, du 将不会再统计该文件, 而 df 的使用量仍会将其计入在内;*\n&nbsp;\n[**原因**]: 当文件句柄被进程持有, 尽管文件被删除, 目录项已经不存在该文件路径了, 但只要句柄不释放, 文件在磁盘上就不会真正删除该文件;\n这样一来, 目录项不存在该文件了, du 命令就不会统计到该文件, 但文件没真正删除, 磁盘分区 super block 的信息就不会改变, df 命令仍会将其计入使用量;\n&nbsp;\n[**结论**]: *这种差异属于第三方因素干扰导致的差异, 且差异十分显著, 需要通过下一节所讨论的方式加以解决;*\n### **问题解决方案**\n磁盘满了, 但是有进程持有大文件的句柄, 无法真正从磁盘删除掉; 对于这类问题, 有如下两种解决方案:\n1.配合使用 lsof 找出相关的 `幽灵文件` 的句柄持有情况(command 与 pid):\n``` bash\n> sudo lsof | grep deleted\nnginx      4804      nobody   59u      REG\t253,1    110116  243425480 /usr/local/openresty/nginx/client_body_temp/0068359496 (deleted)\nnginx      4819      nobody   51u      REG\t253,1    115876  243425480 /usr/local/openresty/nginx/client_body_temp/0068359498 (deleted)\n...\n```\n然后 kill 掉进程 (或 restart 进程), 即可释放文件句柄;\n当然, 本文是以 nginx 举例, 但实际上 nginx 对于日志文件的文件句柄释放, 有自己专有的方法, 具体内容请见本站另外两篇文章: [linux signals 总体认识#其他信号](https://zshell-zhang.github.io/2017/04/05/linux-process--linux_signals总体认识/#其他信号) 和 [nginx signals 处理]();\n另外, 磁盘满的问题, 不能总是靠人肉登机器去解决, 我们需要一些自动化的方案来将我们从这种低级的操作中解放出来; \n所以, 对于所有机器上都会遇到的日志文件不断累积占满磁盘的问题, 这篇文章介绍了解决方案: [logrotate 配置与运维]();\n&nbsp;\n2.如果进程很重要, 不能容忍任何时间范围内的服务不可用 (其实理论上这种情况属于单点瓶颈, 未能做到高可用), 则可以采用如下方式:\n``` bash\n# 将文件写空\nsudo echo > file_path\n```\n将文件内容间接删除, 这样即便句柄未释放, 但文件本身已经没有内容, 也就不再占用空间了;\n\n## **站内相关文章**\n- [logrotate 配置与运维](https://zshell-zhang.github.io/2018/01/15/linux-varlog--logrotate%E9%85%8D%E7%BD%AE%E4%B8%8E%E8%BF%90%E7%BB%B4/)\n- [linux signals 总体认识#其他信号](https://zshell-zhang.github.io/2017/04/05/linux-process--linux_signals总体认识/#其他信号)\n- [nginx signals 处理]()\n\n## **参考链接**\n- [df和du显示的磁盘空间使用情况不一致的原因及处理](http://www.cnblogs.com/heyonggang/p/3644736.html)\n- [linux lsof 详解](http://blog.csdn.net/guoguo1980/article/details/2324454)\n\n","source":"_posts/linux-other--du,df使用及其区别.md","raw":"---\ntitle: du / df 使用及其区别\ndate: 2017-04-07 22:58:04\ncategories:\n - linux\n - other\ntags:\n - linux:disk\n---\n\n> 本文主要是整理 磁盘使用量 相关的命令, 如 du, df 等;\n接着, 一般性得总结这两个命令在实际工作中的应用;\n然后再以 du, df 命令的区别为例, 讨论命令背后的逻辑, 工作中存在的问题, 最后引申出问题解决的工具: lsof;\n\n<!--more-->\n\n------\n\n## **du命令**\n> estimate disk file space usage. --- man du\n\n### **du 的常用选项**\n``` bash\n# 不加任何选项, 默认是 列举指定路径下, 每一个目录(递归所有的子目录)的大小\nsudo du /target_path\n# 列举指定路径下所有的文件(包括目录与文件)的大小\nsudo du -a /target_path\n# 以 human-readable 的形式, 列举目标路径的文件磁盘占用总大小(将该路径下所有子文件大小求和)\nsudo du -s /target_path\n# 以指定路径下所有的子一级路径为 target, 以 human-readable 的方式列举其中每一个下的所有子文件大小之和\n# (诊断 磁盘满问题 最常用的方式)\nsudo du -sh /target_path/*\n# 除了其余选项该有的输出之外, 最后一行另附一个给定 target_path 下的 total 总和\n# 理论上这与目标路径不含通配符的 -sh 输出结果是相同的\nsudo du -c /target_path\n```\n\n## **df 命令**\n> file system disk space usage. --- man df\n\n### **df 的常用选项**\n``` bash\n# 显示给定的路径所挂载的磁盘分区的大小及使用量等\ndf /target_path\n# 以 MB 最小单位显示大小及使用量\ndf --block-size=1m /target_path\ndf -B 1m /target_path\n# 以 human-readable 的方式显示 当前挂载的所有可用健康的文件系统 的大小, 使用量等情况\ndf -h # 1024\ndf -H # 1000\n# 显示所有的文件系统, 包括 伪文件系统, 重复的, 不可访问的文件系统 (pseudo, duplicate, inaccessible)\ndf -a\n# 过滤 nfs 远程文件系统后的本地文件系统\ndf -l\n```\n&nbsp;\n**一般性总结:**\ndf 命令主要关心的是磁盘分区的 size, 而不是具体某文件的占用大小; \n所以 df 命令的主要运用场景是: `df -h`, 判断所挂载的每个分区的使用率, 是不是满了;\n作为先决判断依据, 如果发现磁盘满了, 再接着使用 `du -sh` 等命令进一步排查;\n&nbsp;\n\n## **du 与 df 命令的区别**\n### **df 命令与 du 命令的工作原理**\ndf 命令使用 系统调用 `statfs`, 获取磁盘分区的超级块 (super block) 使用情况;\ndu 命令使用 系统调用 `fstat`, 获取待统计文件的大小;\n### **df 命令与 du 命令可接受范围内不一致**\n[**问题场景**]: *du -s 与 df 核算精确结果总有差异;*\n&nbsp;\n[**原因**]: du -s 命令通过将指定文件系统中所有的目录, 符号链接和文件使用的块数累加得到该文件系统使用的总块数, 这是上层用户级的数据;\ndf 命令通过查看文件系统磁盘块分配图得出总块数与剩余块数, 这是直接从底层获取的数据;\n所以, 一些元数据信息(inode, super blocks 等)不会被上层的 du 命令计入在内, 而 df 命令由于直接获取的底层超级块的信息, 则会将其计入在内;\n&nbsp;\n[**结论**]: *这种差异属于系统性的差异, 是由命令的特点决定的, 无法改变;*\n### **df 命令与 du 命令显著不一致**\n[**问题场景**]: *当一个被某进程持有其句柄的文件被删除后, 进程不释放句柄, du 将不会再统计该文件, 而 df 的使用量仍会将其计入在内;*\n&nbsp;\n[**原因**]: 当文件句柄被进程持有, 尽管文件被删除, 目录项已经不存在该文件路径了, 但只要句柄不释放, 文件在磁盘上就不会真正删除该文件;\n这样一来, 目录项不存在该文件了, du 命令就不会统计到该文件, 但文件没真正删除, 磁盘分区 super block 的信息就不会改变, df 命令仍会将其计入使用量;\n&nbsp;\n[**结论**]: *这种差异属于第三方因素干扰导致的差异, 且差异十分显著, 需要通过下一节所讨论的方式加以解决;*\n### **问题解决方案**\n磁盘满了, 但是有进程持有大文件的句柄, 无法真正从磁盘删除掉; 对于这类问题, 有如下两种解决方案:\n1.配合使用 lsof 找出相关的 `幽灵文件` 的句柄持有情况(command 与 pid):\n``` bash\n> sudo lsof | grep deleted\nnginx      4804      nobody   59u      REG\t253,1    110116  243425480 /usr/local/openresty/nginx/client_body_temp/0068359496 (deleted)\nnginx      4819      nobody   51u      REG\t253,1    115876  243425480 /usr/local/openresty/nginx/client_body_temp/0068359498 (deleted)\n...\n```\n然后 kill 掉进程 (或 restart 进程), 即可释放文件句柄;\n当然, 本文是以 nginx 举例, 但实际上 nginx 对于日志文件的文件句柄释放, 有自己专有的方法, 具体内容请见本站另外两篇文章: [linux signals 总体认识#其他信号](https://zshell-zhang.github.io/2017/04/05/linux-process--linux_signals总体认识/#其他信号) 和 [nginx signals 处理]();\n另外, 磁盘满的问题, 不能总是靠人肉登机器去解决, 我们需要一些自动化的方案来将我们从这种低级的操作中解放出来; \n所以, 对于所有机器上都会遇到的日志文件不断累积占满磁盘的问题, 这篇文章介绍了解决方案: [logrotate 配置与运维]();\n&nbsp;\n2.如果进程很重要, 不能容忍任何时间范围内的服务不可用 (其实理论上这种情况属于单点瓶颈, 未能做到高可用), 则可以采用如下方式:\n``` bash\n# 将文件写空\nsudo echo > file_path\n```\n将文件内容间接删除, 这样即便句柄未释放, 但文件本身已经没有内容, 也就不再占用空间了;\n\n## **站内相关文章**\n- [logrotate 配置与运维](https://zshell-zhang.github.io/2018/01/15/linux-varlog--logrotate%E9%85%8D%E7%BD%AE%E4%B8%8E%E8%BF%90%E7%BB%B4/)\n- [linux signals 总体认识#其他信号](https://zshell-zhang.github.io/2017/04/05/linux-process--linux_signals总体认识/#其他信号)\n- [nginx signals 处理]()\n\n## **参考链接**\n- [df和du显示的磁盘空间使用情况不一致的原因及处理](http://www.cnblogs.com/heyonggang/p/3644736.html)\n- [linux lsof 详解](http://blog.csdn.net/guoguo1980/article/details/2324454)\n\n","slug":"linux-other--du,df使用及其区别","published":1,"updated":"2018-01-27T14:53:07.565Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cje24mxtl0001j1jxctoeax8d","content":"<blockquote>\n<p>本文主要是整理 磁盘使用量 相关的命令, 如 du, df 等;<br>接着, 一般性得总结这两个命令在实际工作中的应用;<br>然后再以 du, df 命令的区别为例, 讨论命令背后的逻辑, 工作中存在的问题, 最后引申出问题解决的工具: lsof;</p>\n</blockquote>\n<a id=\"more\"></a>\n<hr>\n<h2 id=\"du命令\"><a href=\"#du命令\" class=\"headerlink\" title=\"du命令\"></a><strong>du命令</strong></h2><blockquote>\n<p>estimate disk file space usage. — man du</p>\n</blockquote>\n<h3 id=\"du-的常用选项\"><a href=\"#du-的常用选项\" class=\"headerlink\" title=\"du 的常用选项\"></a><strong>du 的常用选项</strong></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 不加任何选项, 默认是 列举指定路径下, 每一个目录(递归所有的子目录)的大小</span></span><br><span class=\"line\">sudo du /target_path</span><br><span class=\"line\"><span class=\"comment\"># 列举指定路径下所有的文件(包括目录与文件)的大小</span></span><br><span class=\"line\">sudo du -a /target_path</span><br><span class=\"line\"><span class=\"comment\"># 以 human-readable 的形式, 列举目标路径的文件磁盘占用总大小(将该路径下所有子文件大小求和)</span></span><br><span class=\"line\">sudo du -s /target_path</span><br><span class=\"line\"><span class=\"comment\"># 以指定路径下所有的子一级路径为 target, 以 human-readable 的方式列举其中每一个下的所有子文件大小之和</span></span><br><span class=\"line\"><span class=\"comment\"># (诊断 磁盘满问题 最常用的方式)</span></span><br><span class=\"line\">sudo du -sh /target_path/*</span><br><span class=\"line\"><span class=\"comment\"># 除了其余选项该有的输出之外, 最后一行另附一个给定 target_path 下的 total 总和</span></span><br><span class=\"line\"><span class=\"comment\"># 理论上这与目标路径不含通配符的 -sh 输出结果是相同的</span></span><br><span class=\"line\">sudo du -c /target_path</span><br></pre></td></tr></table></figure>\n<h2 id=\"df-命令\"><a href=\"#df-命令\" class=\"headerlink\" title=\"df 命令\"></a><strong>df 命令</strong></h2><blockquote>\n<p>file system disk space usage. — man df</p>\n</blockquote>\n<h3 id=\"df-的常用选项\"><a href=\"#df-的常用选项\" class=\"headerlink\" title=\"df 的常用选项\"></a><strong>df 的常用选项</strong></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 显示给定的路径所挂载的磁盘分区的大小及使用量等</span></span><br><span class=\"line\">df /target_path</span><br><span class=\"line\"><span class=\"comment\"># 以 MB 最小单位显示大小及使用量</span></span><br><span class=\"line\">df --block-size=1m /target_path</span><br><span class=\"line\">df -B 1m /target_path</span><br><span class=\"line\"><span class=\"comment\"># 以 human-readable 的方式显示 当前挂载的所有可用健康的文件系统 的大小, 使用量等情况</span></span><br><span class=\"line\">df -h <span class=\"comment\"># 1024</span></span><br><span class=\"line\">df -H <span class=\"comment\"># 1000</span></span><br><span class=\"line\"><span class=\"comment\"># 显示所有的文件系统, 包括 伪文件系统, 重复的, 不可访问的文件系统 (pseudo, duplicate, inaccessible)</span></span><br><span class=\"line\">df -a</span><br><span class=\"line\"><span class=\"comment\"># 过滤 nfs 远程文件系统后的本地文件系统</span></span><br><span class=\"line\">df -l</span><br></pre></td></tr></table></figure>\n<p>&nbsp;<br><strong>一般性总结:</strong><br>df 命令主要关心的是磁盘分区的 size, 而不是具体某文件的占用大小;<br>所以 df 命令的主要运用场景是: <code>df -h</code>, 判断所挂载的每个分区的使用率, 是不是满了;<br>作为先决判断依据, 如果发现磁盘满了, 再接着使用 <code>du -sh</code> 等命令进一步排查;<br>&nbsp;</p>\n<h2 id=\"du-与-df-命令的区别\"><a href=\"#du-与-df-命令的区别\" class=\"headerlink\" title=\"du 与 df 命令的区别\"></a><strong>du 与 df 命令的区别</strong></h2><h3 id=\"df-命令与-du-命令的工作原理\"><a href=\"#df-命令与-du-命令的工作原理\" class=\"headerlink\" title=\"df 命令与 du 命令的工作原理\"></a><strong>df 命令与 du 命令的工作原理</strong></h3><p>df 命令使用 系统调用 <code>statfs</code>, 获取磁盘分区的超级块 (super block) 使用情况;<br>du 命令使用 系统调用 <code>fstat</code>, 获取待统计文件的大小;</p>\n<h3 id=\"df-命令与-du-命令可接受范围内不一致\"><a href=\"#df-命令与-du-命令可接受范围内不一致\" class=\"headerlink\" title=\"df 命令与 du 命令可接受范围内不一致\"></a><strong>df 命令与 du 命令可接受范围内不一致</strong></h3><p>[<strong>问题场景</strong>]: <em>du -s 与 df 核算精确结果总有差异;</em><br>&nbsp;<br>[<strong>原因</strong>]: du -s 命令通过将指定文件系统中所有的目录, 符号链接和文件使用的块数累加得到该文件系统使用的总块数, 这是上层用户级的数据;<br>df 命令通过查看文件系统磁盘块分配图得出总块数与剩余块数, 这是直接从底层获取的数据;<br>所以, 一些元数据信息(inode, super blocks 等)不会被上层的 du 命令计入在内, 而 df 命令由于直接获取的底层超级块的信息, 则会将其计入在内;<br>&nbsp;<br>[<strong>结论</strong>]: <em>这种差异属于系统性的差异, 是由命令的特点决定的, 无法改变;</em></p>\n<h3 id=\"df-命令与-du-命令显著不一致\"><a href=\"#df-命令与-du-命令显著不一致\" class=\"headerlink\" title=\"df 命令与 du 命令显著不一致\"></a><strong>df 命令与 du 命令显著不一致</strong></h3><p>[<strong>问题场景</strong>]: <em>当一个被某进程持有其句柄的文件被删除后, 进程不释放句柄, du 将不会再统计该文件, 而 df 的使用量仍会将其计入在内;</em><br>&nbsp;<br>[<strong>原因</strong>]: 当文件句柄被进程持有, 尽管文件被删除, 目录项已经不存在该文件路径了, 但只要句柄不释放, 文件在磁盘上就不会真正删除该文件;<br>这样一来, 目录项不存在该文件了, du 命令就不会统计到该文件, 但文件没真正删除, 磁盘分区 super block 的信息就不会改变, df 命令仍会将其计入使用量;<br>&nbsp;<br>[<strong>结论</strong>]: <em>这种差异属于第三方因素干扰导致的差异, 且差异十分显著, 需要通过下一节所讨论的方式加以解决;</em></p>\n<h3 id=\"问题解决方案\"><a href=\"#问题解决方案\" class=\"headerlink\" title=\"问题解决方案\"></a><strong>问题解决方案</strong></h3><p>磁盘满了, 但是有进程持有大文件的句柄, 无法真正从磁盘删除掉; 对于这类问题, 有如下两种解决方案:<br>1.配合使用 lsof 找出相关的 <code>幽灵文件</code> 的句柄持有情况(command 与 pid):<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; sudo lsof | grep deleted</span><br><span class=\"line\">nginx      4804      nobody   59u      REG\t253,1    110116  243425480 /usr/<span class=\"built_in\">local</span>/openresty/nginx/client_body_temp/0068359496 (deleted)</span><br><span class=\"line\">nginx      4819      nobody   51u      REG\t253,1    115876  243425480 /usr/<span class=\"built_in\">local</span>/openresty/nginx/client_body_temp/0068359498 (deleted)</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure></p>\n<p>然后 kill 掉进程 (或 restart 进程), 即可释放文件句柄;<br>当然, 本文是以 nginx 举例, 但实际上 nginx 对于日志文件的文件句柄释放, 有自己专有的方法, 具体内容请见本站另外两篇文章: <a href=\"https://zshell-zhang.github.io/2017/04/05/linux-process--linux_signals总体认识/#其他信号\">linux signals 总体认识#其他信号</a> 和 <a href=\"\">nginx signals 处理</a>;<br>另外, 磁盘满的问题, 不能总是靠人肉登机器去解决, 我们需要一些自动化的方案来将我们从这种低级的操作中解放出来;<br>所以, 对于所有机器上都会遇到的日志文件不断累积占满磁盘的问题, 这篇文章介绍了解决方案: <a href=\"\">logrotate 配置与运维</a>;<br>&nbsp;<br>2.如果进程很重要, 不能容忍任何时间范围内的服务不可用 (其实理论上这种情况属于单点瓶颈, 未能做到高可用), 则可以采用如下方式:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 将文件写空</span></span><br><span class=\"line\">sudo <span class=\"built_in\">echo</span> &gt; file_path</span><br></pre></td></tr></table></figure></p>\n<p>将文件内容间接删除, 这样即便句柄未释放, 但文件本身已经没有内容, 也就不再占用空间了;</p>\n<h2 id=\"站内相关文章\"><a href=\"#站内相关文章\" class=\"headerlink\" title=\"站内相关文章\"></a><strong>站内相关文章</strong></h2><ul>\n<li><a href=\"https://zshell-zhang.github.io/2018/01/15/linux-varlog--logrotate%E9%85%8D%E7%BD%AE%E4%B8%8E%E8%BF%90%E7%BB%B4/\">logrotate 配置与运维</a></li>\n<li><a href=\"https://zshell-zhang.github.io/2017/04/05/linux-process--linux_signals总体认识/#其他信号\">linux signals 总体认识#其他信号</a></li>\n<li><a href=\"\">nginx signals 处理</a></li>\n</ul>\n<h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a><strong>参考链接</strong></h2><ul>\n<li><a href=\"http://www.cnblogs.com/heyonggang/p/3644736.html\" target=\"_blank\" rel=\"noopener\">df和du显示的磁盘空间使用情况不一致的原因及处理</a></li>\n<li><a href=\"http://blog.csdn.net/guoguo1980/article/details/2324454\" target=\"_blank\" rel=\"noopener\">linux lsof 详解</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>本文主要是整理 磁盘使用量 相关的命令, 如 du, df 等;<br>接着, 一般性得总结这两个命令在实际工作中的应用;<br>然后再以 du, df 命令的区别为例, 讨论命令背后的逻辑, 工作中存在的问题, 最后引申出问题解决的工具: lsof;</p>\n</blockquote>","more":"<hr>\n<h2 id=\"du命令\"><a href=\"#du命令\" class=\"headerlink\" title=\"du命令\"></a><strong>du命令</strong></h2><blockquote>\n<p>estimate disk file space usage. — man du</p>\n</blockquote>\n<h3 id=\"du-的常用选项\"><a href=\"#du-的常用选项\" class=\"headerlink\" title=\"du 的常用选项\"></a><strong>du 的常用选项</strong></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 不加任何选项, 默认是 列举指定路径下, 每一个目录(递归所有的子目录)的大小</span></span><br><span class=\"line\">sudo du /target_path</span><br><span class=\"line\"><span class=\"comment\"># 列举指定路径下所有的文件(包括目录与文件)的大小</span></span><br><span class=\"line\">sudo du -a /target_path</span><br><span class=\"line\"><span class=\"comment\"># 以 human-readable 的形式, 列举目标路径的文件磁盘占用总大小(将该路径下所有子文件大小求和)</span></span><br><span class=\"line\">sudo du -s /target_path</span><br><span class=\"line\"><span class=\"comment\"># 以指定路径下所有的子一级路径为 target, 以 human-readable 的方式列举其中每一个下的所有子文件大小之和</span></span><br><span class=\"line\"><span class=\"comment\"># (诊断 磁盘满问题 最常用的方式)</span></span><br><span class=\"line\">sudo du -sh /target_path/*</span><br><span class=\"line\"><span class=\"comment\"># 除了其余选项该有的输出之外, 最后一行另附一个给定 target_path 下的 total 总和</span></span><br><span class=\"line\"><span class=\"comment\"># 理论上这与目标路径不含通配符的 -sh 输出结果是相同的</span></span><br><span class=\"line\">sudo du -c /target_path</span><br></pre></td></tr></table></figure>\n<h2 id=\"df-命令\"><a href=\"#df-命令\" class=\"headerlink\" title=\"df 命令\"></a><strong>df 命令</strong></h2><blockquote>\n<p>file system disk space usage. — man df</p>\n</blockquote>\n<h3 id=\"df-的常用选项\"><a href=\"#df-的常用选项\" class=\"headerlink\" title=\"df 的常用选项\"></a><strong>df 的常用选项</strong></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 显示给定的路径所挂载的磁盘分区的大小及使用量等</span></span><br><span class=\"line\">df /target_path</span><br><span class=\"line\"><span class=\"comment\"># 以 MB 最小单位显示大小及使用量</span></span><br><span class=\"line\">df --block-size=1m /target_path</span><br><span class=\"line\">df -B 1m /target_path</span><br><span class=\"line\"><span class=\"comment\"># 以 human-readable 的方式显示 当前挂载的所有可用健康的文件系统 的大小, 使用量等情况</span></span><br><span class=\"line\">df -h <span class=\"comment\"># 1024</span></span><br><span class=\"line\">df -H <span class=\"comment\"># 1000</span></span><br><span class=\"line\"><span class=\"comment\"># 显示所有的文件系统, 包括 伪文件系统, 重复的, 不可访问的文件系统 (pseudo, duplicate, inaccessible)</span></span><br><span class=\"line\">df -a</span><br><span class=\"line\"><span class=\"comment\"># 过滤 nfs 远程文件系统后的本地文件系统</span></span><br><span class=\"line\">df -l</span><br></pre></td></tr></table></figure>\n<p>&nbsp;<br><strong>一般性总结:</strong><br>df 命令主要关心的是磁盘分区的 size, 而不是具体某文件的占用大小;<br>所以 df 命令的主要运用场景是: <code>df -h</code>, 判断所挂载的每个分区的使用率, 是不是满了;<br>作为先决判断依据, 如果发现磁盘满了, 再接着使用 <code>du -sh</code> 等命令进一步排查;<br>&nbsp;</p>\n<h2 id=\"du-与-df-命令的区别\"><a href=\"#du-与-df-命令的区别\" class=\"headerlink\" title=\"du 与 df 命令的区别\"></a><strong>du 与 df 命令的区别</strong></h2><h3 id=\"df-命令与-du-命令的工作原理\"><a href=\"#df-命令与-du-命令的工作原理\" class=\"headerlink\" title=\"df 命令与 du 命令的工作原理\"></a><strong>df 命令与 du 命令的工作原理</strong></h3><p>df 命令使用 系统调用 <code>statfs</code>, 获取磁盘分区的超级块 (super block) 使用情况;<br>du 命令使用 系统调用 <code>fstat</code>, 获取待统计文件的大小;</p>\n<h3 id=\"df-命令与-du-命令可接受范围内不一致\"><a href=\"#df-命令与-du-命令可接受范围内不一致\" class=\"headerlink\" title=\"df 命令与 du 命令可接受范围内不一致\"></a><strong>df 命令与 du 命令可接受范围内不一致</strong></h3><p>[<strong>问题场景</strong>]: <em>du -s 与 df 核算精确结果总有差异;</em><br>&nbsp;<br>[<strong>原因</strong>]: du -s 命令通过将指定文件系统中所有的目录, 符号链接和文件使用的块数累加得到该文件系统使用的总块数, 这是上层用户级的数据;<br>df 命令通过查看文件系统磁盘块分配图得出总块数与剩余块数, 这是直接从底层获取的数据;<br>所以, 一些元数据信息(inode, super blocks 等)不会被上层的 du 命令计入在内, 而 df 命令由于直接获取的底层超级块的信息, 则会将其计入在内;<br>&nbsp;<br>[<strong>结论</strong>]: <em>这种差异属于系统性的差异, 是由命令的特点决定的, 无法改变;</em></p>\n<h3 id=\"df-命令与-du-命令显著不一致\"><a href=\"#df-命令与-du-命令显著不一致\" class=\"headerlink\" title=\"df 命令与 du 命令显著不一致\"></a><strong>df 命令与 du 命令显著不一致</strong></h3><p>[<strong>问题场景</strong>]: <em>当一个被某进程持有其句柄的文件被删除后, 进程不释放句柄, du 将不会再统计该文件, 而 df 的使用量仍会将其计入在内;</em><br>&nbsp;<br>[<strong>原因</strong>]: 当文件句柄被进程持有, 尽管文件被删除, 目录项已经不存在该文件路径了, 但只要句柄不释放, 文件在磁盘上就不会真正删除该文件;<br>这样一来, 目录项不存在该文件了, du 命令就不会统计到该文件, 但文件没真正删除, 磁盘分区 super block 的信息就不会改变, df 命令仍会将其计入使用量;<br>&nbsp;<br>[<strong>结论</strong>]: <em>这种差异属于第三方因素干扰导致的差异, 且差异十分显著, 需要通过下一节所讨论的方式加以解决;</em></p>\n<h3 id=\"问题解决方案\"><a href=\"#问题解决方案\" class=\"headerlink\" title=\"问题解决方案\"></a><strong>问题解决方案</strong></h3><p>磁盘满了, 但是有进程持有大文件的句柄, 无法真正从磁盘删除掉; 对于这类问题, 有如下两种解决方案:<br>1.配合使用 lsof 找出相关的 <code>幽灵文件</code> 的句柄持有情况(command 与 pid):<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; sudo lsof | grep deleted</span><br><span class=\"line\">nginx      4804      nobody   59u      REG\t253,1    110116  243425480 /usr/<span class=\"built_in\">local</span>/openresty/nginx/client_body_temp/0068359496 (deleted)</span><br><span class=\"line\">nginx      4819      nobody   51u      REG\t253,1    115876  243425480 /usr/<span class=\"built_in\">local</span>/openresty/nginx/client_body_temp/0068359498 (deleted)</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure></p>\n<p>然后 kill 掉进程 (或 restart 进程), 即可释放文件句柄;<br>当然, 本文是以 nginx 举例, 但实际上 nginx 对于日志文件的文件句柄释放, 有自己专有的方法, 具体内容请见本站另外两篇文章: <a href=\"https://zshell-zhang.github.io/2017/04/05/linux-process--linux_signals总体认识/#其他信号\">linux signals 总体认识#其他信号</a> 和 <a href=\"\">nginx signals 处理</a>;<br>另外, 磁盘满的问题, 不能总是靠人肉登机器去解决, 我们需要一些自动化的方案来将我们从这种低级的操作中解放出来;<br>所以, 对于所有机器上都会遇到的日志文件不断累积占满磁盘的问题, 这篇文章介绍了解决方案: <a href=\"\">logrotate 配置与运维</a>;<br>&nbsp;<br>2.如果进程很重要, 不能容忍任何时间范围内的服务不可用 (其实理论上这种情况属于单点瓶颈, 未能做到高可用), 则可以采用如下方式:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 将文件写空</span></span><br><span class=\"line\">sudo <span class=\"built_in\">echo</span> &gt; file_path</span><br></pre></td></tr></table></figure></p>\n<p>将文件内容间接删除, 这样即便句柄未释放, 但文件本身已经没有内容, 也就不再占用空间了;</p>\n<h2 id=\"站内相关文章\"><a href=\"#站内相关文章\" class=\"headerlink\" title=\"站内相关文章\"></a><strong>站内相关文章</strong></h2><ul>\n<li><a href=\"https://zshell-zhang.github.io/2018/01/15/linux-varlog--logrotate%E9%85%8D%E7%BD%AE%E4%B8%8E%E8%BF%90%E7%BB%B4/\">logrotate 配置与运维</a></li>\n<li><a href=\"https://zshell-zhang.github.io/2017/04/05/linux-process--linux_signals总体认识/#其他信号\">linux signals 总体认识#其他信号</a></li>\n<li><a href=\"\">nginx signals 处理</a></li>\n</ul>\n<h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a><strong>参考链接</strong></h2><ul>\n<li><a href=\"http://www.cnblogs.com/heyonggang/p/3644736.html\" target=\"_blank\" rel=\"noopener\">df和du显示的磁盘空间使用情况不一致的原因及处理</a></li>\n<li><a href=\"http://blog.csdn.net/guoguo1980/article/details/2324454\" target=\"_blank\" rel=\"noopener\">linux lsof 详解</a></li>\n</ul>"},{"title":"cli 控制字符","date":"2016-11-17T13:11:33.000Z","_content":"\n> cli 控制字符是终端操作中非常实用, 也极其频繁使用的快捷键; 使用得好可以加快敲命令的速度, 提升敲命令的准确性, 为工作带来极大便利; 同时, 这也是我们对 linux 爱不释手, 难以回到 windows 的原因之一;\n另外, 很多 cli 控制字符本质上是向 linux 或进程发送特定的信号, 关于 linux 信号的介绍, 本站有另外一篇文章: [linux signals 总体认识](https://zshell-zhang.github.io/2017/04/05/linux-process--linux_signals%E6%80%BB%E4%BD%93%E8%AE%A4%E8%AF%86/);\n本文总结一些常用的 cli 控制字符的使用及技巧;\n\n<!--more-->\n\n------\n\n### **简单的 cli 控制字符**\n``` bash\n# 发送 SIGINT 中断信号\nctrl + c\n# 清屏\nctrl + l\n# reverse-i-search 搜索历史命令\nctrl + r\n# 从机器上 logout\nctrl + d\n# 暂停控制台标准输出 / 恢复控制台标准输出\nctrl + s / ctrl + q\n# 发送 SIGQUIT 信号给前台进程, 并生成 core dump\nctrl + /\n# 向前删除到第一个空格\nctrl + w\n# 向后删除到第一个空格\n alt + d\n# 向后删除所有的内容\nctrl + k\n# 撤销上一步操作\nctrl + ?\n# 光标快速跃进\nctrl + 方向键\n# 补全命令/文件\ntab\n```\n\n### **与其他命令组合的 cli 控制字符 **\n``` bash\n# 发送 SIGTSTP 信号, 挂起前台进程\nctrl + z\n# ctrl + z 的输出\n[1]+  Stopped                 sudo vim /etc/profile\n```\n此时该前台进程被挂起, 操作系统将不会调度任何 cpu time 给此进程;\n接下来可以有以下配套操作:\n``` bash\n# 查看后台任务\n> jobs\n[1]+  Stopped                 sudo vim /etc/profile\n# 查看后台任务的 pid\njobs -p\n\n# 将后台作业 1 恢复到前台\nfg 1\nfg %1\n# 将后台作业 1 恢复到后台\nbg 1\nbg %1\n```\n要杀死被挂起的后台任务有一些麻烦, 因为该任务处于 suspend 状态, 无法主动响应 SIGTERM, SIGINT 等相对柔和的信号, 但可以被 SIGKILL 这种强力的信号直接杀死:\n``` bash\nkill -9 %1\nkill -9 `jobs -p`\n```\n还有一种比较讨巧的方法是结合 fg/bg 等唤醒后台任务的命令:\n``` bash\n# 当任务被唤醒, 将接收到 SIGTERM 信号并终止\nkill %1 && fg\nkill %1 && bg\nkill `jobs -p` && bg\nkill `jobs -p` && fg\n```\n\n### **控制字符的管理与设置**\n``` bash\n# 打印所有控制字符的设置 (--all)\n> stty -a\nspeed 38400 baud; rows 60; columns 211; line = 0;\nintr = ^C; quit = ^\\; erase = ^?; kill = ^U; eof = ^D; eol = <undef>; eol2 = <undef>; swtch = <undef>; start = ^Q; stop = ^S; susp = ^Z; rprnt = ^R; werase = ^W; lnext = ^V; flush = ^O; min = 1; time = 0;\n-parenb -parodd cs8 -hupcl -cstopb cread -clocal -crtscts -cdtrdsr\n-ignbrk -brkint -ignpar -parmrk -inpck -istrip -inlcr -igncr icrnl ixon -ixoff -iuclc -ixany -imaxbel -iutf8\nopost -olcuc -ocrnl onlcr -onocr -onlret -ofill -ofdel nl0 cr0 tab0 bs0 vt0 ff0\nisig icanon iexten echo echoe echok -echonl -noflsh -xcase -tostop -echoprt echoctl echoke\n```\n\n### **参考链接**\n- [Bg, Fg, &, Ctrl-Z – 5 Examples to Manage Unix Background Jobs](http://www.thegeekstuff.com/2010/05/unix-background-job/)\n- [Linux中 ctrl-c, ctrl-z, ctrl-d 区别](http://blog.csdn.net/mylizh/article/details/38385739)\n\n","source":"_posts/linux-other--cli控制字符.md","raw":"---\ntitle: cli 控制字符\ndate: 2016-11-17 21:11:33\ncategories:\n - linux\n - other\ntags:\n - cheat sheet\n---\n\n> cli 控制字符是终端操作中非常实用, 也极其频繁使用的快捷键; 使用得好可以加快敲命令的速度, 提升敲命令的准确性, 为工作带来极大便利; 同时, 这也是我们对 linux 爱不释手, 难以回到 windows 的原因之一;\n另外, 很多 cli 控制字符本质上是向 linux 或进程发送特定的信号, 关于 linux 信号的介绍, 本站有另外一篇文章: [linux signals 总体认识](https://zshell-zhang.github.io/2017/04/05/linux-process--linux_signals%E6%80%BB%E4%BD%93%E8%AE%A4%E8%AF%86/);\n本文总结一些常用的 cli 控制字符的使用及技巧;\n\n<!--more-->\n\n------\n\n### **简单的 cli 控制字符**\n``` bash\n# 发送 SIGINT 中断信号\nctrl + c\n# 清屏\nctrl + l\n# reverse-i-search 搜索历史命令\nctrl + r\n# 从机器上 logout\nctrl + d\n# 暂停控制台标准输出 / 恢复控制台标准输出\nctrl + s / ctrl + q\n# 发送 SIGQUIT 信号给前台进程, 并生成 core dump\nctrl + /\n# 向前删除到第一个空格\nctrl + w\n# 向后删除到第一个空格\n alt + d\n# 向后删除所有的内容\nctrl + k\n# 撤销上一步操作\nctrl + ?\n# 光标快速跃进\nctrl + 方向键\n# 补全命令/文件\ntab\n```\n\n### **与其他命令组合的 cli 控制字符 **\n``` bash\n# 发送 SIGTSTP 信号, 挂起前台进程\nctrl + z\n# ctrl + z 的输出\n[1]+  Stopped                 sudo vim /etc/profile\n```\n此时该前台进程被挂起, 操作系统将不会调度任何 cpu time 给此进程;\n接下来可以有以下配套操作:\n``` bash\n# 查看后台任务\n> jobs\n[1]+  Stopped                 sudo vim /etc/profile\n# 查看后台任务的 pid\njobs -p\n\n# 将后台作业 1 恢复到前台\nfg 1\nfg %1\n# 将后台作业 1 恢复到后台\nbg 1\nbg %1\n```\n要杀死被挂起的后台任务有一些麻烦, 因为该任务处于 suspend 状态, 无法主动响应 SIGTERM, SIGINT 等相对柔和的信号, 但可以被 SIGKILL 这种强力的信号直接杀死:\n``` bash\nkill -9 %1\nkill -9 `jobs -p`\n```\n还有一种比较讨巧的方法是结合 fg/bg 等唤醒后台任务的命令:\n``` bash\n# 当任务被唤醒, 将接收到 SIGTERM 信号并终止\nkill %1 && fg\nkill %1 && bg\nkill `jobs -p` && bg\nkill `jobs -p` && fg\n```\n\n### **控制字符的管理与设置**\n``` bash\n# 打印所有控制字符的设置 (--all)\n> stty -a\nspeed 38400 baud; rows 60; columns 211; line = 0;\nintr = ^C; quit = ^\\; erase = ^?; kill = ^U; eof = ^D; eol = <undef>; eol2 = <undef>; swtch = <undef>; start = ^Q; stop = ^S; susp = ^Z; rprnt = ^R; werase = ^W; lnext = ^V; flush = ^O; min = 1; time = 0;\n-parenb -parodd cs8 -hupcl -cstopb cread -clocal -crtscts -cdtrdsr\n-ignbrk -brkint -ignpar -parmrk -inpck -istrip -inlcr -igncr icrnl ixon -ixoff -iuclc -ixany -imaxbel -iutf8\nopost -olcuc -ocrnl onlcr -onocr -onlret -ofill -ofdel nl0 cr0 tab0 bs0 vt0 ff0\nisig icanon iexten echo echoe echok -echonl -noflsh -xcase -tostop -echoprt echoctl echoke\n```\n\n### **参考链接**\n- [Bg, Fg, &, Ctrl-Z – 5 Examples to Manage Unix Background Jobs](http://www.thegeekstuff.com/2010/05/unix-background-job/)\n- [Linux中 ctrl-c, ctrl-z, ctrl-d 区别](http://blog.csdn.net/mylizh/article/details/38385739)\n\n","slug":"linux-other--cli控制字符","published":1,"updated":"2018-01-07T13:13:21.679Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cje24mxtp0004j1jxrke44zon","content":"<blockquote>\n<p>cli 控制字符是终端操作中非常实用, 也极其频繁使用的快捷键; 使用得好可以加快敲命令的速度, 提升敲命令的准确性, 为工作带来极大便利; 同时, 这也是我们对 linux 爱不释手, 难以回到 windows 的原因之一;<br>另外, 很多 cli 控制字符本质上是向 linux 或进程发送特定的信号, 关于 linux 信号的介绍, 本站有另外一篇文章: <a href=\"https://zshell-zhang.github.io/2017/04/05/linux-process--linux_signals%E6%80%BB%E4%BD%93%E8%AE%A4%E8%AF%86/\">linux signals 总体认识</a>;<br>本文总结一些常用的 cli 控制字符的使用及技巧;</p>\n</blockquote>\n<a id=\"more\"></a>\n<hr>\n<h3 id=\"简单的-cli-控制字符\"><a href=\"#简单的-cli-控制字符\" class=\"headerlink\" title=\"简单的 cli 控制字符\"></a><strong>简单的 cli 控制字符</strong></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 发送 SIGINT 中断信号</span></span><br><span class=\"line\">ctrl + c</span><br><span class=\"line\"><span class=\"comment\"># 清屏</span></span><br><span class=\"line\">ctrl + l</span><br><span class=\"line\"><span class=\"comment\"># reverse-i-search 搜索历史命令</span></span><br><span class=\"line\">ctrl + r</span><br><span class=\"line\"><span class=\"comment\"># 从机器上 logout</span></span><br><span class=\"line\">ctrl + d</span><br><span class=\"line\"><span class=\"comment\"># 暂停控制台标准输出 / 恢复控制台标准输出</span></span><br><span class=\"line\">ctrl + s / ctrl + q</span><br><span class=\"line\"><span class=\"comment\"># 发送 SIGQUIT 信号给前台进程, 并生成 core dump</span></span><br><span class=\"line\">ctrl + /</span><br><span class=\"line\"><span class=\"comment\"># 向前删除到第一个空格</span></span><br><span class=\"line\">ctrl + w</span><br><span class=\"line\"><span class=\"comment\"># 向后删除到第一个空格</span></span><br><span class=\"line\"> alt + d</span><br><span class=\"line\"><span class=\"comment\"># 向后删除所有的内容</span></span><br><span class=\"line\">ctrl + k</span><br><span class=\"line\"><span class=\"comment\"># 撤销上一步操作</span></span><br><span class=\"line\">ctrl + ?</span><br><span class=\"line\"><span class=\"comment\"># 光标快速跃进</span></span><br><span class=\"line\">ctrl + 方向键</span><br><span class=\"line\"><span class=\"comment\"># 补全命令/文件</span></span><br><span class=\"line\">tab</span><br></pre></td></tr></table></figure>\n<h3 id=\"与其他命令组合的-cli-控制字符\"><a href=\"#与其他命令组合的-cli-控制字符\" class=\"headerlink\" title=\"与其他命令组合的 cli 控制字符 \"></a><strong>与其他命令组合的 cli 控制字符 </strong></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 发送 SIGTSTP 信号, 挂起前台进程</span></span><br><span class=\"line\">ctrl + z</span><br><span class=\"line\"><span class=\"comment\"># ctrl + z 的输出</span></span><br><span class=\"line\">[1]+  Stopped                 sudo vim /etc/profile</span><br></pre></td></tr></table></figure>\n<p>此时该前台进程被挂起, 操作系统将不会调度任何 cpu time 给此进程;<br>接下来可以有以下配套操作:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 查看后台任务</span></span><br><span class=\"line\">&gt; <span class=\"built_in\">jobs</span></span><br><span class=\"line\">[1]+  Stopped                 sudo vim /etc/profile</span><br><span class=\"line\"><span class=\"comment\"># 查看后台任务的 pid</span></span><br><span class=\"line\"><span class=\"built_in\">jobs</span> -p</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 将后台作业 1 恢复到前台</span></span><br><span class=\"line\"><span class=\"built_in\">fg</span> 1</span><br><span class=\"line\"><span class=\"built_in\">fg</span> %1</span><br><span class=\"line\"><span class=\"comment\"># 将后台作业 1 恢复到后台</span></span><br><span class=\"line\"><span class=\"built_in\">bg</span> 1</span><br><span class=\"line\"><span class=\"built_in\">bg</span> %1</span><br></pre></td></tr></table></figure></p>\n<p>要杀死被挂起的后台任务有一些麻烦, 因为该任务处于 suspend 状态, 无法主动响应 SIGTERM, SIGINT 等相对柔和的信号, 但可以被 SIGKILL 这种强力的信号直接杀死:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">kill</span> -9 %1</span><br><span class=\"line\"><span class=\"built_in\">kill</span> -9 `<span class=\"built_in\">jobs</span> -p`</span><br></pre></td></tr></table></figure></p>\n<p>还有一种比较讨巧的方法是结合 fg/bg 等唤醒后台任务的命令:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 当任务被唤醒, 将接收到 SIGTERM 信号并终止</span></span><br><span class=\"line\"><span class=\"built_in\">kill</span> %1 &amp;&amp; <span class=\"built_in\">fg</span></span><br><span class=\"line\"><span class=\"built_in\">kill</span> %1 &amp;&amp; <span class=\"built_in\">bg</span></span><br><span class=\"line\"><span class=\"built_in\">kill</span> `<span class=\"built_in\">jobs</span> -p` &amp;&amp; <span class=\"built_in\">bg</span></span><br><span class=\"line\"><span class=\"built_in\">kill</span> `<span class=\"built_in\">jobs</span> -p` &amp;&amp; <span class=\"built_in\">fg</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"控制字符的管理与设置\"><a href=\"#控制字符的管理与设置\" class=\"headerlink\" title=\"控制字符的管理与设置\"></a><strong>控制字符的管理与设置</strong></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 打印所有控制字符的设置 (--all)</span></span><br><span class=\"line\">&gt; stty -a</span><br><span class=\"line\">speed 38400 baud; rows 60; columns 211; line = 0;</span><br><span class=\"line\">intr = ^C; quit = ^\\; erase = ^?; <span class=\"built_in\">kill</span> = ^U; eof = ^D; eol = &lt;undef&gt;; eol2 = &lt;undef&gt;; swtch = &lt;undef&gt;; start = ^Q; stop = ^S; susp = ^Z; rprnt = ^R; werase = ^W; lnext = ^V; flush = ^O; min = 1; time = 0;</span><br><span class=\"line\">-parenb -parodd cs8 -hupcl -cstopb cread -clocal -crtscts -cdtrdsr</span><br><span class=\"line\">-ignbrk -brkint -ignpar -parmrk -inpck -istrip -inlcr -igncr icrnl ixon -ixoff -iuclc -ixany -imaxbel -iutf8</span><br><span class=\"line\">opost -olcuc -ocrnl onlcr -onocr -onlret -ofill -ofdel nl0 cr0 tab0 bs0 vt0 ff0</span><br><span class=\"line\">isig icanon iexten <span class=\"built_in\">echo</span> echoe echok -echonl -noflsh -xcase -tostop -echoprt echoctl echoke</span><br></pre></td></tr></table></figure>\n<h3 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a><strong>参考链接</strong></h3><ul>\n<li><a href=\"http://www.thegeekstuff.com/2010/05/unix-background-job/\" target=\"_blank\" rel=\"noopener\">Bg, Fg, &amp;, Ctrl-Z – 5 Examples to Manage Unix Background Jobs</a></li>\n<li><a href=\"http://blog.csdn.net/mylizh/article/details/38385739\" target=\"_blank\" rel=\"noopener\">Linux中 ctrl-c, ctrl-z, ctrl-d 区别</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>cli 控制字符是终端操作中非常实用, 也极其频繁使用的快捷键; 使用得好可以加快敲命令的速度, 提升敲命令的准确性, 为工作带来极大便利; 同时, 这也是我们对 linux 爱不释手, 难以回到 windows 的原因之一;<br>另外, 很多 cli 控制字符本质上是向 linux 或进程发送特定的信号, 关于 linux 信号的介绍, 本站有另外一篇文章: <a href=\"https://zshell-zhang.github.io/2017/04/05/linux-process--linux_signals%E6%80%BB%E4%BD%93%E8%AE%A4%E8%AF%86/\">linux signals 总体认识</a>;<br>本文总结一些常用的 cli 控制字符的使用及技巧;</p>\n</blockquote>","more":"<hr>\n<h3 id=\"简单的-cli-控制字符\"><a href=\"#简单的-cli-控制字符\" class=\"headerlink\" title=\"简单的 cli 控制字符\"></a><strong>简单的 cli 控制字符</strong></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 发送 SIGINT 中断信号</span></span><br><span class=\"line\">ctrl + c</span><br><span class=\"line\"><span class=\"comment\"># 清屏</span></span><br><span class=\"line\">ctrl + l</span><br><span class=\"line\"><span class=\"comment\"># reverse-i-search 搜索历史命令</span></span><br><span class=\"line\">ctrl + r</span><br><span class=\"line\"><span class=\"comment\"># 从机器上 logout</span></span><br><span class=\"line\">ctrl + d</span><br><span class=\"line\"><span class=\"comment\"># 暂停控制台标准输出 / 恢复控制台标准输出</span></span><br><span class=\"line\">ctrl + s / ctrl + q</span><br><span class=\"line\"><span class=\"comment\"># 发送 SIGQUIT 信号给前台进程, 并生成 core dump</span></span><br><span class=\"line\">ctrl + /</span><br><span class=\"line\"><span class=\"comment\"># 向前删除到第一个空格</span></span><br><span class=\"line\">ctrl + w</span><br><span class=\"line\"><span class=\"comment\"># 向后删除到第一个空格</span></span><br><span class=\"line\"> alt + d</span><br><span class=\"line\"><span class=\"comment\"># 向后删除所有的内容</span></span><br><span class=\"line\">ctrl + k</span><br><span class=\"line\"><span class=\"comment\"># 撤销上一步操作</span></span><br><span class=\"line\">ctrl + ?</span><br><span class=\"line\"><span class=\"comment\"># 光标快速跃进</span></span><br><span class=\"line\">ctrl + 方向键</span><br><span class=\"line\"><span class=\"comment\"># 补全命令/文件</span></span><br><span class=\"line\">tab</span><br></pre></td></tr></table></figure>\n<h3 id=\"与其他命令组合的-cli-控制字符\"><a href=\"#与其他命令组合的-cli-控制字符\" class=\"headerlink\" title=\"与其他命令组合的 cli 控制字符 \"></a><strong>与其他命令组合的 cli 控制字符 </strong></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 发送 SIGTSTP 信号, 挂起前台进程</span></span><br><span class=\"line\">ctrl + z</span><br><span class=\"line\"><span class=\"comment\"># ctrl + z 的输出</span></span><br><span class=\"line\">[1]+  Stopped                 sudo vim /etc/profile</span><br></pre></td></tr></table></figure>\n<p>此时该前台进程被挂起, 操作系统将不会调度任何 cpu time 给此进程;<br>接下来可以有以下配套操作:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 查看后台任务</span></span><br><span class=\"line\">&gt; <span class=\"built_in\">jobs</span></span><br><span class=\"line\">[1]+  Stopped                 sudo vim /etc/profile</span><br><span class=\"line\"><span class=\"comment\"># 查看后台任务的 pid</span></span><br><span class=\"line\"><span class=\"built_in\">jobs</span> -p</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 将后台作业 1 恢复到前台</span></span><br><span class=\"line\"><span class=\"built_in\">fg</span> 1</span><br><span class=\"line\"><span class=\"built_in\">fg</span> %1</span><br><span class=\"line\"><span class=\"comment\"># 将后台作业 1 恢复到后台</span></span><br><span class=\"line\"><span class=\"built_in\">bg</span> 1</span><br><span class=\"line\"><span class=\"built_in\">bg</span> %1</span><br></pre></td></tr></table></figure></p>\n<p>要杀死被挂起的后台任务有一些麻烦, 因为该任务处于 suspend 状态, 无法主动响应 SIGTERM, SIGINT 等相对柔和的信号, 但可以被 SIGKILL 这种强力的信号直接杀死:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">kill</span> -9 %1</span><br><span class=\"line\"><span class=\"built_in\">kill</span> -9 `<span class=\"built_in\">jobs</span> -p`</span><br></pre></td></tr></table></figure></p>\n<p>还有一种比较讨巧的方法是结合 fg/bg 等唤醒后台任务的命令:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 当任务被唤醒, 将接收到 SIGTERM 信号并终止</span></span><br><span class=\"line\"><span class=\"built_in\">kill</span> %1 &amp;&amp; <span class=\"built_in\">fg</span></span><br><span class=\"line\"><span class=\"built_in\">kill</span> %1 &amp;&amp; <span class=\"built_in\">bg</span></span><br><span class=\"line\"><span class=\"built_in\">kill</span> `<span class=\"built_in\">jobs</span> -p` &amp;&amp; <span class=\"built_in\">bg</span></span><br><span class=\"line\"><span class=\"built_in\">kill</span> `<span class=\"built_in\">jobs</span> -p` &amp;&amp; <span class=\"built_in\">fg</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"控制字符的管理与设置\"><a href=\"#控制字符的管理与设置\" class=\"headerlink\" title=\"控制字符的管理与设置\"></a><strong>控制字符的管理与设置</strong></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 打印所有控制字符的设置 (--all)</span></span><br><span class=\"line\">&gt; stty -a</span><br><span class=\"line\">speed 38400 baud; rows 60; columns 211; line = 0;</span><br><span class=\"line\">intr = ^C; quit = ^\\; erase = ^?; <span class=\"built_in\">kill</span> = ^U; eof = ^D; eol = &lt;undef&gt;; eol2 = &lt;undef&gt;; swtch = &lt;undef&gt;; start = ^Q; stop = ^S; susp = ^Z; rprnt = ^R; werase = ^W; lnext = ^V; flush = ^O; min = 1; time = 0;</span><br><span class=\"line\">-parenb -parodd cs8 -hupcl -cstopb cread -clocal -crtscts -cdtrdsr</span><br><span class=\"line\">-ignbrk -brkint -ignpar -parmrk -inpck -istrip -inlcr -igncr icrnl ixon -ixoff -iuclc -ixany -imaxbel -iutf8</span><br><span class=\"line\">opost -olcuc -ocrnl onlcr -onocr -onlret -ofill -ofdel nl0 cr0 tab0 bs0 vt0 ff0</span><br><span class=\"line\">isig icanon iexten <span class=\"built_in\">echo</span> echoe echok -echonl -noflsh -xcase -tostop -echoprt echoctl echoke</span><br></pre></td></tr></table></figure>\n<h3 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a><strong>参考链接</strong></h3><ul>\n<li><a href=\"http://www.thegeekstuff.com/2010/05/unix-background-job/\" target=\"_blank\" rel=\"noopener\">Bg, Fg, &amp;, Ctrl-Z – 5 Examples to Manage Unix Background Jobs</a></li>\n<li><a href=\"http://blog.csdn.net/mylizh/article/details/38385739\" target=\"_blank\" rel=\"noopener\">Linux中 ctrl-c, ctrl-z, ctrl-d 区别</a></li>\n</ul>"},{"title":"lsof 札记","date":"2017-01-06T07:17:04.000Z","_content":"\n> 第一次接触到 lsof 命令, 是因为偶然间发现 netstat 命令已经落伍了(与此同时, 还发现了 ss 命令, 详见另一篇文章: [netstat/ss 使用对比]() );\n使用之后, 发现 lsof 被人称为 `神器`, 还是有一定道理的; 在任何资源都被抽象为 `文件` 的 linux 中, 一个面向 `文件` 的管理工具, 自然辖域辽阔, 神通广大, 再加上与其他命令的巧妙组合, 更如虎添翼, 在工作实践中独当一面;\n本文参考了一些实用资料, 结合自己的经验, 对 lsof 命令的使用略作整理;\n\n<!--more-->\n\n------\n\n## **lsof 命令的输出结构**\n``` bash\n# COMMAND   启动进程的命令\n# PID       进程号\n# TID       线程号\n# USER      用户\n# FD        文件描述符\n# TYPE      文件类型\n# DEVICE    磁盘名称\n# SIZE      文件大小\n# NODE      inode 号\n# NAME      文件资源的名称\n> sudo lsof | head -n 2\nCOMMAND     PID   TID      USER   FD      TYPE             DEVICE    SIZE/OFF       NODE NAME\nsystemd       1            root  cwd       DIR              253,1        4096        128 /\n```\n\n### **各字段的不同输出含义**\nFD: 文件描述符 file description\n``` bash\n# 任何进程都必须有的\n0:      标准输入流\n1:      标准输出流\n2:      标准错误流\n\n# 几种特殊的保留 fd\ncwd:    current work directory, 应用程序启动的目录\ntxt:    二进制可执行文件或共享库\nrtd:    root directory, 根目录\nmem:    memory mapped file, 内存映射文件\nmmap:   memory-mapped device, 内存映射设备\n\n# 整数后面跟着的字母\nu:      可读可写模式\nr:      只读模式\nw:      只写模式\n```\nTYPE: 文件类型\n``` bash\nDIR:    目录文件\nREG:    普通文件\nCHR:    char, 字符设备文件\nBLK:    block, 块设备文件\nIPV4:   ipv4 socket 套接字文件\nIPV6:   ipv6 socket 套接字文件\n```\nDEVICE:\n``` bash\ntodo\n```\nSIZE: 文件大小\n``` bash\n# 套接字文件的文件大小比较特殊, 其没有大小, 用特殊字符占位, 其余则正常显示 size\n0t0:    套接字文件的默认占位\n```\n&nbsp;\n## **lsof 的日常应用**\n### **lsof 网络 相关的应用**\n``` bash\n# 显示所有网络连接\nsudo lsof -i\n# 只显示 ipv6 的连接\nsudo lsof -i 6\n# 只显示 tcp 协议的连接\nsudo lsof -i TCP\n# 指定端口号\nsudo lsof -i:port\n# 指定主机(与端口)\nsudo lsof -i@l-tracer15.tc.cn2.xx.com:9999\n```\n\n### **lsof 用户 相关的应用**\n``` bash\n# 显示某用户所打开的文件\nsudo lsof -u zshell.zhang\nsudo lsof -u ^zshell.zhang (排除此用户)\n```\n\n### **lsof 命令/进程 相关的应用**\n``` bash\n# 只显示 pid\nsudo lsof -t\n# 只显示指定的命令打开的文件\nsudo lsof -c nginx\n# 只显示指定 pid 的进程打开的文件\nsudo lsof -p pid\n```\n\n### **lsof 文件/目录 相关的应用**\n``` bash\n# 搜索与指定路径相关的一切资源(user, process 等)\nsudo lsof /target_path\n# +d: 搜索与指定的一级目录下所有的文件相关的一切资源; +D: 递归操作(往下所有层级目录)\nsudo lsof +d /target_path\nsudo lsof +D /target_path\n```\n\n### **lsof 的选项组合及实践技巧**\n上述的 lsof 操作, 对于多种选项的组合, 其默认是 或(or) 的关系, 即满足其中之一便会打印出来;\nlsof 与(and) 的逻辑运算关系如下:\n``` bash\n# 使用 -a 达到 与(and) 的效果\n# 必须同时满足三个条件: \n#   1. 是用户 zshell.zhang 启动的进程;\n#   2. 是套接字文件, 且连接的主机是 10.64.4.11;\n#   3. 该进程命令是 java;\nsudo lsof -a -u zshell.zhang -i@10.64.4.11 -c java\n```\nlsof 常用的组合及实践:\n``` bash\n# 寻找已删除但未释放文件句柄的幽灵文件\nsudo lsof | grep deleted\n# 杀死所有匹配一定文件打开条件的进程\nsudo kill `sudo lsof -t -c java` # 杀死所有 java 进程\nsudo kill `sudo lsof -t -u zshell.zhang` # 杀死所有 zshell.zhang 的用户进程\n# 恢复删除的文件\n# 找到误删文件被什么进程持有, 获得 pid 和 fd\n1. sudo lsof /target_deleted_file\n# /proc/{pid}/fd/{fd_num} 的内容即为误删内容, 重定向到误删文件中即可\n2. cat /proc/{pid}/fd/{fd_num} > /target_deleted_file\n```\n另外, lsof 还可以被运用于找出系统中的幽灵文件, 详见: [du / df 使用及其区别](https://zshell-zhang.github.io/2017/04/07/linux-other--du,df使用及其区别/);\n\n## **站内相关文章**\n- [netstat/ss 使用对比]()\n- [du / df 使用及其区别](https://zshell-zhang.github.io/2017/04/07/linux-other--du,df使用及其区别/)\n\n## **参考链接**\n- [linux lsof详解](http://blog.csdn.net/guoguo1980/article/details/2324454)\n- [每天一个Linux命令（45）lsof命令](http://www.cnblogs.com/MenAngel/p/5575479.html)\n- [Linux 命令神器: lsof 入门](https://linux.cn/article-4099-1.html)\n- [what-does-the-fd-column-of-pipes-listed-by-lsof-mean](https://stackoverflow.com/questions/25140730/what-does-the-fd-column-of-pipes-listed-by-lsof-mean)\n\n","source":"_posts/linux-other--lsof札记.md","raw":"---\ntitle: lsof 札记\ndate: 2017-01-06 15:17:04\ncategories:\n  - linux\n  - other\ntags:\n  - linux:net\n  - linux:disk\n---\n\n> 第一次接触到 lsof 命令, 是因为偶然间发现 netstat 命令已经落伍了(与此同时, 还发现了 ss 命令, 详见另一篇文章: [netstat/ss 使用对比]() );\n使用之后, 发现 lsof 被人称为 `神器`, 还是有一定道理的; 在任何资源都被抽象为 `文件` 的 linux 中, 一个面向 `文件` 的管理工具, 自然辖域辽阔, 神通广大, 再加上与其他命令的巧妙组合, 更如虎添翼, 在工作实践中独当一面;\n本文参考了一些实用资料, 结合自己的经验, 对 lsof 命令的使用略作整理;\n\n<!--more-->\n\n------\n\n## **lsof 命令的输出结构**\n``` bash\n# COMMAND   启动进程的命令\n# PID       进程号\n# TID       线程号\n# USER      用户\n# FD        文件描述符\n# TYPE      文件类型\n# DEVICE    磁盘名称\n# SIZE      文件大小\n# NODE      inode 号\n# NAME      文件资源的名称\n> sudo lsof | head -n 2\nCOMMAND     PID   TID      USER   FD      TYPE             DEVICE    SIZE/OFF       NODE NAME\nsystemd       1            root  cwd       DIR              253,1        4096        128 /\n```\n\n### **各字段的不同输出含义**\nFD: 文件描述符 file description\n``` bash\n# 任何进程都必须有的\n0:      标准输入流\n1:      标准输出流\n2:      标准错误流\n\n# 几种特殊的保留 fd\ncwd:    current work directory, 应用程序启动的目录\ntxt:    二进制可执行文件或共享库\nrtd:    root directory, 根目录\nmem:    memory mapped file, 内存映射文件\nmmap:   memory-mapped device, 内存映射设备\n\n# 整数后面跟着的字母\nu:      可读可写模式\nr:      只读模式\nw:      只写模式\n```\nTYPE: 文件类型\n``` bash\nDIR:    目录文件\nREG:    普通文件\nCHR:    char, 字符设备文件\nBLK:    block, 块设备文件\nIPV4:   ipv4 socket 套接字文件\nIPV6:   ipv6 socket 套接字文件\n```\nDEVICE:\n``` bash\ntodo\n```\nSIZE: 文件大小\n``` bash\n# 套接字文件的文件大小比较特殊, 其没有大小, 用特殊字符占位, 其余则正常显示 size\n0t0:    套接字文件的默认占位\n```\n&nbsp;\n## **lsof 的日常应用**\n### **lsof 网络 相关的应用**\n``` bash\n# 显示所有网络连接\nsudo lsof -i\n# 只显示 ipv6 的连接\nsudo lsof -i 6\n# 只显示 tcp 协议的连接\nsudo lsof -i TCP\n# 指定端口号\nsudo lsof -i:port\n# 指定主机(与端口)\nsudo lsof -i@l-tracer15.tc.cn2.xx.com:9999\n```\n\n### **lsof 用户 相关的应用**\n``` bash\n# 显示某用户所打开的文件\nsudo lsof -u zshell.zhang\nsudo lsof -u ^zshell.zhang (排除此用户)\n```\n\n### **lsof 命令/进程 相关的应用**\n``` bash\n# 只显示 pid\nsudo lsof -t\n# 只显示指定的命令打开的文件\nsudo lsof -c nginx\n# 只显示指定 pid 的进程打开的文件\nsudo lsof -p pid\n```\n\n### **lsof 文件/目录 相关的应用**\n``` bash\n# 搜索与指定路径相关的一切资源(user, process 等)\nsudo lsof /target_path\n# +d: 搜索与指定的一级目录下所有的文件相关的一切资源; +D: 递归操作(往下所有层级目录)\nsudo lsof +d /target_path\nsudo lsof +D /target_path\n```\n\n### **lsof 的选项组合及实践技巧**\n上述的 lsof 操作, 对于多种选项的组合, 其默认是 或(or) 的关系, 即满足其中之一便会打印出来;\nlsof 与(and) 的逻辑运算关系如下:\n``` bash\n# 使用 -a 达到 与(and) 的效果\n# 必须同时满足三个条件: \n#   1. 是用户 zshell.zhang 启动的进程;\n#   2. 是套接字文件, 且连接的主机是 10.64.4.11;\n#   3. 该进程命令是 java;\nsudo lsof -a -u zshell.zhang -i@10.64.4.11 -c java\n```\nlsof 常用的组合及实践:\n``` bash\n# 寻找已删除但未释放文件句柄的幽灵文件\nsudo lsof | grep deleted\n# 杀死所有匹配一定文件打开条件的进程\nsudo kill `sudo lsof -t -c java` # 杀死所有 java 进程\nsudo kill `sudo lsof -t -u zshell.zhang` # 杀死所有 zshell.zhang 的用户进程\n# 恢复删除的文件\n# 找到误删文件被什么进程持有, 获得 pid 和 fd\n1. sudo lsof /target_deleted_file\n# /proc/{pid}/fd/{fd_num} 的内容即为误删内容, 重定向到误删文件中即可\n2. cat /proc/{pid}/fd/{fd_num} > /target_deleted_file\n```\n另外, lsof 还可以被运用于找出系统中的幽灵文件, 详见: [du / df 使用及其区别](https://zshell-zhang.github.io/2017/04/07/linux-other--du,df使用及其区别/);\n\n## **站内相关文章**\n- [netstat/ss 使用对比]()\n- [du / df 使用及其区别](https://zshell-zhang.github.io/2017/04/07/linux-other--du,df使用及其区别/)\n\n## **参考链接**\n- [linux lsof详解](http://blog.csdn.net/guoguo1980/article/details/2324454)\n- [每天一个Linux命令（45）lsof命令](http://www.cnblogs.com/MenAngel/p/5575479.html)\n- [Linux 命令神器: lsof 入门](https://linux.cn/article-4099-1.html)\n- [what-does-the-fd-column-of-pipes-listed-by-lsof-mean](https://stackoverflow.com/questions/25140730/what-does-the-fd-column-of-pipes-listed-by-lsof-mean)\n\n","slug":"linux-other--lsof札记","published":1,"updated":"2018-01-20T13:26:42.069Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cje24mxtr0005j1jxx2uwlh9n","content":"<blockquote>\n<p>第一次接触到 lsof 命令, 是因为偶然间发现 netstat 命令已经落伍了(与此同时, 还发现了 ss 命令, 详见另一篇文章: <a href=\"\">netstat/ss 使用对比</a> );<br>使用之后, 发现 lsof 被人称为 <code>神器</code>, 还是有一定道理的; 在任何资源都被抽象为 <code>文件</code> 的 linux 中, 一个面向 <code>文件</code> 的管理工具, 自然辖域辽阔, 神通广大, 再加上与其他命令的巧妙组合, 更如虎添翼, 在工作实践中独当一面;<br>本文参考了一些实用资料, 结合自己的经验, 对 lsof 命令的使用略作整理;</p>\n</blockquote>\n<a id=\"more\"></a>\n<hr>\n<h2 id=\"lsof-命令的输出结构\"><a href=\"#lsof-命令的输出结构\" class=\"headerlink\" title=\"lsof 命令的输出结构\"></a><strong>lsof 命令的输出结构</strong></h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># COMMAND   启动进程的命令</span></span><br><span class=\"line\"><span class=\"comment\"># PID       进程号</span></span><br><span class=\"line\"><span class=\"comment\"># TID       线程号</span></span><br><span class=\"line\"><span class=\"comment\"># USER      用户</span></span><br><span class=\"line\"><span class=\"comment\"># FD        文件描述符</span></span><br><span class=\"line\"><span class=\"comment\"># TYPE      文件类型</span></span><br><span class=\"line\"><span class=\"comment\"># DEVICE    磁盘名称</span></span><br><span class=\"line\"><span class=\"comment\"># SIZE      文件大小</span></span><br><span class=\"line\"><span class=\"comment\"># NODE      inode 号</span></span><br><span class=\"line\"><span class=\"comment\"># NAME      文件资源的名称</span></span><br><span class=\"line\">&gt; sudo lsof | head -n 2</span><br><span class=\"line\">COMMAND     PID   TID      USER   FD      TYPE             DEVICE    SIZE/OFF       NODE NAME</span><br><span class=\"line\">systemd       1            root  cwd       DIR              253,1        4096        128 /</span><br></pre></td></tr></table></figure>\n<h3 id=\"各字段的不同输出含义\"><a href=\"#各字段的不同输出含义\" class=\"headerlink\" title=\"各字段的不同输出含义\"></a><strong>各字段的不同输出含义</strong></h3><p>FD: 文件描述符 file description<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 任何进程都必须有的</span></span><br><span class=\"line\">0:      标准输入流</span><br><span class=\"line\">1:      标准输出流</span><br><span class=\"line\">2:      标准错误流</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 几种特殊的保留 fd</span></span><br><span class=\"line\">cwd:    current work directory, 应用程序启动的目录</span><br><span class=\"line\">txt:    二进制可执行文件或共享库</span><br><span class=\"line\">rtd:    root directory, 根目录</span><br><span class=\"line\">mem:    memory mapped file, 内存映射文件</span><br><span class=\"line\">mmap:   memory-mapped device, 内存映射设备</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 整数后面跟着的字母</span></span><br><span class=\"line\">u:      可读可写模式</span><br><span class=\"line\">r:      只读模式</span><br><span class=\"line\">w:      只写模式</span><br></pre></td></tr></table></figure></p>\n<p>TYPE: 文件类型<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DIR:    目录文件</span><br><span class=\"line\">REG:    普通文件</span><br><span class=\"line\">CHR:    char, 字符设备文件</span><br><span class=\"line\">BLK:    block, 块设备文件</span><br><span class=\"line\">IPV4:   ipv4 socket 套接字文件</span><br><span class=\"line\">IPV6:   ipv6 socket 套接字文件</span><br></pre></td></tr></table></figure></p>\n<p>DEVICE:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">todo</span><br></pre></td></tr></table></figure></p>\n<p>SIZE: 文件大小<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 套接字文件的文件大小比较特殊, 其没有大小, 用特殊字符占位, 其余则正常显示 size</span></span><br><span class=\"line\">0t0:    套接字文件的默认占位</span><br></pre></td></tr></table></figure></p>\n<p>&nbsp;</p>\n<h2 id=\"lsof-的日常应用\"><a href=\"#lsof-的日常应用\" class=\"headerlink\" title=\"lsof 的日常应用\"></a><strong>lsof 的日常应用</strong></h2><h3 id=\"lsof-网络-相关的应用\"><a href=\"#lsof-网络-相关的应用\" class=\"headerlink\" title=\"lsof 网络 相关的应用\"></a><strong>lsof 网络 相关的应用</strong></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 显示所有网络连接</span></span><br><span class=\"line\">sudo lsof -i</span><br><span class=\"line\"><span class=\"comment\"># 只显示 ipv6 的连接</span></span><br><span class=\"line\">sudo lsof -i 6</span><br><span class=\"line\"><span class=\"comment\"># 只显示 tcp 协议的连接</span></span><br><span class=\"line\">sudo lsof -i TCP</span><br><span class=\"line\"><span class=\"comment\"># 指定端口号</span></span><br><span class=\"line\">sudo lsof -i:port</span><br><span class=\"line\"><span class=\"comment\"># 指定主机(与端口)</span></span><br><span class=\"line\">sudo lsof -i@l-tracer15.tc.cn2.xx.com:9999</span><br></pre></td></tr></table></figure>\n<h3 id=\"lsof-用户-相关的应用\"><a href=\"#lsof-用户-相关的应用\" class=\"headerlink\" title=\"lsof 用户 相关的应用\"></a><strong>lsof 用户 相关的应用</strong></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 显示某用户所打开的文件</span></span><br><span class=\"line\">sudo lsof -u zshell.zhang</span><br><span class=\"line\">sudo lsof -u ^zshell.zhang (排除此用户)</span><br></pre></td></tr></table></figure>\n<h3 id=\"lsof-命令-进程-相关的应用\"><a href=\"#lsof-命令-进程-相关的应用\" class=\"headerlink\" title=\"lsof 命令/进程 相关的应用\"></a><strong>lsof 命令/进程 相关的应用</strong></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 只显示 pid</span></span><br><span class=\"line\">sudo lsof -t</span><br><span class=\"line\"><span class=\"comment\"># 只显示指定的命令打开的文件</span></span><br><span class=\"line\">sudo lsof -c nginx</span><br><span class=\"line\"><span class=\"comment\"># 只显示指定 pid 的进程打开的文件</span></span><br><span class=\"line\">sudo lsof -p pid</span><br></pre></td></tr></table></figure>\n<h3 id=\"lsof-文件-目录-相关的应用\"><a href=\"#lsof-文件-目录-相关的应用\" class=\"headerlink\" title=\"lsof 文件/目录 相关的应用\"></a><strong>lsof 文件/目录 相关的应用</strong></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 搜索与指定路径相关的一切资源(user, process 等)</span></span><br><span class=\"line\">sudo lsof /target_path</span><br><span class=\"line\"><span class=\"comment\"># +d: 搜索与指定的一级目录下所有的文件相关的一切资源; +D: 递归操作(往下所有层级目录)</span></span><br><span class=\"line\">sudo lsof +d /target_path</span><br><span class=\"line\">sudo lsof +D /target_path</span><br></pre></td></tr></table></figure>\n<h3 id=\"lsof-的选项组合及实践技巧\"><a href=\"#lsof-的选项组合及实践技巧\" class=\"headerlink\" title=\"lsof 的选项组合及实践技巧\"></a><strong>lsof 的选项组合及实践技巧</strong></h3><p>上述的 lsof 操作, 对于多种选项的组合, 其默认是 或(or) 的关系, 即满足其中之一便会打印出来;<br>lsof 与(and) 的逻辑运算关系如下:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 使用 -a 达到 与(and) 的效果</span></span><br><span class=\"line\"><span class=\"comment\"># 必须同时满足三个条件: </span></span><br><span class=\"line\"><span class=\"comment\">#   1. 是用户 zshell.zhang 启动的进程;</span></span><br><span class=\"line\"><span class=\"comment\">#   2. 是套接字文件, 且连接的主机是 10.64.4.11;</span></span><br><span class=\"line\"><span class=\"comment\">#   3. 该进程命令是 java;</span></span><br><span class=\"line\">sudo lsof -a -u zshell.zhang -i@10.64.4.11 -c java</span><br></pre></td></tr></table></figure></p>\n<p>lsof 常用的组合及实践:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 寻找已删除但未释放文件句柄的幽灵文件</span></span><br><span class=\"line\">sudo lsof | grep deleted</span><br><span class=\"line\"><span class=\"comment\"># 杀死所有匹配一定文件打开条件的进程</span></span><br><span class=\"line\">sudo <span class=\"built_in\">kill</span> `sudo lsof -t -c java` <span class=\"comment\"># 杀死所有 java 进程</span></span><br><span class=\"line\">sudo <span class=\"built_in\">kill</span> `sudo lsof -t -u zshell.zhang` <span class=\"comment\"># 杀死所有 zshell.zhang 的用户进程</span></span><br><span class=\"line\"><span class=\"comment\"># 恢复删除的文件</span></span><br><span class=\"line\"><span class=\"comment\"># 找到误删文件被什么进程持有, 获得 pid 和 fd</span></span><br><span class=\"line\">1. sudo lsof /target_deleted_file</span><br><span class=\"line\"><span class=\"comment\"># /proc/&#123;pid&#125;/fd/&#123;fd_num&#125; 的内容即为误删内容, 重定向到误删文件中即可</span></span><br><span class=\"line\">2. cat /proc/&#123;pid&#125;/fd/&#123;fd_num&#125; &gt; /target_deleted_file</span><br></pre></td></tr></table></figure></p>\n<p>另外, lsof 还可以被运用于找出系统中的幽灵文件, 详见: <a href=\"https://zshell-zhang.github.io/2017/04/07/linux-other--du,df使用及其区别/\">du / df 使用及其区别</a>;</p>\n<h2 id=\"站内相关文章\"><a href=\"#站内相关文章\" class=\"headerlink\" title=\"站内相关文章\"></a><strong>站内相关文章</strong></h2><ul>\n<li><a href=\"\">netstat/ss 使用对比</a></li>\n<li><a href=\"https://zshell-zhang.github.io/2017/04/07/linux-other--du,df使用及其区别/\">du / df 使用及其区别</a></li>\n</ul>\n<h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a><strong>参考链接</strong></h2><ul>\n<li><a href=\"http://blog.csdn.net/guoguo1980/article/details/2324454\" target=\"_blank\" rel=\"noopener\">linux lsof详解</a></li>\n<li><a href=\"http://www.cnblogs.com/MenAngel/p/5575479.html\" target=\"_blank\" rel=\"noopener\">每天一个Linux命令（45）lsof命令</a></li>\n<li><a href=\"https://linux.cn/article-4099-1.html\" target=\"_blank\" rel=\"noopener\">Linux 命令神器: lsof 入门</a></li>\n<li><a href=\"https://stackoverflow.com/questions/25140730/what-does-the-fd-column-of-pipes-listed-by-lsof-mean\" target=\"_blank\" rel=\"noopener\">what-does-the-fd-column-of-pipes-listed-by-lsof-mean</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>第一次接触到 lsof 命令, 是因为偶然间发现 netstat 命令已经落伍了(与此同时, 还发现了 ss 命令, 详见另一篇文章: <a href=\"\">netstat/ss 使用对比</a> );<br>使用之后, 发现 lsof 被人称为 <code>神器</code>, 还是有一定道理的; 在任何资源都被抽象为 <code>文件</code> 的 linux 中, 一个面向 <code>文件</code> 的管理工具, 自然辖域辽阔, 神通广大, 再加上与其他命令的巧妙组合, 更如虎添翼, 在工作实践中独当一面;<br>本文参考了一些实用资料, 结合自己的经验, 对 lsof 命令的使用略作整理;</p>\n</blockquote>","more":"<hr>\n<h2 id=\"lsof-命令的输出结构\"><a href=\"#lsof-命令的输出结构\" class=\"headerlink\" title=\"lsof 命令的输出结构\"></a><strong>lsof 命令的输出结构</strong></h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># COMMAND   启动进程的命令</span></span><br><span class=\"line\"><span class=\"comment\"># PID       进程号</span></span><br><span class=\"line\"><span class=\"comment\"># TID       线程号</span></span><br><span class=\"line\"><span class=\"comment\"># USER      用户</span></span><br><span class=\"line\"><span class=\"comment\"># FD        文件描述符</span></span><br><span class=\"line\"><span class=\"comment\"># TYPE      文件类型</span></span><br><span class=\"line\"><span class=\"comment\"># DEVICE    磁盘名称</span></span><br><span class=\"line\"><span class=\"comment\"># SIZE      文件大小</span></span><br><span class=\"line\"><span class=\"comment\"># NODE      inode 号</span></span><br><span class=\"line\"><span class=\"comment\"># NAME      文件资源的名称</span></span><br><span class=\"line\">&gt; sudo lsof | head -n 2</span><br><span class=\"line\">COMMAND     PID   TID      USER   FD      TYPE             DEVICE    SIZE/OFF       NODE NAME</span><br><span class=\"line\">systemd       1            root  cwd       DIR              253,1        4096        128 /</span><br></pre></td></tr></table></figure>\n<h3 id=\"各字段的不同输出含义\"><a href=\"#各字段的不同输出含义\" class=\"headerlink\" title=\"各字段的不同输出含义\"></a><strong>各字段的不同输出含义</strong></h3><p>FD: 文件描述符 file description<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 任何进程都必须有的</span></span><br><span class=\"line\">0:      标准输入流</span><br><span class=\"line\">1:      标准输出流</span><br><span class=\"line\">2:      标准错误流</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 几种特殊的保留 fd</span></span><br><span class=\"line\">cwd:    current work directory, 应用程序启动的目录</span><br><span class=\"line\">txt:    二进制可执行文件或共享库</span><br><span class=\"line\">rtd:    root directory, 根目录</span><br><span class=\"line\">mem:    memory mapped file, 内存映射文件</span><br><span class=\"line\">mmap:   memory-mapped device, 内存映射设备</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 整数后面跟着的字母</span></span><br><span class=\"line\">u:      可读可写模式</span><br><span class=\"line\">r:      只读模式</span><br><span class=\"line\">w:      只写模式</span><br></pre></td></tr></table></figure></p>\n<p>TYPE: 文件类型<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DIR:    目录文件</span><br><span class=\"line\">REG:    普通文件</span><br><span class=\"line\">CHR:    char, 字符设备文件</span><br><span class=\"line\">BLK:    block, 块设备文件</span><br><span class=\"line\">IPV4:   ipv4 socket 套接字文件</span><br><span class=\"line\">IPV6:   ipv6 socket 套接字文件</span><br></pre></td></tr></table></figure></p>\n<p>DEVICE:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">todo</span><br></pre></td></tr></table></figure></p>\n<p>SIZE: 文件大小<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 套接字文件的文件大小比较特殊, 其没有大小, 用特殊字符占位, 其余则正常显示 size</span></span><br><span class=\"line\">0t0:    套接字文件的默认占位</span><br></pre></td></tr></table></figure></p>\n<p>&nbsp;</p>\n<h2 id=\"lsof-的日常应用\"><a href=\"#lsof-的日常应用\" class=\"headerlink\" title=\"lsof 的日常应用\"></a><strong>lsof 的日常应用</strong></h2><h3 id=\"lsof-网络-相关的应用\"><a href=\"#lsof-网络-相关的应用\" class=\"headerlink\" title=\"lsof 网络 相关的应用\"></a><strong>lsof 网络 相关的应用</strong></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 显示所有网络连接</span></span><br><span class=\"line\">sudo lsof -i</span><br><span class=\"line\"><span class=\"comment\"># 只显示 ipv6 的连接</span></span><br><span class=\"line\">sudo lsof -i 6</span><br><span class=\"line\"><span class=\"comment\"># 只显示 tcp 协议的连接</span></span><br><span class=\"line\">sudo lsof -i TCP</span><br><span class=\"line\"><span class=\"comment\"># 指定端口号</span></span><br><span class=\"line\">sudo lsof -i:port</span><br><span class=\"line\"><span class=\"comment\"># 指定主机(与端口)</span></span><br><span class=\"line\">sudo lsof -i@l-tracer15.tc.cn2.xx.com:9999</span><br></pre></td></tr></table></figure>\n<h3 id=\"lsof-用户-相关的应用\"><a href=\"#lsof-用户-相关的应用\" class=\"headerlink\" title=\"lsof 用户 相关的应用\"></a><strong>lsof 用户 相关的应用</strong></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 显示某用户所打开的文件</span></span><br><span class=\"line\">sudo lsof -u zshell.zhang</span><br><span class=\"line\">sudo lsof -u ^zshell.zhang (排除此用户)</span><br></pre></td></tr></table></figure>\n<h3 id=\"lsof-命令-进程-相关的应用\"><a href=\"#lsof-命令-进程-相关的应用\" class=\"headerlink\" title=\"lsof 命令/进程 相关的应用\"></a><strong>lsof 命令/进程 相关的应用</strong></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 只显示 pid</span></span><br><span class=\"line\">sudo lsof -t</span><br><span class=\"line\"><span class=\"comment\"># 只显示指定的命令打开的文件</span></span><br><span class=\"line\">sudo lsof -c nginx</span><br><span class=\"line\"><span class=\"comment\"># 只显示指定 pid 的进程打开的文件</span></span><br><span class=\"line\">sudo lsof -p pid</span><br></pre></td></tr></table></figure>\n<h3 id=\"lsof-文件-目录-相关的应用\"><a href=\"#lsof-文件-目录-相关的应用\" class=\"headerlink\" title=\"lsof 文件/目录 相关的应用\"></a><strong>lsof 文件/目录 相关的应用</strong></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 搜索与指定路径相关的一切资源(user, process 等)</span></span><br><span class=\"line\">sudo lsof /target_path</span><br><span class=\"line\"><span class=\"comment\"># +d: 搜索与指定的一级目录下所有的文件相关的一切资源; +D: 递归操作(往下所有层级目录)</span></span><br><span class=\"line\">sudo lsof +d /target_path</span><br><span class=\"line\">sudo lsof +D /target_path</span><br></pre></td></tr></table></figure>\n<h3 id=\"lsof-的选项组合及实践技巧\"><a href=\"#lsof-的选项组合及实践技巧\" class=\"headerlink\" title=\"lsof 的选项组合及实践技巧\"></a><strong>lsof 的选项组合及实践技巧</strong></h3><p>上述的 lsof 操作, 对于多种选项的组合, 其默认是 或(or) 的关系, 即满足其中之一便会打印出来;<br>lsof 与(and) 的逻辑运算关系如下:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 使用 -a 达到 与(and) 的效果</span></span><br><span class=\"line\"><span class=\"comment\"># 必须同时满足三个条件: </span></span><br><span class=\"line\"><span class=\"comment\">#   1. 是用户 zshell.zhang 启动的进程;</span></span><br><span class=\"line\"><span class=\"comment\">#   2. 是套接字文件, 且连接的主机是 10.64.4.11;</span></span><br><span class=\"line\"><span class=\"comment\">#   3. 该进程命令是 java;</span></span><br><span class=\"line\">sudo lsof -a -u zshell.zhang -i@10.64.4.11 -c java</span><br></pre></td></tr></table></figure></p>\n<p>lsof 常用的组合及实践:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 寻找已删除但未释放文件句柄的幽灵文件</span></span><br><span class=\"line\">sudo lsof | grep deleted</span><br><span class=\"line\"><span class=\"comment\"># 杀死所有匹配一定文件打开条件的进程</span></span><br><span class=\"line\">sudo <span class=\"built_in\">kill</span> `sudo lsof -t -c java` <span class=\"comment\"># 杀死所有 java 进程</span></span><br><span class=\"line\">sudo <span class=\"built_in\">kill</span> `sudo lsof -t -u zshell.zhang` <span class=\"comment\"># 杀死所有 zshell.zhang 的用户进程</span></span><br><span class=\"line\"><span class=\"comment\"># 恢复删除的文件</span></span><br><span class=\"line\"><span class=\"comment\"># 找到误删文件被什么进程持有, 获得 pid 和 fd</span></span><br><span class=\"line\">1. sudo lsof /target_deleted_file</span><br><span class=\"line\"><span class=\"comment\"># /proc/&#123;pid&#125;/fd/&#123;fd_num&#125; 的内容即为误删内容, 重定向到误删文件中即可</span></span><br><span class=\"line\">2. cat /proc/&#123;pid&#125;/fd/&#123;fd_num&#125; &gt; /target_deleted_file</span><br></pre></td></tr></table></figure></p>\n<p>另外, lsof 还可以被运用于找出系统中的幽灵文件, 详见: <a href=\"https://zshell-zhang.github.io/2017/04/07/linux-other--du,df使用及其区别/\">du / df 使用及其区别</a>;</p>\n<h2 id=\"站内相关文章\"><a href=\"#站内相关文章\" class=\"headerlink\" title=\"站内相关文章\"></a><strong>站内相关文章</strong></h2><ul>\n<li><a href=\"\">netstat/ss 使用对比</a></li>\n<li><a href=\"https://zshell-zhang.github.io/2017/04/07/linux-other--du,df使用及其区别/\">du / df 使用及其区别</a></li>\n</ul>\n<h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a><strong>参考链接</strong></h2><ul>\n<li><a href=\"http://blog.csdn.net/guoguo1980/article/details/2324454\" target=\"_blank\" rel=\"noopener\">linux lsof详解</a></li>\n<li><a href=\"http://www.cnblogs.com/MenAngel/p/5575479.html\" target=\"_blank\" rel=\"noopener\">每天一个Linux命令（45）lsof命令</a></li>\n<li><a href=\"https://linux.cn/article-4099-1.html\" target=\"_blank\" rel=\"noopener\">Linux 命令神器: lsof 入门</a></li>\n<li><a href=\"https://stackoverflow.com/questions/25140730/what-does-the-fd-column-of-pipes-listed-by-lsof-mean\" target=\"_blank\" rel=\"noopener\">what-does-the-fd-column-of-pipes-listed-by-lsof-mean</a></li>\n</ul>"},{"title":"bash 条件判断全梳理","date":"2016-09-01T09:52:36.000Z","_content":"\n> 本文基于 GNU bash, version 4.1.2(1)-release (x86_64-redhat-linux-gnu)\n\n<!--more-->\n\n## **bash 条件判断 的类型与逻辑运算符**\n\n### **字符串比较**\n1. `=`同`==`, 相同为真;\n2. `!=`, 不相同为真;\n3. `-z`, 长度为0(空)为真;\n4. `-n`, 长度不为0(非空)为真;\n5. `<`, 按字典序小于为真;\n6. `>`, 按字典序大于为真;\n\n### **整数比较**\n1. `-eq`, equals, 相等为真;\n2. `-ne`, not equals, 不相等为真;\n3. `-gt`, greater than, 大于为真;\n4. `-ge`, greater equals, 大于等于为真;\n5. `-lt`, less than, 小于为真;\n6. `-le`, less equals, 小于等于为真;\n7. `>`, 大于;\n8. `>=`, 大于等于;\n9. `<`, 小于;\n10. `<=`, 小于等于;\n11. `==`, 等于;\n12. `!=`, 不等于;\n\n### **文件比较**\n1. `-e`, exists, 文件存在为真\n2. `-r`, read, 用户可读为真 \n3. `-w`, write, 用户可写为真 \n4. `-x`, execute, 用户可执行为真 \n5. `-f`, file, 文件为正规文件为真 \n6. `-d`, directory, 文件为目录为真\n7. `-L`, link, 文件为链接文件为真\n8. `-c`, char, 文件为字符特殊文件为真 \n9. `-b`, block, 文件为块特殊文件为真 \n10. `-s`, 文件大小非0时为真 \n11. `-t`, 当文件描述符(默认为1)指定的设备为终端时为真\n12. `-nt`, newer than, 更新时间更晚为真;\n13. `-ot`, older than, 更新时间更早为真;\n\n### **逻辑比较**\n1. `-a`, and, 逻辑与;\n2. `-o`, or, 逻辑或;\n3. `!`, 逻辑非;\n4. `&&`, 逻辑与( 支持短路 );\n5. `||`, 逻辑或( 支持短路 );\n\n&nbsp;\n## **bash 条件判断 的命令(关键字)与语法**\n\n### **test 与 [ ]**\n`test` 与 `[` 是 shell 的内置命令;\n`test` 和 `[]` 可以用于比较字符串, 整数, 文件, `test expr `与`[ expr ]`有等价的效果;\n\n#### **字符串比较**\n`test`可以使用`=`, `==`, `!=`比较, bash 4.1版本下也能使用`-n`, `-z`比较字符串( 旧版本可能不支持该方式 );\n`[]`可以使用上述全部的比较符号;\n``` bash\nif !test $str1 == $str2; then ... ; fi\nif ! [ $str1 == $str2 ]; then ... ; fi\n```\n`test` 与 `[]` 也可以使用 `<` 和 `>` 作字符串比较; 但是有一点要注意, `test`和`[`是 shell 的内置命令, 使用 `<` 和 `>` 需要转义, 否则会被当成重定向; \n#### **整数比较**\n`test`和`[]`均可以使用`-eq`, `-gt`, `-ge`, `-lt`, `-le`, `-ne` 作整数比较, 但不能使用 `>`, `>=`, `<`, `<=`,`==`,`!=` 等比较运算符;\n使用`<`,`>`,`==`,`!=`虽然语法不会报错, 但是会被当成字符串以字典序比较, 不能确保结果的正确性;\n``` bash\nif test $1 -le 0; then ... ; fi\nif [ $1 -le 0 ]; then ... ; fi\n```\n#### **文件比较**\n`test`和`[]`均可以使用`-e`, `-r`, `-w`, `-x`等文件比较逻辑;\n``` bash\nif test -e /usr/local/localtime; then ... ; fi\nif [ -e /usr/local/localtime ]; then ... ; fi\n```\n#### **逻辑比较**\n`test`和`[]`只能使用`-a`, `-o`和`!`运算符, 但`-a`和`-o` 不支持逻辑短路;\n``` bash\nif !test $str1 == $str2 -a -n $str3; then ... ; fi\nif [ $str1 == $str2 -a -n $str3 ]; then ... ; fi\n```\n#### **test的返回值**\n`test`可以独立于`if`使用, 其执行结果( 0为真, 1为假 )可以使用`$?`来接收;\n``` bash\ntest -z \"$1\"; echo \"$?\"\n```\n\n### **bash关键字 [[ ]] ( 推荐使用 )**\n`[[` 是 bash 的关键字, 而不是命令;\n`[[ ]]` 比 `[]` 更通用, 更安全, 功能更强大; 在生产环境中, 推荐使用 `[[ ]]`;\n\n#### **字符串比较**\n`[[ ]]` 除了可以使用基本的 `=`, `==`, `!=`, `-n`, `-z` 之外, 其 `=`,`==` 和 `!=`还有通配符模式匹配的功能:\n``` bash\n# 模式串不能加双引号, 否则会被当作普通串\nif [[ \"test\" == t* ]]; then ... ; fi\n```\n`[[ ]]` 还可以使用支持正则表达式的 `=~` 运算符:\n``` bash\n# 模式串不能加双引号, 否则会被当作普通串\nif [[ \"test\" =~ ^t[a-z].t$ ]]; then ... ; fi\n```\n`[[ ]]`也可以使用`<`和`>`作字符串比较; 由于`[[`是bash内置的关键字, `<`和`>`并不会被当成重定向, 所以可以不需要转义;\n#### **整数比较**\n和`test`, `[]`一样, `[[ ]]`可以使用`-eq`, `-gt`, `-ge`, `-lt`, `-le`, `-ne` 作整数比较, 但不能使用 `>`, `>=`, `<`, `<=`,`==`,`!=` 等比较运算符; 不能使用的原因也是一样的(当成字符串来处理了);\n#### **算术拓展**\n`[[]]`支持算术拓展, 但是其对整数比较支持度较差, 算术拓展可能是一个鸡肋功能, 而且运算符与运算数之间不能有空格:\n``` bash\nif [[ 1+1 -eq 2 ]]; then ... ; fi\n```\n此功能不推荐使用;\n#### **文件比较**\n和`test`, `[]`一样, `[[ ]]`可以使用`-e`, `-r`, `-w`, `-x`等文件比较逻辑;\n#### **逻辑比较**\n`[[ ]]`只能使用`&&`, `||`, `!`运算符, 且`&&`和`||`支持逻辑短路;\n\n### **(( ))的使用场景**\n无论是`test`, `[]`还是`[[ ]]`, 都不能很好地使用`<`和`>`处理整数的比较运算;\n所以通常使用`(())`来处理整数的比较运算;\n`(())`可以使用`>`, `>=`, `<`, `<=`,`==`,`!=`运算符;\n``` bash\nif (( 1 + 1 == 2 )); then ... ; fi\n```\n使用`(())`的时候, 如果使用到了变量, 可以不需要加上`$`符号;\n\n&nbsp;\n## **总结**\n\n|-           | test 与 [ ]                                          | [[ ]]                                                | (( ))                 |\n|:----------:|:----------------------------------------------------:|:----------------------------------------------------:|:---------------------:|\n| 字符串比较 | =, ==, !=, -n, -z, \\\\<, \\\\>                          | =, ==, !=, -n, -z, <, >                              | 不支持                |\n| 整数比较   | -eq, -gt, -ge, -lt, -le, -ne                         | -eq, -gt, -ge, -lt, -le, -ne                         | \\>, >=, <, <=, ==, != |\n| 文件比较   | -e, -r, -w, -x, -f, -d, -L, -s, -b, -c, -t, -nt, -ot | -e, -r, -w, -x, -f, -d, -L, -s, -b, -c, -t, -nt, -ot | 不支持                |\n| 逻辑比较   | -a, -o, !                                            | &&, &#124;&#124;, !                                  | &&, &#124;&#124;, !   |\n\n&nbsp;\n## **参考链接**\n","source":"_posts/linux-shell--bash条件判断全梳理.md","raw":"---\ntitle: bash 条件判断全梳理\ndate: 2016-09-01 17:52:36\ntags: \n  - linux:shell\ncategories:\n  - linux\n  - shell\n---\n\n> 本文基于 GNU bash, version 4.1.2(1)-release (x86_64-redhat-linux-gnu)\n\n<!--more-->\n\n## **bash 条件判断 的类型与逻辑运算符**\n\n### **字符串比较**\n1. `=`同`==`, 相同为真;\n2. `!=`, 不相同为真;\n3. `-z`, 长度为0(空)为真;\n4. `-n`, 长度不为0(非空)为真;\n5. `<`, 按字典序小于为真;\n6. `>`, 按字典序大于为真;\n\n### **整数比较**\n1. `-eq`, equals, 相等为真;\n2. `-ne`, not equals, 不相等为真;\n3. `-gt`, greater than, 大于为真;\n4. `-ge`, greater equals, 大于等于为真;\n5. `-lt`, less than, 小于为真;\n6. `-le`, less equals, 小于等于为真;\n7. `>`, 大于;\n8. `>=`, 大于等于;\n9. `<`, 小于;\n10. `<=`, 小于等于;\n11. `==`, 等于;\n12. `!=`, 不等于;\n\n### **文件比较**\n1. `-e`, exists, 文件存在为真\n2. `-r`, read, 用户可读为真 \n3. `-w`, write, 用户可写为真 \n4. `-x`, execute, 用户可执行为真 \n5. `-f`, file, 文件为正规文件为真 \n6. `-d`, directory, 文件为目录为真\n7. `-L`, link, 文件为链接文件为真\n8. `-c`, char, 文件为字符特殊文件为真 \n9. `-b`, block, 文件为块特殊文件为真 \n10. `-s`, 文件大小非0时为真 \n11. `-t`, 当文件描述符(默认为1)指定的设备为终端时为真\n12. `-nt`, newer than, 更新时间更晚为真;\n13. `-ot`, older than, 更新时间更早为真;\n\n### **逻辑比较**\n1. `-a`, and, 逻辑与;\n2. `-o`, or, 逻辑或;\n3. `!`, 逻辑非;\n4. `&&`, 逻辑与( 支持短路 );\n5. `||`, 逻辑或( 支持短路 );\n\n&nbsp;\n## **bash 条件判断 的命令(关键字)与语法**\n\n### **test 与 [ ]**\n`test` 与 `[` 是 shell 的内置命令;\n`test` 和 `[]` 可以用于比较字符串, 整数, 文件, `test expr `与`[ expr ]`有等价的效果;\n\n#### **字符串比较**\n`test`可以使用`=`, `==`, `!=`比较, bash 4.1版本下也能使用`-n`, `-z`比较字符串( 旧版本可能不支持该方式 );\n`[]`可以使用上述全部的比较符号;\n``` bash\nif !test $str1 == $str2; then ... ; fi\nif ! [ $str1 == $str2 ]; then ... ; fi\n```\n`test` 与 `[]` 也可以使用 `<` 和 `>` 作字符串比较; 但是有一点要注意, `test`和`[`是 shell 的内置命令, 使用 `<` 和 `>` 需要转义, 否则会被当成重定向; \n#### **整数比较**\n`test`和`[]`均可以使用`-eq`, `-gt`, `-ge`, `-lt`, `-le`, `-ne` 作整数比较, 但不能使用 `>`, `>=`, `<`, `<=`,`==`,`!=` 等比较运算符;\n使用`<`,`>`,`==`,`!=`虽然语法不会报错, 但是会被当成字符串以字典序比较, 不能确保结果的正确性;\n``` bash\nif test $1 -le 0; then ... ; fi\nif [ $1 -le 0 ]; then ... ; fi\n```\n#### **文件比较**\n`test`和`[]`均可以使用`-e`, `-r`, `-w`, `-x`等文件比较逻辑;\n``` bash\nif test -e /usr/local/localtime; then ... ; fi\nif [ -e /usr/local/localtime ]; then ... ; fi\n```\n#### **逻辑比较**\n`test`和`[]`只能使用`-a`, `-o`和`!`运算符, 但`-a`和`-o` 不支持逻辑短路;\n``` bash\nif !test $str1 == $str2 -a -n $str3; then ... ; fi\nif [ $str1 == $str2 -a -n $str3 ]; then ... ; fi\n```\n#### **test的返回值**\n`test`可以独立于`if`使用, 其执行结果( 0为真, 1为假 )可以使用`$?`来接收;\n``` bash\ntest -z \"$1\"; echo \"$?\"\n```\n\n### **bash关键字 [[ ]] ( 推荐使用 )**\n`[[` 是 bash 的关键字, 而不是命令;\n`[[ ]]` 比 `[]` 更通用, 更安全, 功能更强大; 在生产环境中, 推荐使用 `[[ ]]`;\n\n#### **字符串比较**\n`[[ ]]` 除了可以使用基本的 `=`, `==`, `!=`, `-n`, `-z` 之外, 其 `=`,`==` 和 `!=`还有通配符模式匹配的功能:\n``` bash\n# 模式串不能加双引号, 否则会被当作普通串\nif [[ \"test\" == t* ]]; then ... ; fi\n```\n`[[ ]]` 还可以使用支持正则表达式的 `=~` 运算符:\n``` bash\n# 模式串不能加双引号, 否则会被当作普通串\nif [[ \"test\" =~ ^t[a-z].t$ ]]; then ... ; fi\n```\n`[[ ]]`也可以使用`<`和`>`作字符串比较; 由于`[[`是bash内置的关键字, `<`和`>`并不会被当成重定向, 所以可以不需要转义;\n#### **整数比较**\n和`test`, `[]`一样, `[[ ]]`可以使用`-eq`, `-gt`, `-ge`, `-lt`, `-le`, `-ne` 作整数比较, 但不能使用 `>`, `>=`, `<`, `<=`,`==`,`!=` 等比较运算符; 不能使用的原因也是一样的(当成字符串来处理了);\n#### **算术拓展**\n`[[]]`支持算术拓展, 但是其对整数比较支持度较差, 算术拓展可能是一个鸡肋功能, 而且运算符与运算数之间不能有空格:\n``` bash\nif [[ 1+1 -eq 2 ]]; then ... ; fi\n```\n此功能不推荐使用;\n#### **文件比较**\n和`test`, `[]`一样, `[[ ]]`可以使用`-e`, `-r`, `-w`, `-x`等文件比较逻辑;\n#### **逻辑比较**\n`[[ ]]`只能使用`&&`, `||`, `!`运算符, 且`&&`和`||`支持逻辑短路;\n\n### **(( ))的使用场景**\n无论是`test`, `[]`还是`[[ ]]`, 都不能很好地使用`<`和`>`处理整数的比较运算;\n所以通常使用`(())`来处理整数的比较运算;\n`(())`可以使用`>`, `>=`, `<`, `<=`,`==`,`!=`运算符;\n``` bash\nif (( 1 + 1 == 2 )); then ... ; fi\n```\n使用`(())`的时候, 如果使用到了变量, 可以不需要加上`$`符号;\n\n&nbsp;\n## **总结**\n\n|-           | test 与 [ ]                                          | [[ ]]                                                | (( ))                 |\n|:----------:|:----------------------------------------------------:|:----------------------------------------------------:|:---------------------:|\n| 字符串比较 | =, ==, !=, -n, -z, \\\\<, \\\\>                          | =, ==, !=, -n, -z, <, >                              | 不支持                |\n| 整数比较   | -eq, -gt, -ge, -lt, -le, -ne                         | -eq, -gt, -ge, -lt, -le, -ne                         | \\>, >=, <, <=, ==, != |\n| 文件比较   | -e, -r, -w, -x, -f, -d, -L, -s, -b, -c, -t, -nt, -ot | -e, -r, -w, -x, -f, -d, -L, -s, -b, -c, -t, -nt, -ot | 不支持                |\n| 逻辑比较   | -a, -o, !                                            | &&, &#124;&#124;, !                                  | &&, &#124;&#124;, !   |\n\n&nbsp;\n## **参考链接**\n","slug":"linux-shell--bash条件判断全梳理","published":1,"updated":"2018-01-20T13:10:27.025Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cje24mxts0006j1jx10eq3zja","content":"<blockquote>\n<p>本文基于 GNU bash, version 4.1.2(1)-release (x86_64-redhat-linux-gnu)</p>\n</blockquote>\n<a id=\"more\"></a>\n<h2 id=\"bash-条件判断-的类型与逻辑运算符\"><a href=\"#bash-条件判断-的类型与逻辑运算符\" class=\"headerlink\" title=\"bash 条件判断 的类型与逻辑运算符\"></a><strong>bash 条件判断 的类型与逻辑运算符</strong></h2><h3 id=\"字符串比较\"><a href=\"#字符串比较\" class=\"headerlink\" title=\"字符串比较\"></a><strong>字符串比较</strong></h3><ol>\n<li><code>=</code>同<code>==</code>, 相同为真;</li>\n<li><code>!=</code>, 不相同为真;</li>\n<li><code>-z</code>, 长度为0(空)为真;</li>\n<li><code>-n</code>, 长度不为0(非空)为真;</li>\n<li><code>&lt;</code>, 按字典序小于为真;</li>\n<li><code>&gt;</code>, 按字典序大于为真;</li>\n</ol>\n<h3 id=\"整数比较\"><a href=\"#整数比较\" class=\"headerlink\" title=\"整数比较\"></a><strong>整数比较</strong></h3><ol>\n<li><code>-eq</code>, equals, 相等为真;</li>\n<li><code>-ne</code>, not equals, 不相等为真;</li>\n<li><code>-gt</code>, greater than, 大于为真;</li>\n<li><code>-ge</code>, greater equals, 大于等于为真;</li>\n<li><code>-lt</code>, less than, 小于为真;</li>\n<li><code>-le</code>, less equals, 小于等于为真;</li>\n<li><code>&gt;</code>, 大于;</li>\n<li><code>&gt;=</code>, 大于等于;</li>\n<li><code>&lt;</code>, 小于;</li>\n<li><code>&lt;=</code>, 小于等于;</li>\n<li><code>==</code>, 等于;</li>\n<li><code>!=</code>, 不等于;</li>\n</ol>\n<h3 id=\"文件比较\"><a href=\"#文件比较\" class=\"headerlink\" title=\"文件比较\"></a><strong>文件比较</strong></h3><ol>\n<li><code>-e</code>, exists, 文件存在为真</li>\n<li><code>-r</code>, read, 用户可读为真 </li>\n<li><code>-w</code>, write, 用户可写为真 </li>\n<li><code>-x</code>, execute, 用户可执行为真 </li>\n<li><code>-f</code>, file, 文件为正规文件为真 </li>\n<li><code>-d</code>, directory, 文件为目录为真</li>\n<li><code>-L</code>, link, 文件为链接文件为真</li>\n<li><code>-c</code>, char, 文件为字符特殊文件为真 </li>\n<li><code>-b</code>, block, 文件为块特殊文件为真 </li>\n<li><code>-s</code>, 文件大小非0时为真 </li>\n<li><code>-t</code>, 当文件描述符(默认为1)指定的设备为终端时为真</li>\n<li><code>-nt</code>, newer than, 更新时间更晚为真;</li>\n<li><code>-ot</code>, older than, 更新时间更早为真;</li>\n</ol>\n<h3 id=\"逻辑比较\"><a href=\"#逻辑比较\" class=\"headerlink\" title=\"逻辑比较\"></a><strong>逻辑比较</strong></h3><ol>\n<li><code>-a</code>, and, 逻辑与;</li>\n<li><code>-o</code>, or, 逻辑或;</li>\n<li><code>!</code>, 逻辑非;</li>\n<li><code>&amp;&amp;</code>, 逻辑与( 支持短路 );</li>\n<li><code>||</code>, 逻辑或( 支持短路 );</li>\n</ol>\n<p>&nbsp;</p>\n<h2 id=\"bash-条件判断-的命令-关键字-与语法\"><a href=\"#bash-条件判断-的命令-关键字-与语法\" class=\"headerlink\" title=\"bash 条件判断 的命令(关键字)与语法\"></a><strong>bash 条件判断 的命令(关键字)与语法</strong></h2><h3 id=\"test-与\"><a href=\"#test-与\" class=\"headerlink\" title=\"test 与 [ ]\"></a><strong>test 与 [ ]</strong></h3><p><code>test</code> 与 <code>[</code> 是 shell 的内置命令;<br><code>test</code> 和 <code>[]</code> 可以用于比较字符串, 整数, 文件, <code>test expr</code>与<code>[ expr ]</code>有等价的效果;</p>\n<h4 id=\"字符串比较-1\"><a href=\"#字符串比较-1\" class=\"headerlink\" title=\"字符串比较\"></a><strong>字符串比较</strong></h4><p><code>test</code>可以使用<code>=</code>, <code>==</code>, <code>!=</code>比较, bash 4.1版本下也能使用<code>-n</code>, <code>-z</code>比较字符串( 旧版本可能不支持该方式 );<br><code>[]</code>可以使用上述全部的比较符号;<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> !<span class=\"built_in\">test</span> <span class=\"variable\">$str1</span> == <span class=\"variable\">$str2</span>; <span class=\"keyword\">then</span> ... ; <span class=\"keyword\">fi</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> ! [ <span class=\"variable\">$str1</span> == <span class=\"variable\">$str2</span> ]; <span class=\"keyword\">then</span> ... ; <span class=\"keyword\">fi</span></span><br></pre></td></tr></table></figure></p>\n<p><code>test</code> 与 <code>[]</code> 也可以使用 <code>&lt;</code> 和 <code>&gt;</code> 作字符串比较; 但是有一点要注意, <code>test</code>和<code>[</code>是 shell 的内置命令, 使用 <code>&lt;</code> 和 <code>&gt;</code> 需要转义, 否则会被当成重定向; </p>\n<h4 id=\"整数比较-1\"><a href=\"#整数比较-1\" class=\"headerlink\" title=\"整数比较\"></a><strong>整数比较</strong></h4><p><code>test</code>和<code>[]</code>均可以使用<code>-eq</code>, <code>-gt</code>, <code>-ge</code>, <code>-lt</code>, <code>-le</code>, <code>-ne</code> 作整数比较, 但不能使用 <code>&gt;</code>, <code>&gt;=</code>, <code>&lt;</code>, <code>&lt;=</code>,<code>==</code>,<code>!=</code> 等比较运算符;<br>使用<code>&lt;</code>,<code>&gt;</code>,<code>==</code>,<code>!=</code>虽然语法不会报错, 但是会被当成字符串以字典序比较, 不能确保结果的正确性;<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> <span class=\"built_in\">test</span> <span class=\"variable\">$1</span> -le 0; <span class=\"keyword\">then</span> ... ; <span class=\"keyword\">fi</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> [ <span class=\"variable\">$1</span> -le 0 ]; <span class=\"keyword\">then</span> ... ; <span class=\"keyword\">fi</span></span><br></pre></td></tr></table></figure></p>\n<h4 id=\"文件比较-1\"><a href=\"#文件比较-1\" class=\"headerlink\" title=\"文件比较\"></a><strong>文件比较</strong></h4><p><code>test</code>和<code>[]</code>均可以使用<code>-e</code>, <code>-r</code>, <code>-w</code>, <code>-x</code>等文件比较逻辑;<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> <span class=\"built_in\">test</span> -e /usr/<span class=\"built_in\">local</span>/localtime; <span class=\"keyword\">then</span> ... ; <span class=\"keyword\">fi</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> [ -e /usr/<span class=\"built_in\">local</span>/localtime ]; <span class=\"keyword\">then</span> ... ; <span class=\"keyword\">fi</span></span><br></pre></td></tr></table></figure></p>\n<h4 id=\"逻辑比较-1\"><a href=\"#逻辑比较-1\" class=\"headerlink\" title=\"逻辑比较\"></a><strong>逻辑比较</strong></h4><p><code>test</code>和<code>[]</code>只能使用<code>-a</code>, <code>-o</code>和<code>!</code>运算符, 但<code>-a</code>和<code>-o</code> 不支持逻辑短路;<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> !<span class=\"built_in\">test</span> <span class=\"variable\">$str1</span> == <span class=\"variable\">$str2</span> -a -n <span class=\"variable\">$str3</span>; <span class=\"keyword\">then</span> ... ; <span class=\"keyword\">fi</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> [ <span class=\"variable\">$str1</span> == <span class=\"variable\">$str2</span> -a -n <span class=\"variable\">$str3</span> ]; <span class=\"keyword\">then</span> ... ; <span class=\"keyword\">fi</span></span><br></pre></td></tr></table></figure></p>\n<h4 id=\"test的返回值\"><a href=\"#test的返回值\" class=\"headerlink\" title=\"test的返回值\"></a><strong>test的返回值</strong></h4><p><code>test</code>可以独立于<code>if</code>使用, 其执行结果( 0为真, 1为假 )可以使用<code>$?</code>来接收;<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">test</span> -z <span class=\"string\">\"<span class=\"variable\">$1</span>\"</span>; <span class=\"built_in\">echo</span> <span class=\"string\">\"$?\"</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"bash关键字-推荐使用\"><a href=\"#bash关键字-推荐使用\" class=\"headerlink\" title=\"bash关键字 [[ ]] ( 推荐使用 )\"></a><strong>bash关键字 [[ ]] ( 推荐使用 )</strong></h3><p><code>[[</code> 是 bash 的关键字, 而不是命令;<br><code>[[ ]]</code> 比 <code>[]</code> 更通用, 更安全, 功能更强大; 在生产环境中, 推荐使用 <code>[[ ]]</code>;</p>\n<h4 id=\"字符串比较-2\"><a href=\"#字符串比较-2\" class=\"headerlink\" title=\"字符串比较\"></a><strong>字符串比较</strong></h4><p><code>[[ ]]</code> 除了可以使用基本的 <code>=</code>, <code>==</code>, <code>!=</code>, <code>-n</code>, <code>-z</code> 之外, 其 <code>=</code>,<code>==</code> 和 <code>!=</code>还有通配符模式匹配的功能:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 模式串不能加双引号, 否则会被当作普通串</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> [[ <span class=\"string\">\"test\"</span> == t* ]]; <span class=\"keyword\">then</span> ... ; <span class=\"keyword\">fi</span></span><br></pre></td></tr></table></figure></p>\n<p><code>[[ ]]</code> 还可以使用支持正则表达式的 <code>=~</code> 运算符:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 模式串不能加双引号, 否则会被当作普通串</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> [[ <span class=\"string\">\"test\"</span> =~ ^t[a-z].t$ ]]; <span class=\"keyword\">then</span> ... ; <span class=\"keyword\">fi</span></span><br></pre></td></tr></table></figure></p>\n<p><code>[[ ]]</code>也可以使用<code>&lt;</code>和<code>&gt;</code>作字符串比较; 由于<code>[[</code>是bash内置的关键字, <code>&lt;</code>和<code>&gt;</code>并不会被当成重定向, 所以可以不需要转义;</p>\n<h4 id=\"整数比较-2\"><a href=\"#整数比较-2\" class=\"headerlink\" title=\"整数比较\"></a><strong>整数比较</strong></h4><p>和<code>test</code>, <code>[]</code>一样, <code>[[ ]]</code>可以使用<code>-eq</code>, <code>-gt</code>, <code>-ge</code>, <code>-lt</code>, <code>-le</code>, <code>-ne</code> 作整数比较, 但不能使用 <code>&gt;</code>, <code>&gt;=</code>, <code>&lt;</code>, <code>&lt;=</code>,<code>==</code>,<code>!=</code> 等比较运算符; 不能使用的原因也是一样的(当成字符串来处理了);</p>\n<h4 id=\"算术拓展\"><a href=\"#算术拓展\" class=\"headerlink\" title=\"算术拓展\"></a><strong>算术拓展</strong></h4><p><code>[[]]</code>支持算术拓展, 但是其对整数比较支持度较差, 算术拓展可能是一个鸡肋功能, 而且运算符与运算数之间不能有空格:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> [[ 1+1 -eq 2 ]]; <span class=\"keyword\">then</span> ... ; <span class=\"keyword\">fi</span></span><br></pre></td></tr></table></figure></p>\n<p>此功能不推荐使用;</p>\n<h4 id=\"文件比较-2\"><a href=\"#文件比较-2\" class=\"headerlink\" title=\"文件比较\"></a><strong>文件比较</strong></h4><p>和<code>test</code>, <code>[]</code>一样, <code>[[ ]]</code>可以使用<code>-e</code>, <code>-r</code>, <code>-w</code>, <code>-x</code>等文件比较逻辑;</p>\n<h4 id=\"逻辑比较-2\"><a href=\"#逻辑比较-2\" class=\"headerlink\" title=\"逻辑比较\"></a><strong>逻辑比较</strong></h4><p><code>[[ ]]</code>只能使用<code>&amp;&amp;</code>, <code>||</code>, <code>!</code>运算符, 且<code>&amp;&amp;</code>和<code>||</code>支持逻辑短路;</p>\n<h3 id=\"的使用场景\"><a href=\"#的使用场景\" class=\"headerlink\" title=\"(( ))的使用场景\"></a><strong>(( ))的使用场景</strong></h3><p>无论是<code>test</code>, <code>[]</code>还是<code>[[ ]]</code>, 都不能很好地使用<code>&lt;</code>和<code>&gt;</code>处理整数的比较运算;<br>所以通常使用<code>(())</code>来处理整数的比较运算;<br><code>(())</code>可以使用<code>&gt;</code>, <code>&gt;=</code>, <code>&lt;</code>, <code>&lt;=</code>,<code>==</code>,<code>!=</code>运算符;<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> (( 1 + 1 == 2 )); <span class=\"keyword\">then</span> ... ; <span class=\"keyword\">fi</span></span><br></pre></td></tr></table></figure></p>\n<p>使用<code>(())</code>的时候, 如果使用到了变量, 可以不需要加上<code>$</code>符号;</p>\n<p>&nbsp;</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a><strong>总结</strong></h2><table>\n<thead>\n<tr>\n<th style=\"text-align:center\">-</th>\n<th style=\"text-align:center\">test 与 [ ]</th>\n<th style=\"text-align:center\">[[ ]]</th>\n<th style=\"text-align:center\">(( ))</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">字符串比较</td>\n<td style=\"text-align:center\">=, ==, !=, -n, -z, \\&lt;, \\&gt;</td>\n<td style=\"text-align:center\">=, ==, !=, -n, -z, &lt;, &gt;</td>\n<td style=\"text-align:center\">不支持</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">整数比较</td>\n<td style=\"text-align:center\">-eq, -gt, -ge, -lt, -le, -ne</td>\n<td style=\"text-align:center\">-eq, -gt, -ge, -lt, -le, -ne</td>\n<td style=\"text-align:center\">>, &gt;=, &lt;, &lt;=, ==, !=</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">文件比较</td>\n<td style=\"text-align:center\">-e, -r, -w, -x, -f, -d, -L, -s, -b, -c, -t, -nt, -ot</td>\n<td style=\"text-align:center\">-e, -r, -w, -x, -f, -d, -L, -s, -b, -c, -t, -nt, -ot</td>\n<td style=\"text-align:center\">不支持</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">逻辑比较</td>\n<td style=\"text-align:center\">-a, -o, !</td>\n<td style=\"text-align:center\">&amp;&amp;, &#124;&#124;, !</td>\n<td style=\"text-align:center\">&amp;&amp;, &#124;&#124;, !</td>\n</tr>\n</tbody>\n</table>\n<p>&nbsp;</p>\n<h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a><strong>参考链接</strong></h2>","site":{"data":{}},"excerpt":"<blockquote>\n<p>本文基于 GNU bash, version 4.1.2(1)-release (x86_64-redhat-linux-gnu)</p>\n</blockquote>","more":"<h2 id=\"bash-条件判断-的类型与逻辑运算符\"><a href=\"#bash-条件判断-的类型与逻辑运算符\" class=\"headerlink\" title=\"bash 条件判断 的类型与逻辑运算符\"></a><strong>bash 条件判断 的类型与逻辑运算符</strong></h2><h3 id=\"字符串比较\"><a href=\"#字符串比较\" class=\"headerlink\" title=\"字符串比较\"></a><strong>字符串比较</strong></h3><ol>\n<li><code>=</code>同<code>==</code>, 相同为真;</li>\n<li><code>!=</code>, 不相同为真;</li>\n<li><code>-z</code>, 长度为0(空)为真;</li>\n<li><code>-n</code>, 长度不为0(非空)为真;</li>\n<li><code>&lt;</code>, 按字典序小于为真;</li>\n<li><code>&gt;</code>, 按字典序大于为真;</li>\n</ol>\n<h3 id=\"整数比较\"><a href=\"#整数比较\" class=\"headerlink\" title=\"整数比较\"></a><strong>整数比较</strong></h3><ol>\n<li><code>-eq</code>, equals, 相等为真;</li>\n<li><code>-ne</code>, not equals, 不相等为真;</li>\n<li><code>-gt</code>, greater than, 大于为真;</li>\n<li><code>-ge</code>, greater equals, 大于等于为真;</li>\n<li><code>-lt</code>, less than, 小于为真;</li>\n<li><code>-le</code>, less equals, 小于等于为真;</li>\n<li><code>&gt;</code>, 大于;</li>\n<li><code>&gt;=</code>, 大于等于;</li>\n<li><code>&lt;</code>, 小于;</li>\n<li><code>&lt;=</code>, 小于等于;</li>\n<li><code>==</code>, 等于;</li>\n<li><code>!=</code>, 不等于;</li>\n</ol>\n<h3 id=\"文件比较\"><a href=\"#文件比较\" class=\"headerlink\" title=\"文件比较\"></a><strong>文件比较</strong></h3><ol>\n<li><code>-e</code>, exists, 文件存在为真</li>\n<li><code>-r</code>, read, 用户可读为真 </li>\n<li><code>-w</code>, write, 用户可写为真 </li>\n<li><code>-x</code>, execute, 用户可执行为真 </li>\n<li><code>-f</code>, file, 文件为正规文件为真 </li>\n<li><code>-d</code>, directory, 文件为目录为真</li>\n<li><code>-L</code>, link, 文件为链接文件为真</li>\n<li><code>-c</code>, char, 文件为字符特殊文件为真 </li>\n<li><code>-b</code>, block, 文件为块特殊文件为真 </li>\n<li><code>-s</code>, 文件大小非0时为真 </li>\n<li><code>-t</code>, 当文件描述符(默认为1)指定的设备为终端时为真</li>\n<li><code>-nt</code>, newer than, 更新时间更晚为真;</li>\n<li><code>-ot</code>, older than, 更新时间更早为真;</li>\n</ol>\n<h3 id=\"逻辑比较\"><a href=\"#逻辑比较\" class=\"headerlink\" title=\"逻辑比较\"></a><strong>逻辑比较</strong></h3><ol>\n<li><code>-a</code>, and, 逻辑与;</li>\n<li><code>-o</code>, or, 逻辑或;</li>\n<li><code>!</code>, 逻辑非;</li>\n<li><code>&amp;&amp;</code>, 逻辑与( 支持短路 );</li>\n<li><code>||</code>, 逻辑或( 支持短路 );</li>\n</ol>\n<p>&nbsp;</p>\n<h2 id=\"bash-条件判断-的命令-关键字-与语法\"><a href=\"#bash-条件判断-的命令-关键字-与语法\" class=\"headerlink\" title=\"bash 条件判断 的命令(关键字)与语法\"></a><strong>bash 条件判断 的命令(关键字)与语法</strong></h2><h3 id=\"test-与\"><a href=\"#test-与\" class=\"headerlink\" title=\"test 与 [ ]\"></a><strong>test 与 [ ]</strong></h3><p><code>test</code> 与 <code>[</code> 是 shell 的内置命令;<br><code>test</code> 和 <code>[]</code> 可以用于比较字符串, 整数, 文件, <code>test expr</code>与<code>[ expr ]</code>有等价的效果;</p>\n<h4 id=\"字符串比较-1\"><a href=\"#字符串比较-1\" class=\"headerlink\" title=\"字符串比较\"></a><strong>字符串比较</strong></h4><p><code>test</code>可以使用<code>=</code>, <code>==</code>, <code>!=</code>比较, bash 4.1版本下也能使用<code>-n</code>, <code>-z</code>比较字符串( 旧版本可能不支持该方式 );<br><code>[]</code>可以使用上述全部的比较符号;<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> !<span class=\"built_in\">test</span> <span class=\"variable\">$str1</span> == <span class=\"variable\">$str2</span>; <span class=\"keyword\">then</span> ... ; <span class=\"keyword\">fi</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> ! [ <span class=\"variable\">$str1</span> == <span class=\"variable\">$str2</span> ]; <span class=\"keyword\">then</span> ... ; <span class=\"keyword\">fi</span></span><br></pre></td></tr></table></figure></p>\n<p><code>test</code> 与 <code>[]</code> 也可以使用 <code>&lt;</code> 和 <code>&gt;</code> 作字符串比较; 但是有一点要注意, <code>test</code>和<code>[</code>是 shell 的内置命令, 使用 <code>&lt;</code> 和 <code>&gt;</code> 需要转义, 否则会被当成重定向; </p>\n<h4 id=\"整数比较-1\"><a href=\"#整数比较-1\" class=\"headerlink\" title=\"整数比较\"></a><strong>整数比较</strong></h4><p><code>test</code>和<code>[]</code>均可以使用<code>-eq</code>, <code>-gt</code>, <code>-ge</code>, <code>-lt</code>, <code>-le</code>, <code>-ne</code> 作整数比较, 但不能使用 <code>&gt;</code>, <code>&gt;=</code>, <code>&lt;</code>, <code>&lt;=</code>,<code>==</code>,<code>!=</code> 等比较运算符;<br>使用<code>&lt;</code>,<code>&gt;</code>,<code>==</code>,<code>!=</code>虽然语法不会报错, 但是会被当成字符串以字典序比较, 不能确保结果的正确性;<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> <span class=\"built_in\">test</span> <span class=\"variable\">$1</span> -le 0; <span class=\"keyword\">then</span> ... ; <span class=\"keyword\">fi</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> [ <span class=\"variable\">$1</span> -le 0 ]; <span class=\"keyword\">then</span> ... ; <span class=\"keyword\">fi</span></span><br></pre></td></tr></table></figure></p>\n<h4 id=\"文件比较-1\"><a href=\"#文件比较-1\" class=\"headerlink\" title=\"文件比较\"></a><strong>文件比较</strong></h4><p><code>test</code>和<code>[]</code>均可以使用<code>-e</code>, <code>-r</code>, <code>-w</code>, <code>-x</code>等文件比较逻辑;<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> <span class=\"built_in\">test</span> -e /usr/<span class=\"built_in\">local</span>/localtime; <span class=\"keyword\">then</span> ... ; <span class=\"keyword\">fi</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> [ -e /usr/<span class=\"built_in\">local</span>/localtime ]; <span class=\"keyword\">then</span> ... ; <span class=\"keyword\">fi</span></span><br></pre></td></tr></table></figure></p>\n<h4 id=\"逻辑比较-1\"><a href=\"#逻辑比较-1\" class=\"headerlink\" title=\"逻辑比较\"></a><strong>逻辑比较</strong></h4><p><code>test</code>和<code>[]</code>只能使用<code>-a</code>, <code>-o</code>和<code>!</code>运算符, 但<code>-a</code>和<code>-o</code> 不支持逻辑短路;<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> !<span class=\"built_in\">test</span> <span class=\"variable\">$str1</span> == <span class=\"variable\">$str2</span> -a -n <span class=\"variable\">$str3</span>; <span class=\"keyword\">then</span> ... ; <span class=\"keyword\">fi</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> [ <span class=\"variable\">$str1</span> == <span class=\"variable\">$str2</span> -a -n <span class=\"variable\">$str3</span> ]; <span class=\"keyword\">then</span> ... ; <span class=\"keyword\">fi</span></span><br></pre></td></tr></table></figure></p>\n<h4 id=\"test的返回值\"><a href=\"#test的返回值\" class=\"headerlink\" title=\"test的返回值\"></a><strong>test的返回值</strong></h4><p><code>test</code>可以独立于<code>if</code>使用, 其执行结果( 0为真, 1为假 )可以使用<code>$?</code>来接收;<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">test</span> -z <span class=\"string\">\"<span class=\"variable\">$1</span>\"</span>; <span class=\"built_in\">echo</span> <span class=\"string\">\"$?\"</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"bash关键字-推荐使用\"><a href=\"#bash关键字-推荐使用\" class=\"headerlink\" title=\"bash关键字 [[ ]] ( 推荐使用 )\"></a><strong>bash关键字 [[ ]] ( 推荐使用 )</strong></h3><p><code>[[</code> 是 bash 的关键字, 而不是命令;<br><code>[[ ]]</code> 比 <code>[]</code> 更通用, 更安全, 功能更强大; 在生产环境中, 推荐使用 <code>[[ ]]</code>;</p>\n<h4 id=\"字符串比较-2\"><a href=\"#字符串比较-2\" class=\"headerlink\" title=\"字符串比较\"></a><strong>字符串比较</strong></h4><p><code>[[ ]]</code> 除了可以使用基本的 <code>=</code>, <code>==</code>, <code>!=</code>, <code>-n</code>, <code>-z</code> 之外, 其 <code>=</code>,<code>==</code> 和 <code>!=</code>还有通配符模式匹配的功能:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 模式串不能加双引号, 否则会被当作普通串</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> [[ <span class=\"string\">\"test\"</span> == t* ]]; <span class=\"keyword\">then</span> ... ; <span class=\"keyword\">fi</span></span><br></pre></td></tr></table></figure></p>\n<p><code>[[ ]]</code> 还可以使用支持正则表达式的 <code>=~</code> 运算符:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 模式串不能加双引号, 否则会被当作普通串</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> [[ <span class=\"string\">\"test\"</span> =~ ^t[a-z].t$ ]]; <span class=\"keyword\">then</span> ... ; <span class=\"keyword\">fi</span></span><br></pre></td></tr></table></figure></p>\n<p><code>[[ ]]</code>也可以使用<code>&lt;</code>和<code>&gt;</code>作字符串比较; 由于<code>[[</code>是bash内置的关键字, <code>&lt;</code>和<code>&gt;</code>并不会被当成重定向, 所以可以不需要转义;</p>\n<h4 id=\"整数比较-2\"><a href=\"#整数比较-2\" class=\"headerlink\" title=\"整数比较\"></a><strong>整数比较</strong></h4><p>和<code>test</code>, <code>[]</code>一样, <code>[[ ]]</code>可以使用<code>-eq</code>, <code>-gt</code>, <code>-ge</code>, <code>-lt</code>, <code>-le</code>, <code>-ne</code> 作整数比较, 但不能使用 <code>&gt;</code>, <code>&gt;=</code>, <code>&lt;</code>, <code>&lt;=</code>,<code>==</code>,<code>!=</code> 等比较运算符; 不能使用的原因也是一样的(当成字符串来处理了);</p>\n<h4 id=\"算术拓展\"><a href=\"#算术拓展\" class=\"headerlink\" title=\"算术拓展\"></a><strong>算术拓展</strong></h4><p><code>[[]]</code>支持算术拓展, 但是其对整数比较支持度较差, 算术拓展可能是一个鸡肋功能, 而且运算符与运算数之间不能有空格:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> [[ 1+1 -eq 2 ]]; <span class=\"keyword\">then</span> ... ; <span class=\"keyword\">fi</span></span><br></pre></td></tr></table></figure></p>\n<p>此功能不推荐使用;</p>\n<h4 id=\"文件比较-2\"><a href=\"#文件比较-2\" class=\"headerlink\" title=\"文件比较\"></a><strong>文件比较</strong></h4><p>和<code>test</code>, <code>[]</code>一样, <code>[[ ]]</code>可以使用<code>-e</code>, <code>-r</code>, <code>-w</code>, <code>-x</code>等文件比较逻辑;</p>\n<h4 id=\"逻辑比较-2\"><a href=\"#逻辑比较-2\" class=\"headerlink\" title=\"逻辑比较\"></a><strong>逻辑比较</strong></h4><p><code>[[ ]]</code>只能使用<code>&amp;&amp;</code>, <code>||</code>, <code>!</code>运算符, 且<code>&amp;&amp;</code>和<code>||</code>支持逻辑短路;</p>\n<h3 id=\"的使用场景\"><a href=\"#的使用场景\" class=\"headerlink\" title=\"(( ))的使用场景\"></a><strong>(( ))的使用场景</strong></h3><p>无论是<code>test</code>, <code>[]</code>还是<code>[[ ]]</code>, 都不能很好地使用<code>&lt;</code>和<code>&gt;</code>处理整数的比较运算;<br>所以通常使用<code>(())</code>来处理整数的比较运算;<br><code>(())</code>可以使用<code>&gt;</code>, <code>&gt;=</code>, <code>&lt;</code>, <code>&lt;=</code>,<code>==</code>,<code>!=</code>运算符;<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> (( 1 + 1 == 2 )); <span class=\"keyword\">then</span> ... ; <span class=\"keyword\">fi</span></span><br></pre></td></tr></table></figure></p>\n<p>使用<code>(())</code>的时候, 如果使用到了变量, 可以不需要加上<code>$</code>符号;</p>\n<p>&nbsp;</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a><strong>总结</strong></h2><table>\n<thead>\n<tr>\n<th style=\"text-align:center\">-</th>\n<th style=\"text-align:center\">test 与 [ ]</th>\n<th style=\"text-align:center\">[[ ]]</th>\n<th style=\"text-align:center\">(( ))</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">字符串比较</td>\n<td style=\"text-align:center\">=, ==, !=, -n, -z, \\&lt;, \\&gt;</td>\n<td style=\"text-align:center\">=, ==, !=, -n, -z, &lt;, &gt;</td>\n<td style=\"text-align:center\">不支持</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">整数比较</td>\n<td style=\"text-align:center\">-eq, -gt, -ge, -lt, -le, -ne</td>\n<td style=\"text-align:center\">-eq, -gt, -ge, -lt, -le, -ne</td>\n<td style=\"text-align:center\">>, &gt;=, &lt;, &lt;=, ==, !=</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">文件比较</td>\n<td style=\"text-align:center\">-e, -r, -w, -x, -f, -d, -L, -s, -b, -c, -t, -nt, -ot</td>\n<td style=\"text-align:center\">-e, -r, -w, -x, -f, -d, -L, -s, -b, -c, -t, -nt, -ot</td>\n<td style=\"text-align:center\">不支持</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">逻辑比较</td>\n<td style=\"text-align:center\">-a, -o, !</td>\n<td style=\"text-align:center\">&amp;&amp;, &#124;&#124;, !</td>\n<td style=\"text-align:center\">&amp;&amp;, &#124;&#124;, !</td>\n</tr>\n</tbody>\n</table>\n<p>&nbsp;</p>\n<h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a><strong>参考链接</strong></h2>"},{"title":"bash 数组与映射","date":"2017-10-22T15:32:19.000Z","_content":"\n> 注: bash 映射 (map) 在文档里叫做 `关联数组 (associated array)`, 使用关联数组的最低 bash 版本是 4.1.2;\n\n<!--more-->\n\n## **数组/关联数组 的创建**\n### **静态创建**\n使用类型限定 declare 定义:\n``` bash\n# 数组\ndeclare -a array1=('a' 'b' 'c')\ndeclare -a array2=(a b c)\n# 关联数组\ndeclare -A map1=([\"a\"]=\"aa\" [\"b\"]=\"bb\" [\"c\"]=\"cc\")\ndeclare -A map2=([a]=aa [b]=bb [c]=cc)\n```\n如果不带类型限定, bash 不会自动推断 关联数组 类型:\n``` bash\nobject1=(a b c)\nobject2=([\"a\"]=\"aa\" [\"b\"]=\"bb\" [\"c\"]=\"cc\")\n```\n对于以上两者, bash 都将推断为 普通数组 类型, 其中 object2 中有三个 string 元素: [\"a\"]=\"aa\", [\"b\"]=\"bb\" 与 [\"c\"]=\"cc\";\n\n### **动态创建**\n以上展示了 数组/动态数组 的静态创建方式;\n更复杂的场景是, 由一段其他复杂命令的输出, 赋值构建一个数组类型:\n``` bash\npair_array=(`sed -n -e '6,/}/p' -e '$d' ${formatted_curl_response_file} | awk -F ':' '{\n    log_length = length($1);\n    app_code_length = length($2);\n    log_path = substr($1, 2, log_length - 2);\n    app_code = substr($2, 2, app_code_length - 2);\n    map[log_path] = app_code\n} END {\n    for (key in map) {\n        printf (\"%10s=%10s \", key, map[key])\n    }\n}'`)\n```\n以上逻辑, 由 sed 与 awk 两重管道输出目标内容, 作为创建数组的参数, 以达到动态创建的目的;\n但是, 以上方式只适用于创建 数组, 而不适用于创建 关联数组, 原因与上一节 静态创建数组 中所表述的相同: 即使输出格式符合定义规范, bash 并不会自动推断为 关联数组;\n&nbsp;\n另外, 企图通过 declare 强制限定类型去动态创建, 也是不合法的:\n``` bash\n> declare -A map=(`last -n 1 | head -n 1 | awk '{map[$1]=$3} END{for (key in map) {printf (\"[%10s]=%10s \", key, map[key])}}'`)\n# 以上语句会报如下错误:\n-bash: map: [: must use subscript when assigning associative array\n-bash: map: zshell.z]=113.44.125.146: must use subscript when assigning associative array\n```\n因为, 通过 ``, $() 等命令代换, [zshell.z]=113.44.125.146 这样的输出内容被当作命令执行, 而 [ 这是一个 bash 的内置命令, 用于条件判断;\n显然 zshell.z]=113.44.125.146 这样的语句是不符合条件判断的参数输入的;\n\n## **数组/关联数组 的使用**\n单独赋值:\n``` bash\nmap['a']='aaa'\narray[0]=aaa\n```\n获取数据:\n``` bash\n# 获得所有 values\necho ${map[@]}\necho ${array[@]}\n# 获得某个单独的值\nvar=${map['a']}\nvar=${array[0]}\n# 获得所有 keys (对于数组而言, 就是获得所有的索引下标)\nfor key in ${!map[@]}; do\n    ...\ndone\nfor key in ${!array[@]}; do\n    ...\ndone\n```\n\n## **参考链接**\n- [shell中的map使用](http://blog.csdn.net/adermxl/article/details/41145019)\n\n","source":"_posts/linux-shell--bash数组与映射.md","raw":"---\ntitle: bash 数组与映射\ndate: 2017-10-22 23:32:19\ncategories:\n  - linux\n  - shell\ntags:\n  - linux:shell\n---\n\n> 注: bash 映射 (map) 在文档里叫做 `关联数组 (associated array)`, 使用关联数组的最低 bash 版本是 4.1.2;\n\n<!--more-->\n\n## **数组/关联数组 的创建**\n### **静态创建**\n使用类型限定 declare 定义:\n``` bash\n# 数组\ndeclare -a array1=('a' 'b' 'c')\ndeclare -a array2=(a b c)\n# 关联数组\ndeclare -A map1=([\"a\"]=\"aa\" [\"b\"]=\"bb\" [\"c\"]=\"cc\")\ndeclare -A map2=([a]=aa [b]=bb [c]=cc)\n```\n如果不带类型限定, bash 不会自动推断 关联数组 类型:\n``` bash\nobject1=(a b c)\nobject2=([\"a\"]=\"aa\" [\"b\"]=\"bb\" [\"c\"]=\"cc\")\n```\n对于以上两者, bash 都将推断为 普通数组 类型, 其中 object2 中有三个 string 元素: [\"a\"]=\"aa\", [\"b\"]=\"bb\" 与 [\"c\"]=\"cc\";\n\n### **动态创建**\n以上展示了 数组/动态数组 的静态创建方式;\n更复杂的场景是, 由一段其他复杂命令的输出, 赋值构建一个数组类型:\n``` bash\npair_array=(`sed -n -e '6,/}/p' -e '$d' ${formatted_curl_response_file} | awk -F ':' '{\n    log_length = length($1);\n    app_code_length = length($2);\n    log_path = substr($1, 2, log_length - 2);\n    app_code = substr($2, 2, app_code_length - 2);\n    map[log_path] = app_code\n} END {\n    for (key in map) {\n        printf (\"%10s=%10s \", key, map[key])\n    }\n}'`)\n```\n以上逻辑, 由 sed 与 awk 两重管道输出目标内容, 作为创建数组的参数, 以达到动态创建的目的;\n但是, 以上方式只适用于创建 数组, 而不适用于创建 关联数组, 原因与上一节 静态创建数组 中所表述的相同: 即使输出格式符合定义规范, bash 并不会自动推断为 关联数组;\n&nbsp;\n另外, 企图通过 declare 强制限定类型去动态创建, 也是不合法的:\n``` bash\n> declare -A map=(`last -n 1 | head -n 1 | awk '{map[$1]=$3} END{for (key in map) {printf (\"[%10s]=%10s \", key, map[key])}}'`)\n# 以上语句会报如下错误:\n-bash: map: [: must use subscript when assigning associative array\n-bash: map: zshell.z]=113.44.125.146: must use subscript when assigning associative array\n```\n因为, 通过 ``, $() 等命令代换, [zshell.z]=113.44.125.146 这样的输出内容被当作命令执行, 而 [ 这是一个 bash 的内置命令, 用于条件判断;\n显然 zshell.z]=113.44.125.146 这样的语句是不符合条件判断的参数输入的;\n\n## **数组/关联数组 的使用**\n单独赋值:\n``` bash\nmap['a']='aaa'\narray[0]=aaa\n```\n获取数据:\n``` bash\n# 获得所有 values\necho ${map[@]}\necho ${array[@]}\n# 获得某个单独的值\nvar=${map['a']}\nvar=${array[0]}\n# 获得所有 keys (对于数组而言, 就是获得所有的索引下标)\nfor key in ${!map[@]}; do\n    ...\ndone\nfor key in ${!array[@]}; do\n    ...\ndone\n```\n\n## **参考链接**\n- [shell中的map使用](http://blog.csdn.net/adermxl/article/details/41145019)\n\n","slug":"linux-shell--bash数组与映射","published":1,"updated":"2018-01-03T15:18:11.226Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cje24mxtw000aj1jx4sfjjmjr","content":"<blockquote>\n<p>注: bash 映射 (map) 在文档里叫做 <code>关联数组 (associated array)</code>, 使用关联数组的最低 bash 版本是 4.1.2;</p>\n</blockquote>\n<a id=\"more\"></a>\n<h2 id=\"数组-关联数组-的创建\"><a href=\"#数组-关联数组-的创建\" class=\"headerlink\" title=\"数组/关联数组 的创建\"></a><strong>数组/关联数组 的创建</strong></h2><h3 id=\"静态创建\"><a href=\"#静态创建\" class=\"headerlink\" title=\"静态创建\"></a><strong>静态创建</strong></h3><p>使用类型限定 declare 定义:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 数组</span></span><br><span class=\"line\"><span class=\"built_in\">declare</span> -a array1=(<span class=\"string\">'a'</span> <span class=\"string\">'b'</span> <span class=\"string\">'c'</span>)</span><br><span class=\"line\"><span class=\"built_in\">declare</span> -a array2=(a b c)</span><br><span class=\"line\"><span class=\"comment\"># 关联数组</span></span><br><span class=\"line\"><span class=\"built_in\">declare</span> -A map1=([<span class=\"string\">\"a\"</span>]=<span class=\"string\">\"aa\"</span> [<span class=\"string\">\"b\"</span>]=<span class=\"string\">\"bb\"</span> [<span class=\"string\">\"c\"</span>]=<span class=\"string\">\"cc\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">declare</span> -A map2=([a]=aa [b]=bb [c]=cc)</span><br></pre></td></tr></table></figure></p>\n<p>如果不带类型限定, bash 不会自动推断 关联数组 类型:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">object1=(a b c)</span><br><span class=\"line\">object2=([<span class=\"string\">\"a\"</span>]=<span class=\"string\">\"aa\"</span> [<span class=\"string\">\"b\"</span>]=<span class=\"string\">\"bb\"</span> [<span class=\"string\">\"c\"</span>]=<span class=\"string\">\"cc\"</span>)</span><br></pre></td></tr></table></figure></p>\n<p>对于以上两者, bash 都将推断为 普通数组 类型, 其中 object2 中有三个 string 元素: [“a”]=”aa”, [“b”]=”bb” 与 [“c”]=”cc”;</p>\n<h3 id=\"动态创建\"><a href=\"#动态创建\" class=\"headerlink\" title=\"动态创建\"></a><strong>动态创建</strong></h3><p>以上展示了 数组/动态数组 的静态创建方式;<br>更复杂的场景是, 由一段其他复杂命令的输出, 赋值构建一个数组类型:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pair_array=(`sed -n -e <span class=\"string\">'6,/&#125;/p'</span> -e <span class=\"string\">'$d'</span> <span class=\"variable\">$&#123;formatted_curl_response_file&#125;</span> | awk -F <span class=\"string\">':'</span> <span class=\"string\">'&#123;</span></span><br><span class=\"line\"><span class=\"string\">    log_length = length($1);</span></span><br><span class=\"line\"><span class=\"string\">    app_code_length = length($2);</span></span><br><span class=\"line\"><span class=\"string\">    log_path = substr($1, 2, log_length - 2);</span></span><br><span class=\"line\"><span class=\"string\">    app_code = substr($2, 2, app_code_length - 2);</span></span><br><span class=\"line\"><span class=\"string\">    map[log_path] = app_code</span></span><br><span class=\"line\"><span class=\"string\">&#125; END &#123;</span></span><br><span class=\"line\"><span class=\"string\">    for (key in map) &#123;</span></span><br><span class=\"line\"><span class=\"string\">        printf (\"%10s=%10s \", key, map[key])</span></span><br><span class=\"line\"><span class=\"string\">    &#125;</span></span><br><span class=\"line\"><span class=\"string\">&#125;'</span>`)</span><br></pre></td></tr></table></figure></p>\n<p>以上逻辑, 由 sed 与 awk 两重管道输出目标内容, 作为创建数组的参数, 以达到动态创建的目的;<br>但是, 以上方式只适用于创建 数组, 而不适用于创建 关联数组, 原因与上一节 静态创建数组 中所表述的相同: 即使输出格式符合定义规范, bash 并不会自动推断为 关联数组;<br>&nbsp;<br>另外, 企图通过 declare 强制限定类型去动态创建, 也是不合法的:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; <span class=\"built_in\">declare</span> -A map=(`last -n 1 | head -n 1 | awk <span class=\"string\">'&#123;map[$1]=$3&#125; END&#123;for (key in map) &#123;printf (\"[%10s]=%10s \", key, map[key])&#125;&#125;'</span>`)</span><br><span class=\"line\"><span class=\"comment\"># 以上语句会报如下错误:</span></span><br><span class=\"line\">-bash: map: [: must use subscript when assigning associative array</span><br><span class=\"line\">-bash: map: zshell.z]=113.44.125.146: must use subscript when assigning associative array</span><br></pre></td></tr></table></figure></p>\n<p>因为, 通过 ``, $() 等命令代换, [zshell.z]=113.44.125.146 这样的输出内容被当作命令执行, 而 [ 这是一个 bash 的内置命令, 用于条件判断;<br>显然 zshell.z]=113.44.125.146 这样的语句是不符合条件判断的参数输入的;</p>\n<h2 id=\"数组-关联数组-的使用\"><a href=\"#数组-关联数组-的使用\" class=\"headerlink\" title=\"数组/关联数组 的使用\"></a><strong>数组/关联数组 的使用</strong></h2><p>单独赋值:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">map[<span class=\"string\">'a'</span>]=<span class=\"string\">'aaa'</span></span><br><span class=\"line\">array[0]=aaa</span><br></pre></td></tr></table></figure></p>\n<p>获取数据:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 获得所有 values</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"variable\">$&#123;map[@]&#125;</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"variable\">$&#123;array[@]&#125;</span></span><br><span class=\"line\"><span class=\"comment\"># 获得某个单独的值</span></span><br><span class=\"line\">var=<span class=\"variable\">$&#123;map['a']&#125;</span></span><br><span class=\"line\">var=<span class=\"variable\">$&#123;array[0]&#125;</span></span><br><span class=\"line\"><span class=\"comment\"># 获得所有 keys (对于数组而言, 就是获得所有的索引下标)</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> key <span class=\"keyword\">in</span> <span class=\"variable\">$&#123;!map[@]&#125;</span>; <span class=\"keyword\">do</span></span><br><span class=\"line\">    ...</span><br><span class=\"line\"><span class=\"keyword\">done</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> key <span class=\"keyword\">in</span> <span class=\"variable\">$&#123;!array[@]&#125;</span>; <span class=\"keyword\">do</span></span><br><span class=\"line\">    ...</span><br><span class=\"line\"><span class=\"keyword\">done</span></span><br></pre></td></tr></table></figure></p>\n<h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a><strong>参考链接</strong></h2><ul>\n<li><a href=\"http://blog.csdn.net/adermxl/article/details/41145019\" target=\"_blank\" rel=\"noopener\">shell中的map使用</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>注: bash 映射 (map) 在文档里叫做 <code>关联数组 (associated array)</code>, 使用关联数组的最低 bash 版本是 4.1.2;</p>\n</blockquote>","more":"<h2 id=\"数组-关联数组-的创建\"><a href=\"#数组-关联数组-的创建\" class=\"headerlink\" title=\"数组/关联数组 的创建\"></a><strong>数组/关联数组 的创建</strong></h2><h3 id=\"静态创建\"><a href=\"#静态创建\" class=\"headerlink\" title=\"静态创建\"></a><strong>静态创建</strong></h3><p>使用类型限定 declare 定义:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 数组</span></span><br><span class=\"line\"><span class=\"built_in\">declare</span> -a array1=(<span class=\"string\">'a'</span> <span class=\"string\">'b'</span> <span class=\"string\">'c'</span>)</span><br><span class=\"line\"><span class=\"built_in\">declare</span> -a array2=(a b c)</span><br><span class=\"line\"><span class=\"comment\"># 关联数组</span></span><br><span class=\"line\"><span class=\"built_in\">declare</span> -A map1=([<span class=\"string\">\"a\"</span>]=<span class=\"string\">\"aa\"</span> [<span class=\"string\">\"b\"</span>]=<span class=\"string\">\"bb\"</span> [<span class=\"string\">\"c\"</span>]=<span class=\"string\">\"cc\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">declare</span> -A map2=([a]=aa [b]=bb [c]=cc)</span><br></pre></td></tr></table></figure></p>\n<p>如果不带类型限定, bash 不会自动推断 关联数组 类型:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">object1=(a b c)</span><br><span class=\"line\">object2=([<span class=\"string\">\"a\"</span>]=<span class=\"string\">\"aa\"</span> [<span class=\"string\">\"b\"</span>]=<span class=\"string\">\"bb\"</span> [<span class=\"string\">\"c\"</span>]=<span class=\"string\">\"cc\"</span>)</span><br></pre></td></tr></table></figure></p>\n<p>对于以上两者, bash 都将推断为 普通数组 类型, 其中 object2 中有三个 string 元素: [“a”]=”aa”, [“b”]=”bb” 与 [“c”]=”cc”;</p>\n<h3 id=\"动态创建\"><a href=\"#动态创建\" class=\"headerlink\" title=\"动态创建\"></a><strong>动态创建</strong></h3><p>以上展示了 数组/动态数组 的静态创建方式;<br>更复杂的场景是, 由一段其他复杂命令的输出, 赋值构建一个数组类型:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pair_array=(`sed -n -e <span class=\"string\">'6,/&#125;/p'</span> -e <span class=\"string\">'$d'</span> <span class=\"variable\">$&#123;formatted_curl_response_file&#125;</span> | awk -F <span class=\"string\">':'</span> <span class=\"string\">'&#123;</span></span><br><span class=\"line\"><span class=\"string\">    log_length = length($1);</span></span><br><span class=\"line\"><span class=\"string\">    app_code_length = length($2);</span></span><br><span class=\"line\"><span class=\"string\">    log_path = substr($1, 2, log_length - 2);</span></span><br><span class=\"line\"><span class=\"string\">    app_code = substr($2, 2, app_code_length - 2);</span></span><br><span class=\"line\"><span class=\"string\">    map[log_path] = app_code</span></span><br><span class=\"line\"><span class=\"string\">&#125; END &#123;</span></span><br><span class=\"line\"><span class=\"string\">    for (key in map) &#123;</span></span><br><span class=\"line\"><span class=\"string\">        printf (\"%10s=%10s \", key, map[key])</span></span><br><span class=\"line\"><span class=\"string\">    &#125;</span></span><br><span class=\"line\"><span class=\"string\">&#125;'</span>`)</span><br></pre></td></tr></table></figure></p>\n<p>以上逻辑, 由 sed 与 awk 两重管道输出目标内容, 作为创建数组的参数, 以达到动态创建的目的;<br>但是, 以上方式只适用于创建 数组, 而不适用于创建 关联数组, 原因与上一节 静态创建数组 中所表述的相同: 即使输出格式符合定义规范, bash 并不会自动推断为 关联数组;<br>&nbsp;<br>另外, 企图通过 declare 强制限定类型去动态创建, 也是不合法的:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; <span class=\"built_in\">declare</span> -A map=(`last -n 1 | head -n 1 | awk <span class=\"string\">'&#123;map[$1]=$3&#125; END&#123;for (key in map) &#123;printf (\"[%10s]=%10s \", key, map[key])&#125;&#125;'</span>`)</span><br><span class=\"line\"><span class=\"comment\"># 以上语句会报如下错误:</span></span><br><span class=\"line\">-bash: map: [: must use subscript when assigning associative array</span><br><span class=\"line\">-bash: map: zshell.z]=113.44.125.146: must use subscript when assigning associative array</span><br></pre></td></tr></table></figure></p>\n<p>因为, 通过 ``, $() 等命令代换, [zshell.z]=113.44.125.146 这样的输出内容被当作命令执行, 而 [ 这是一个 bash 的内置命令, 用于条件判断;<br>显然 zshell.z]=113.44.125.146 这样的语句是不符合条件判断的参数输入的;</p>\n<h2 id=\"数组-关联数组-的使用\"><a href=\"#数组-关联数组-的使用\" class=\"headerlink\" title=\"数组/关联数组 的使用\"></a><strong>数组/关联数组 的使用</strong></h2><p>单独赋值:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">map[<span class=\"string\">'a'</span>]=<span class=\"string\">'aaa'</span></span><br><span class=\"line\">array[0]=aaa</span><br></pre></td></tr></table></figure></p>\n<p>获取数据:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 获得所有 values</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"variable\">$&#123;map[@]&#125;</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"variable\">$&#123;array[@]&#125;</span></span><br><span class=\"line\"><span class=\"comment\"># 获得某个单独的值</span></span><br><span class=\"line\">var=<span class=\"variable\">$&#123;map['a']&#125;</span></span><br><span class=\"line\">var=<span class=\"variable\">$&#123;array[0]&#125;</span></span><br><span class=\"line\"><span class=\"comment\"># 获得所有 keys (对于数组而言, 就是获得所有的索引下标)</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> key <span class=\"keyword\">in</span> <span class=\"variable\">$&#123;!map[@]&#125;</span>; <span class=\"keyword\">do</span></span><br><span class=\"line\">    ...</span><br><span class=\"line\"><span class=\"keyword\">done</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> key <span class=\"keyword\">in</span> <span class=\"variable\">$&#123;!array[@]&#125;</span>; <span class=\"keyword\">do</span></span><br><span class=\"line\">    ...</span><br><span class=\"line\"><span class=\"keyword\">done</span></span><br></pre></td></tr></table></figure></p>\n<h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a><strong>参考链接</strong></h2><ul>\n<li><a href=\"http://blog.csdn.net/adermxl/article/details/41145019\" target=\"_blank\" rel=\"noopener\">shell中的map使用</a></li>\n</ul>"},{"title":"logrotate 配置与运维","date":"2018-01-14T16:23:27.000Z","_content":"\n> 本文主要讨论以下几个方面:\n1. logrotate 的关键配置文件和配置项语法;\n2. logrotate 的使用与运维技巧;\n3. logrotate 的运行原理;\n4. 特殊场景下 logrotate 的代替方案;\n\n<!--more-->\n\n------\n\n### **配置文件与配置语法**\nlogrotate 的配置文件主要是 `/etc/logrotate.conf` 和 `/etc/logrotate.d` 目录;\n/etc/logrotate.conf 文件作为主配置文件, include 了 /etc/logrotate.d 目录下具体的配置内容;\n以下是 /etc/logrotate.conf 的默认内容:\n``` bash\n# 默认的历史日志保留周期单位: 周\nweekly\n# 历史日志保留四个周期单位, 即四周, 一个月\nrotate 4\n# use the syslog group by default, since this is the owning group of /var/log/syslog.\nsu root syslog\n# 当旧日志作了 rotate 之后, 将会创建一个和旧日志同名的新文件\ncreate\n# 默认使用 gzip 压缩旧日志文件\ncompress\n# 将 /etc/logrotate.d 下面的所有独立配置文件都 include 进来\ninclude /etc/logrotate.d\n```\n/etc/logrotate.conf 的默认配置优先级比 /etc/logrotate.d/ 目录下的独立配置要低, /etc/logrotate.d 下所有的独立配置文件中的配置项可以覆盖 /etc/logrotate.conf;\n以 rsyslog 的配置文件为例, 以下是 /etc/logrotate.d/rsyslog 的内容:\n``` bash\n/var/log/syslog {\n    # 以 天 为周期单位, 保留 7 天的日志\n    daily\n    rotate 7\n\t\n    # 忽略任何错误, 比如找不到文件\n    missingok\n\t\n    # not if empty, 当日志内容为空时, 不作 rotate\n    notifempty\n\t\n    # 压缩日志, 但是采用延时压缩, 即本轮周期产生的日志不压缩, 而在下一个周期时压缩之\n    compress\n    delaycompress\n\t\n    # postrotate/endscript 内的命令, 作为后处理, 会在本轮周期 rotate 之后回调执行\n    postrotate\n\tinvoke-rc.d rsyslog rotate > /dev/null\n    endscript\n}\n\n# 可以同时指定多个目标日志使用同一段配置\n/var/log/mail.info\n/var/log/mail.warn\n/var/log/mail.err\n/var/log/mail.log\n/var/log/daemon.log\n/var/log/kern.log\n/var/log/auth.log\n/var/log/user.log\n/var/log/lpr.log\n/var/log/cron.log\n/var/log/debug\n/var/log/messages {\n    weekly\n    rotate 4\n\t\n    missingok\n    notifempty\n\t\n    compress\n    delaycompress\n\t\n    # 共享处理脚本, 仅对 prerotate/postrotate 定义时生效\n    sharedscripts\n\t\n    postrotate\n\tinvoke-rc.d rsyslog rotate > /dev/null\n    endscript\n}\n```\n注意:\n\n1. `sharedscripts` 选项打开后, 所有使用该段配置作 rotate 的目标日志名都会作为参数一次性传给 prerotate/postrotate;\n而默认的选项 `nosharedscripts` 则是将每一个日志名分别作为参数传给 prerotate/postrotate;\n2. logrotate 支持的周期单位, 有 hourly, daily, weekly, monthly; 但是这里有坑: hourly 默认是不生效的, 具体原因见本文第三节;\n\n&nbsp;\n如上所叙, prerotate/postrotate 是一种在 rotate 过程中某个时机回调的一段脚本, 像这样类似的配置项总共有如下几种 (所有的配置项必须与 `endscript` 成对出现):\n``` bash\n# 在所有匹配的日志 rotate 之前, 仅执行一次\nfirstaction/endscript\n# 在日志 rotate 之前回调\nprerotate/endscript\n# 在日志 rotate 之后回调\npostrotate/endscript\n# 在所有匹配的日志 rotate 之后, 仅执行一次\nlastaction/endscript\n\n# 在某个日志将要被删除之前回调执行\npreremove/endscript\n```\n这几种回调时间点的设计, 不禁让人想到 junit 测试类几种注解的方法执行时机, 不得不说有异曲同工之妙;\n&nbsp;\nrsyslog 的 logrotate 配置是一个典型, 但同时 logrotate 还有着其他的个性化配置选项:\n``` bash\n# 以下是另一段案例\n/var/log/test.log {\n    # 不以时间为周期单位, 而是以 日志size 为周期单位, 当日志大小达到 100MB 时, 作一次 rotate, 日志保留 5 个周期\n    size=100M\n    rotate 5\n    \n    # 使用日期命名 rotate 后的旧文件, 日期格式采用 -%Y-%m-%d\n    dateext\n    dateformat -%Y-%m-%d\n    \n    # 以指定的权限掩码, owner/group 创建 rotate 后的新文件\n    create 644 root root\n    \n    postrotate\n        /usr/bin/killall -HUP rsyslogd\n    endscript\n}\n```\n\n### **logrotate 命令的常用运维选项**\n1.指定目标配置文件, 手动执行:\n``` bash\n# 将会执行 /etc/logrotate.d/ 下所有的配置\nlogrotate /etc/logrotate.conf\n# 将会只执行指定配置文件中的配置\nlogrotate /etc/logrotate.d/xxx.log\n```\n2.debug 验证配置文件正误:\n``` bash\n# -d:   --debug\n> logrotate -d /etc/logrotate.d/redis-server.log\n# output\nreading config file /etc/logrotate.d/redis-server\nHandling 1 logs\nrotating pattern: /var/log/redis/redis-server*.log  weekly (12 rotations)\nempty log files are not rotated, old logs are removed\nconsidering log /var/log/redis/redis-server.log\n  log does not need rotating\n```\n3.强制 rotate:\n即便当前不满足 rotate 的条件, force rotate 也会强制作一次 rotate, 而那些超过指定轮数的旧日志将会被删除;\nforce rotate 比较适用于加入了新的配置文件, 需要对其存量历史立即作一次 rotate;\n``` bash\n# -f:   --force\nlogrotate -f /etc/logrotate.d/xxx.log\n```\n4.verbose 详细信息:\n``` bash\n# -v:   --verbose\nlogrotate -vf /etc/logrotate.d/xxx.log\n```\n5.指定 logrotate 自身的日志文件路径:\n``` bash\n# -s:   --state\n# 默认 logrotate 的日志路径: /var/lib/logrotate/status\nlogrotate -s /tmp/logrotate.log /etc/logrotate.conf\n```\n\n### **logrotate 的运行原理及其缺陷**\nlogrotate 并不是一个 daemon service, 其本质上只是一个 '什么时候调用就什么时候立即执行一次' 的 C 程序;\n所以 logrotate 的执行, 依赖于其他 daemon service 的调用, 那么最自然的就是通过 crond 定时任务来调用了;\n默认情况下, logrotate 是一天被调用一次的, 因为与它相关的 crontab 配置在 `/etc/cron.daily` 里:\n``` bash\n#!/bin/sh\n\n# Clean non existent log file entries from status file\ncd /var/lib/logrotate\ntest -e status || touch status\nhead -1 status > status.clean\nsed 's/\"//g' status | while read logfile date\ndo\n    [ -e \"$logfile\" ] && echo \"\\\"$logfile\\\" $date\"\ndone >> status.clean\nmv status.clean status\n\ntest -x /usr/sbin/logrotate || exit 0\n/usr/sbin/logrotate /etc/logrotate.conf\n```\n如本文第二节所述, 由于 logrotate 的执行方式是通过 cron 默认 1 天执行一次, 所以按小时 rotate 的 `hourly` 配置项, 默认是不生效的; logrotate 的 manual 文档里也有说明:\n> `hourly` Log files are rotated every hour. Note that usually logrotate is configured to be run by cron daily. You have to change this configuration and run logrotate hourly to be able to really rotate logs hourly.\n\n不过, 这还不是最大的问题, 毕竟我们只要把上述脚本放到 `cron.hourly` 里, 就能解决该问题;\n这种靠定时任务来运行的方式, 最大的问题是: 当我们对某个日志配置成按 `size` 来 rotate 时, 无法做到当日志触达 size 条件时及时切分, 其所能实现的最小延时是一分钟 (当把 logrotate 脚本的定时任务配成 \\* \\* \\* \\* \\*, 即每分钟执行一次时), 没法更短了;\n\n### **其他的特殊场景**\nlogrotate 集日志切分, 日志压缩, 删除旧日志, 邮件提醒等功能为一体, 提供了非常完整的日志管理策略; 不过, 并不是所有的系统日志, 自身都不具有上述功能, 都需要依赖 logrotate 来管理自己;\n有一个非常典型, 而且使用十分广泛的场景: tomcat web 服务器; 当我们在 tomcat 上部署的服务使用了诸如 logback 之类的第三方日志框架时, 日志切分, 日志压缩等服务它自己便能够胜任了 (与 logback 相关功能的文章请见: [logback appender 使用总结]()), 而且我们绝大部分人 (去哪儿网), 即便不怎么接触 logback 的日志压缩功能, 也至少都习惯于使用 logback  `RollingFileAppender` 的基础功能去作日志切分;\n基于以上, 我们只需要一个简单的脚本, 便能够满足日常的 tomcat web 服务器日志运维:\n``` bash\n#!/bin/bash\nHOUR1=$(date -d \"1 hours ago\" +%F-%H)\nDATE7=$(date -d \"7 days ago\" +%F-%H)\n# for example: /home/web/my_server/logs\nfor i in `find /home/web/ -maxdepth 2 \\( -type d -o -type l \\) -name logs`; do\n        find -L $i -maxdepth 1 -type f \\( -name \"*${HOUR1}*\" -a ! -name \"*.gz\" \\) -exec gzip {} \\;\n        find -L $i -maxdepth 1 -type f \\( -name \"*${DATE7}*\" -a -name \"*.gz\" \\) -exec rm -f {} \\;\ndone\n```\n本节内容讨论的是针对 tomcat web 系统上的日志切分, 压缩, 以及删除等常规运维内容; 其实, 针对公司各业务线 web 系统的业务日志, 除此之外至少还有另外两项重要的运维内容: *日志冷备份收集* 与 *日志实时收集及其可视化 (ELK)*; 与之相关的内容请参见如下文章: \n\n1. [改造 flume-ng: 融入公司的技术体系]();\n2. [日志冷备份收集的方案选型]();\n\n### **站内相关文章**\n- [cron 相关全梳理]()\n- [logback appender 使用总结]()\n- [改造 flume-ng: 融入公司的技术体系]()\n- [日志冷备份收集的方案选型]()\n\n### **参考链接**\n- [Linux日志文件总管——logrotate](https://linux.cn/article-4126-1.html)\n- [被遗忘的 Logrotate](https://huoding.com/2013/04/21/246)\n\n","source":"_posts/linux-varlog--logrotate配置与运维.md","raw":"---\ntitle: logrotate 配置与运维\ndate: 2018-01-15 00:23:27\ncategories:\n - linux\n - varlog\ntags:\n - linux:varlog\n---\n\n> 本文主要讨论以下几个方面:\n1. logrotate 的关键配置文件和配置项语法;\n2. logrotate 的使用与运维技巧;\n3. logrotate 的运行原理;\n4. 特殊场景下 logrotate 的代替方案;\n\n<!--more-->\n\n------\n\n### **配置文件与配置语法**\nlogrotate 的配置文件主要是 `/etc/logrotate.conf` 和 `/etc/logrotate.d` 目录;\n/etc/logrotate.conf 文件作为主配置文件, include 了 /etc/logrotate.d 目录下具体的配置内容;\n以下是 /etc/logrotate.conf 的默认内容:\n``` bash\n# 默认的历史日志保留周期单位: 周\nweekly\n# 历史日志保留四个周期单位, 即四周, 一个月\nrotate 4\n# use the syslog group by default, since this is the owning group of /var/log/syslog.\nsu root syslog\n# 当旧日志作了 rotate 之后, 将会创建一个和旧日志同名的新文件\ncreate\n# 默认使用 gzip 压缩旧日志文件\ncompress\n# 将 /etc/logrotate.d 下面的所有独立配置文件都 include 进来\ninclude /etc/logrotate.d\n```\n/etc/logrotate.conf 的默认配置优先级比 /etc/logrotate.d/ 目录下的独立配置要低, /etc/logrotate.d 下所有的独立配置文件中的配置项可以覆盖 /etc/logrotate.conf;\n以 rsyslog 的配置文件为例, 以下是 /etc/logrotate.d/rsyslog 的内容:\n``` bash\n/var/log/syslog {\n    # 以 天 为周期单位, 保留 7 天的日志\n    daily\n    rotate 7\n\t\n    # 忽略任何错误, 比如找不到文件\n    missingok\n\t\n    # not if empty, 当日志内容为空时, 不作 rotate\n    notifempty\n\t\n    # 压缩日志, 但是采用延时压缩, 即本轮周期产生的日志不压缩, 而在下一个周期时压缩之\n    compress\n    delaycompress\n\t\n    # postrotate/endscript 内的命令, 作为后处理, 会在本轮周期 rotate 之后回调执行\n    postrotate\n\tinvoke-rc.d rsyslog rotate > /dev/null\n    endscript\n}\n\n# 可以同时指定多个目标日志使用同一段配置\n/var/log/mail.info\n/var/log/mail.warn\n/var/log/mail.err\n/var/log/mail.log\n/var/log/daemon.log\n/var/log/kern.log\n/var/log/auth.log\n/var/log/user.log\n/var/log/lpr.log\n/var/log/cron.log\n/var/log/debug\n/var/log/messages {\n    weekly\n    rotate 4\n\t\n    missingok\n    notifempty\n\t\n    compress\n    delaycompress\n\t\n    # 共享处理脚本, 仅对 prerotate/postrotate 定义时生效\n    sharedscripts\n\t\n    postrotate\n\tinvoke-rc.d rsyslog rotate > /dev/null\n    endscript\n}\n```\n注意:\n\n1. `sharedscripts` 选项打开后, 所有使用该段配置作 rotate 的目标日志名都会作为参数一次性传给 prerotate/postrotate;\n而默认的选项 `nosharedscripts` 则是将每一个日志名分别作为参数传给 prerotate/postrotate;\n2. logrotate 支持的周期单位, 有 hourly, daily, weekly, monthly; 但是这里有坑: hourly 默认是不生效的, 具体原因见本文第三节;\n\n&nbsp;\n如上所叙, prerotate/postrotate 是一种在 rotate 过程中某个时机回调的一段脚本, 像这样类似的配置项总共有如下几种 (所有的配置项必须与 `endscript` 成对出现):\n``` bash\n# 在所有匹配的日志 rotate 之前, 仅执行一次\nfirstaction/endscript\n# 在日志 rotate 之前回调\nprerotate/endscript\n# 在日志 rotate 之后回调\npostrotate/endscript\n# 在所有匹配的日志 rotate 之后, 仅执行一次\nlastaction/endscript\n\n# 在某个日志将要被删除之前回调执行\npreremove/endscript\n```\n这几种回调时间点的设计, 不禁让人想到 junit 测试类几种注解的方法执行时机, 不得不说有异曲同工之妙;\n&nbsp;\nrsyslog 的 logrotate 配置是一个典型, 但同时 logrotate 还有着其他的个性化配置选项:\n``` bash\n# 以下是另一段案例\n/var/log/test.log {\n    # 不以时间为周期单位, 而是以 日志size 为周期单位, 当日志大小达到 100MB 时, 作一次 rotate, 日志保留 5 个周期\n    size=100M\n    rotate 5\n    \n    # 使用日期命名 rotate 后的旧文件, 日期格式采用 -%Y-%m-%d\n    dateext\n    dateformat -%Y-%m-%d\n    \n    # 以指定的权限掩码, owner/group 创建 rotate 后的新文件\n    create 644 root root\n    \n    postrotate\n        /usr/bin/killall -HUP rsyslogd\n    endscript\n}\n```\n\n### **logrotate 命令的常用运维选项**\n1.指定目标配置文件, 手动执行:\n``` bash\n# 将会执行 /etc/logrotate.d/ 下所有的配置\nlogrotate /etc/logrotate.conf\n# 将会只执行指定配置文件中的配置\nlogrotate /etc/logrotate.d/xxx.log\n```\n2.debug 验证配置文件正误:\n``` bash\n# -d:   --debug\n> logrotate -d /etc/logrotate.d/redis-server.log\n# output\nreading config file /etc/logrotate.d/redis-server\nHandling 1 logs\nrotating pattern: /var/log/redis/redis-server*.log  weekly (12 rotations)\nempty log files are not rotated, old logs are removed\nconsidering log /var/log/redis/redis-server.log\n  log does not need rotating\n```\n3.强制 rotate:\n即便当前不满足 rotate 的条件, force rotate 也会强制作一次 rotate, 而那些超过指定轮数的旧日志将会被删除;\nforce rotate 比较适用于加入了新的配置文件, 需要对其存量历史立即作一次 rotate;\n``` bash\n# -f:   --force\nlogrotate -f /etc/logrotate.d/xxx.log\n```\n4.verbose 详细信息:\n``` bash\n# -v:   --verbose\nlogrotate -vf /etc/logrotate.d/xxx.log\n```\n5.指定 logrotate 自身的日志文件路径:\n``` bash\n# -s:   --state\n# 默认 logrotate 的日志路径: /var/lib/logrotate/status\nlogrotate -s /tmp/logrotate.log /etc/logrotate.conf\n```\n\n### **logrotate 的运行原理及其缺陷**\nlogrotate 并不是一个 daemon service, 其本质上只是一个 '什么时候调用就什么时候立即执行一次' 的 C 程序;\n所以 logrotate 的执行, 依赖于其他 daemon service 的调用, 那么最自然的就是通过 crond 定时任务来调用了;\n默认情况下, logrotate 是一天被调用一次的, 因为与它相关的 crontab 配置在 `/etc/cron.daily` 里:\n``` bash\n#!/bin/sh\n\n# Clean non existent log file entries from status file\ncd /var/lib/logrotate\ntest -e status || touch status\nhead -1 status > status.clean\nsed 's/\"//g' status | while read logfile date\ndo\n    [ -e \"$logfile\" ] && echo \"\\\"$logfile\\\" $date\"\ndone >> status.clean\nmv status.clean status\n\ntest -x /usr/sbin/logrotate || exit 0\n/usr/sbin/logrotate /etc/logrotate.conf\n```\n如本文第二节所述, 由于 logrotate 的执行方式是通过 cron 默认 1 天执行一次, 所以按小时 rotate 的 `hourly` 配置项, 默认是不生效的; logrotate 的 manual 文档里也有说明:\n> `hourly` Log files are rotated every hour. Note that usually logrotate is configured to be run by cron daily. You have to change this configuration and run logrotate hourly to be able to really rotate logs hourly.\n\n不过, 这还不是最大的问题, 毕竟我们只要把上述脚本放到 `cron.hourly` 里, 就能解决该问题;\n这种靠定时任务来运行的方式, 最大的问题是: 当我们对某个日志配置成按 `size` 来 rotate 时, 无法做到当日志触达 size 条件时及时切分, 其所能实现的最小延时是一分钟 (当把 logrotate 脚本的定时任务配成 \\* \\* \\* \\* \\*, 即每分钟执行一次时), 没法更短了;\n\n### **其他的特殊场景**\nlogrotate 集日志切分, 日志压缩, 删除旧日志, 邮件提醒等功能为一体, 提供了非常完整的日志管理策略; 不过, 并不是所有的系统日志, 自身都不具有上述功能, 都需要依赖 logrotate 来管理自己;\n有一个非常典型, 而且使用十分广泛的场景: tomcat web 服务器; 当我们在 tomcat 上部署的服务使用了诸如 logback 之类的第三方日志框架时, 日志切分, 日志压缩等服务它自己便能够胜任了 (与 logback 相关功能的文章请见: [logback appender 使用总结]()), 而且我们绝大部分人 (去哪儿网), 即便不怎么接触 logback 的日志压缩功能, 也至少都习惯于使用 logback  `RollingFileAppender` 的基础功能去作日志切分;\n基于以上, 我们只需要一个简单的脚本, 便能够满足日常的 tomcat web 服务器日志运维:\n``` bash\n#!/bin/bash\nHOUR1=$(date -d \"1 hours ago\" +%F-%H)\nDATE7=$(date -d \"7 days ago\" +%F-%H)\n# for example: /home/web/my_server/logs\nfor i in `find /home/web/ -maxdepth 2 \\( -type d -o -type l \\) -name logs`; do\n        find -L $i -maxdepth 1 -type f \\( -name \"*${HOUR1}*\" -a ! -name \"*.gz\" \\) -exec gzip {} \\;\n        find -L $i -maxdepth 1 -type f \\( -name \"*${DATE7}*\" -a -name \"*.gz\" \\) -exec rm -f {} \\;\ndone\n```\n本节内容讨论的是针对 tomcat web 系统上的日志切分, 压缩, 以及删除等常规运维内容; 其实, 针对公司各业务线 web 系统的业务日志, 除此之外至少还有另外两项重要的运维内容: *日志冷备份收集* 与 *日志实时收集及其可视化 (ELK)*; 与之相关的内容请参见如下文章: \n\n1. [改造 flume-ng: 融入公司的技术体系]();\n2. [日志冷备份收集的方案选型]();\n\n### **站内相关文章**\n- [cron 相关全梳理]()\n- [logback appender 使用总结]()\n- [改造 flume-ng: 融入公司的技术体系]()\n- [日志冷备份收集的方案选型]()\n\n### **参考链接**\n- [Linux日志文件总管——logrotate](https://linux.cn/article-4126-1.html)\n- [被遗忘的 Logrotate](https://huoding.com/2013/04/21/246)\n\n","slug":"linux-varlog--logrotate配置与运维","published":1,"updated":"2018-01-27T14:53:07.577Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cje24mxtz000bj1jxha7xg6kp","content":"<blockquote>\n<p>本文主要讨论以下几个方面:</p>\n<ol>\n<li>logrotate 的关键配置文件和配置项语法;</li>\n<li>logrotate 的使用与运维技巧;</li>\n<li>logrotate 的运行原理;</li>\n<li>特殊场景下 logrotate 的代替方案;</li>\n</ol>\n</blockquote>\n<a id=\"more\"></a>\n<hr>\n<h3 id=\"配置文件与配置语法\"><a href=\"#配置文件与配置语法\" class=\"headerlink\" title=\"配置文件与配置语法\"></a><strong>配置文件与配置语法</strong></h3><p>logrotate 的配置文件主要是 <code>/etc/logrotate.conf</code> 和 <code>/etc/logrotate.d</code> 目录;<br>/etc/logrotate.conf 文件作为主配置文件, include 了 /etc/logrotate.d 目录下具体的配置内容;<br>以下是 /etc/logrotate.conf 的默认内容:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 默认的历史日志保留周期单位: 周</span></span><br><span class=\"line\">weekly</span><br><span class=\"line\"><span class=\"comment\"># 历史日志保留四个周期单位, 即四周, 一个月</span></span><br><span class=\"line\">rotate 4</span><br><span class=\"line\"><span class=\"comment\"># use the syslog group by default, since this is the owning group of /var/log/syslog.</span></span><br><span class=\"line\">su root syslog</span><br><span class=\"line\"><span class=\"comment\"># 当旧日志作了 rotate 之后, 将会创建一个和旧日志同名的新文件</span></span><br><span class=\"line\">create</span><br><span class=\"line\"><span class=\"comment\"># 默认使用 gzip 压缩旧日志文件</span></span><br><span class=\"line\">compress</span><br><span class=\"line\"><span class=\"comment\"># 将 /etc/logrotate.d 下面的所有独立配置文件都 include 进来</span></span><br><span class=\"line\">include /etc/logrotate.d</span><br></pre></td></tr></table></figure></p>\n<p>/etc/logrotate.conf 的默认配置优先级比 /etc/logrotate.d/ 目录下的独立配置要低, /etc/logrotate.d 下所有的独立配置文件中的配置项可以覆盖 /etc/logrotate.conf;<br>以 rsyslog 的配置文件为例, 以下是 /etc/logrotate.d/rsyslog 的内容:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/var/<span class=\"built_in\">log</span>/syslog &#123;</span><br><span class=\"line\">    <span class=\"comment\"># 以 天 为周期单位, 保留 7 天的日志</span></span><br><span class=\"line\">    daily</span><br><span class=\"line\">    rotate 7</span><br><span class=\"line\">\t</span><br><span class=\"line\">    <span class=\"comment\"># 忽略任何错误, 比如找不到文件</span></span><br><span class=\"line\">    missingok</span><br><span class=\"line\">\t</span><br><span class=\"line\">    <span class=\"comment\"># not if empty, 当日志内容为空时, 不作 rotate</span></span><br><span class=\"line\">    notifempty</span><br><span class=\"line\">\t</span><br><span class=\"line\">    <span class=\"comment\"># 压缩日志, 但是采用延时压缩, 即本轮周期产生的日志不压缩, 而在下一个周期时压缩之</span></span><br><span class=\"line\">    compress</span><br><span class=\"line\">    delaycompress</span><br><span class=\"line\">\t</span><br><span class=\"line\">    <span class=\"comment\"># postrotate/endscript 内的命令, 作为后处理, 会在本轮周期 rotate 之后回调执行</span></span><br><span class=\"line\">    postrotate</span><br><span class=\"line\">\tinvoke-rc.d rsyslog rotate &gt; /dev/null</span><br><span class=\"line\">    endscript</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 可以同时指定多个目标日志使用同一段配置</span></span><br><span class=\"line\">/var/<span class=\"built_in\">log</span>/mail.info</span><br><span class=\"line\">/var/<span class=\"built_in\">log</span>/mail.warn</span><br><span class=\"line\">/var/<span class=\"built_in\">log</span>/mail.err</span><br><span class=\"line\">/var/<span class=\"built_in\">log</span>/mail.log</span><br><span class=\"line\">/var/<span class=\"built_in\">log</span>/daemon.log</span><br><span class=\"line\">/var/<span class=\"built_in\">log</span>/kern.log</span><br><span class=\"line\">/var/<span class=\"built_in\">log</span>/auth.log</span><br><span class=\"line\">/var/<span class=\"built_in\">log</span>/user.log</span><br><span class=\"line\">/var/<span class=\"built_in\">log</span>/lpr.log</span><br><span class=\"line\">/var/<span class=\"built_in\">log</span>/cron.log</span><br><span class=\"line\">/var/<span class=\"built_in\">log</span>/debug</span><br><span class=\"line\">/var/<span class=\"built_in\">log</span>/messages &#123;</span><br><span class=\"line\">    weekly</span><br><span class=\"line\">    rotate 4</span><br><span class=\"line\">\t</span><br><span class=\"line\">    missingok</span><br><span class=\"line\">    notifempty</span><br><span class=\"line\">\t</span><br><span class=\"line\">    compress</span><br><span class=\"line\">    delaycompress</span><br><span class=\"line\">\t</span><br><span class=\"line\">    <span class=\"comment\"># 共享处理脚本, 仅对 prerotate/postrotate 定义时生效</span></span><br><span class=\"line\">    sharedscripts</span><br><span class=\"line\">\t</span><br><span class=\"line\">    postrotate</span><br><span class=\"line\">\tinvoke-rc.d rsyslog rotate &gt; /dev/null</span><br><span class=\"line\">    endscript</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>注意:</p>\n<ol>\n<li><code>sharedscripts</code> 选项打开后, 所有使用该段配置作 rotate 的目标日志名都会作为参数一次性传给 prerotate/postrotate;<br>而默认的选项 <code>nosharedscripts</code> 则是将每一个日志名分别作为参数传给 prerotate/postrotate;</li>\n<li>logrotate 支持的周期单位, 有 hourly, daily, weekly, monthly; 但是这里有坑: hourly 默认是不生效的, 具体原因见本文第三节;</li>\n</ol>\n<p>&nbsp;<br>如上所叙, prerotate/postrotate 是一种在 rotate 过程中某个时机回调的一段脚本, 像这样类似的配置项总共有如下几种 (所有的配置项必须与 <code>endscript</code> 成对出现):<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 在所有匹配的日志 rotate 之前, 仅执行一次</span></span><br><span class=\"line\">firstaction/endscript</span><br><span class=\"line\"><span class=\"comment\"># 在日志 rotate 之前回调</span></span><br><span class=\"line\">prerotate/endscript</span><br><span class=\"line\"><span class=\"comment\"># 在日志 rotate 之后回调</span></span><br><span class=\"line\">postrotate/endscript</span><br><span class=\"line\"><span class=\"comment\"># 在所有匹配的日志 rotate 之后, 仅执行一次</span></span><br><span class=\"line\">lastaction/endscript</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 在某个日志将要被删除之前回调执行</span></span><br><span class=\"line\">preremove/endscript</span><br></pre></td></tr></table></figure></p>\n<p>这几种回调时间点的设计, 不禁让人想到 junit 测试类几种注解的方法执行时机, 不得不说有异曲同工之妙;<br>&nbsp;<br>rsyslog 的 logrotate 配置是一个典型, 但同时 logrotate 还有着其他的个性化配置选项:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 以下是另一段案例</span></span><br><span class=\"line\">/var/<span class=\"built_in\">log</span>/test.log &#123;</span><br><span class=\"line\">    <span class=\"comment\"># 不以时间为周期单位, 而是以 日志size 为周期单位, 当日志大小达到 100MB 时, 作一次 rotate, 日志保留 5 个周期</span></span><br><span class=\"line\">    size=100M</span><br><span class=\"line\">    rotate 5</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># 使用日期命名 rotate 后的旧文件, 日期格式采用 -%Y-%m-%d</span></span><br><span class=\"line\">    dateext</span><br><span class=\"line\">    dateformat -%Y-%m-%d</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># 以指定的权限掩码, owner/group 创建 rotate 后的新文件</span></span><br><span class=\"line\">    create 644 root root</span><br><span class=\"line\">    </span><br><span class=\"line\">    postrotate</span><br><span class=\"line\">        /usr/bin/killall -HUP rsyslogd</span><br><span class=\"line\">    endscript</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"logrotate-命令的常用运维选项\"><a href=\"#logrotate-命令的常用运维选项\" class=\"headerlink\" title=\"logrotate 命令的常用运维选项\"></a><strong>logrotate 命令的常用运维选项</strong></h3><p>1.指定目标配置文件, 手动执行:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 将会执行 /etc/logrotate.d/ 下所有的配置</span></span><br><span class=\"line\">logrotate /etc/logrotate.conf</span><br><span class=\"line\"><span class=\"comment\"># 将会只执行指定配置文件中的配置</span></span><br><span class=\"line\">logrotate /etc/logrotate.d/xxx.log</span><br></pre></td></tr></table></figure></p>\n<p>2.debug 验证配置文件正误:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># -d:   --debug</span></span><br><span class=\"line\">&gt; logrotate -d /etc/logrotate.d/redis-server.log</span><br><span class=\"line\"><span class=\"comment\"># output</span></span><br><span class=\"line\">reading config file /etc/logrotate.d/redis-server</span><br><span class=\"line\">Handling 1 logs</span><br><span class=\"line\">rotating pattern: /var/<span class=\"built_in\">log</span>/redis/redis-server*.<span class=\"built_in\">log</span>  weekly (12 rotations)</span><br><span class=\"line\">empty <span class=\"built_in\">log</span> files are not rotated, old logs are removed</span><br><span class=\"line\">considering <span class=\"built_in\">log</span> /var/<span class=\"built_in\">log</span>/redis/redis-server.log</span><br><span class=\"line\">  <span class=\"built_in\">log</span> does not need rotating</span><br></pre></td></tr></table></figure></p>\n<p>3.强制 rotate:<br>即便当前不满足 rotate 的条件, force rotate 也会强制作一次 rotate, 而那些超过指定轮数的旧日志将会被删除;<br>force rotate 比较适用于加入了新的配置文件, 需要对其存量历史立即作一次 rotate;<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># -f:   --force</span></span><br><span class=\"line\">logrotate -f /etc/logrotate.d/xxx.log</span><br></pre></td></tr></table></figure></p>\n<p>4.verbose 详细信息:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># -v:   --verbose</span></span><br><span class=\"line\">logrotate -vf /etc/logrotate.d/xxx.log</span><br></pre></td></tr></table></figure></p>\n<p>5.指定 logrotate 自身的日志文件路径:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># -s:   --state</span></span><br><span class=\"line\"><span class=\"comment\"># 默认 logrotate 的日志路径: /var/lib/logrotate/status</span></span><br><span class=\"line\">logrotate -s /tmp/logrotate.log /etc/logrotate.conf</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"logrotate-的运行原理及其缺陷\"><a href=\"#logrotate-的运行原理及其缺陷\" class=\"headerlink\" title=\"logrotate 的运行原理及其缺陷\"></a><strong>logrotate 的运行原理及其缺陷</strong></h3><p>logrotate 并不是一个 daemon service, 其本质上只是一个 ‘什么时候调用就什么时候立即执行一次’ 的 C 程序;<br>所以 logrotate 的执行, 依赖于其他 daemon service 的调用, 那么最自然的就是通过 crond 定时任务来调用了;<br>默认情况下, logrotate 是一天被调用一次的, 因为与它相关的 crontab 配置在 <code>/etc/cron.daily</code> 里:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#!/bin/sh</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Clean non existent log file entries from status file</span></span><br><span class=\"line\"><span class=\"built_in\">cd</span> /var/lib/logrotate</span><br><span class=\"line\"><span class=\"built_in\">test</span> -e status || touch status</span><br><span class=\"line\">head -1 status &gt; status.clean</span><br><span class=\"line\">sed <span class=\"string\">'s/\"//g'</span> status | <span class=\"keyword\">while</span> <span class=\"built_in\">read</span> logfile date</span><br><span class=\"line\"><span class=\"keyword\">do</span></span><br><span class=\"line\">    [ -e <span class=\"string\">\"<span class=\"variable\">$logfile</span>\"</span> ] &amp;&amp; <span class=\"built_in\">echo</span> <span class=\"string\">\"\\\"<span class=\"variable\">$logfile</span>\\\" <span class=\"variable\">$date</span>\"</span></span><br><span class=\"line\"><span class=\"keyword\">done</span> &gt;&gt; status.clean</span><br><span class=\"line\">mv status.clean status</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">test</span> -x /usr/sbin/logrotate || <span class=\"built_in\">exit</span> 0</span><br><span class=\"line\">/usr/sbin/logrotate /etc/logrotate.conf</span><br></pre></td></tr></table></figure></p>\n<p>如本文第二节所述, 由于 logrotate 的执行方式是通过 cron 默认 1 天执行一次, 所以按小时 rotate 的 <code>hourly</code> 配置项, 默认是不生效的; logrotate 的 manual 文档里也有说明:</p>\n<blockquote>\n<p><code>hourly</code> Log files are rotated every hour. Note that usually logrotate is configured to be run by cron daily. You have to change this configuration and run logrotate hourly to be able to really rotate logs hourly.</p>\n</blockquote>\n<p>不过, 这还不是最大的问题, 毕竟我们只要把上述脚本放到 <code>cron.hourly</code> 里, 就能解决该问题;<br>这种靠定时任务来运行的方式, 最大的问题是: 当我们对某个日志配置成按 <code>size</code> 来 rotate 时, 无法做到当日志触达 size 条件时及时切分, 其所能实现的最小延时是一分钟 (当把 logrotate 脚本的定时任务配成 * * * * *, 即每分钟执行一次时), 没法更短了;</p>\n<h3 id=\"其他的特殊场景\"><a href=\"#其他的特殊场景\" class=\"headerlink\" title=\"其他的特殊场景\"></a><strong>其他的特殊场景</strong></h3><p>logrotate 集日志切分, 日志压缩, 删除旧日志, 邮件提醒等功能为一体, 提供了非常完整的日志管理策略; 不过, 并不是所有的系统日志, 自身都不具有上述功能, 都需要依赖 logrotate 来管理自己;<br>有一个非常典型, 而且使用十分广泛的场景: tomcat web 服务器; 当我们在 tomcat 上部署的服务使用了诸如 logback 之类的第三方日志框架时, 日志切分, 日志压缩等服务它自己便能够胜任了 (与 logback 相关功能的文章请见: <a href=\"\">logback appender 使用总结</a>), 而且我们绝大部分人 (去哪儿网), 即便不怎么接触 logback 的日志压缩功能, 也至少都习惯于使用 logback  <code>RollingFileAppender</code> 的基础功能去作日志切分;<br>基于以上, 我们只需要一个简单的脚本, 便能够满足日常的 tomcat web 服务器日志运维:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#!/bin/bash</span></span><br><span class=\"line\">HOUR1=$(date -d <span class=\"string\">\"1 hours ago\"</span> +%F-%H)</span><br><span class=\"line\">DATE7=$(date -d <span class=\"string\">\"7 days ago\"</span> +%F-%H)</span><br><span class=\"line\"><span class=\"comment\"># for example: /home/web/my_server/logs</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> `find /home/web/ -maxdepth 2 \\( -<span class=\"built_in\">type</span> d -o -<span class=\"built_in\">type</span> l \\) -name logs`; <span class=\"keyword\">do</span></span><br><span class=\"line\">        find -L <span class=\"variable\">$i</span> -maxdepth 1 -<span class=\"built_in\">type</span> f \\( -name <span class=\"string\">\"*<span class=\"variable\">$&#123;HOUR1&#125;</span>*\"</span> -a ! -name <span class=\"string\">\"*.gz\"</span> \\) -<span class=\"built_in\">exec</span> gzip &#123;&#125; \\;</span><br><span class=\"line\">        find -L <span class=\"variable\">$i</span> -maxdepth 1 -<span class=\"built_in\">type</span> f \\( -name <span class=\"string\">\"*<span class=\"variable\">$&#123;DATE7&#125;</span>*\"</span> -a -name <span class=\"string\">\"*.gz\"</span> \\) -<span class=\"built_in\">exec</span> rm -f &#123;&#125; \\;</span><br><span class=\"line\"><span class=\"keyword\">done</span></span><br></pre></td></tr></table></figure></p>\n<p>本节内容讨论的是针对 tomcat web 系统上的日志切分, 压缩, 以及删除等常规运维内容; 其实, 针对公司各业务线 web 系统的业务日志, 除此之外至少还有另外两项重要的运维内容: <em>日志冷备份收集</em> 与 <em>日志实时收集及其可视化 (ELK)</em>; 与之相关的内容请参见如下文章: </p>\n<ol>\n<li><a href=\"\">改造 flume-ng: 融入公司的技术体系</a>;</li>\n<li><a href=\"\">日志冷备份收集的方案选型</a>;</li>\n</ol>\n<h3 id=\"站内相关文章\"><a href=\"#站内相关文章\" class=\"headerlink\" title=\"站内相关文章\"></a><strong>站内相关文章</strong></h3><ul>\n<li><a href=\"\">cron 相关全梳理</a></li>\n<li><a href=\"\">logback appender 使用总结</a></li>\n<li><a href=\"\">改造 flume-ng: 融入公司的技术体系</a></li>\n<li><a href=\"\">日志冷备份收集的方案选型</a></li>\n</ul>\n<h3 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a><strong>参考链接</strong></h3><ul>\n<li><a href=\"https://linux.cn/article-4126-1.html\" target=\"_blank\" rel=\"noopener\">Linux日志文件总管——logrotate</a></li>\n<li><a href=\"https://huoding.com/2013/04/21/246\" target=\"_blank\" rel=\"noopener\">被遗忘的 Logrotate</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>本文主要讨论以下几个方面:</p>\n<ol>\n<li>logrotate 的关键配置文件和配置项语法;</li>\n<li>logrotate 的使用与运维技巧;</li>\n<li>logrotate 的运行原理;</li>\n<li>特殊场景下 logrotate 的代替方案;</li>\n</ol>\n</blockquote>","more":"<hr>\n<h3 id=\"配置文件与配置语法\"><a href=\"#配置文件与配置语法\" class=\"headerlink\" title=\"配置文件与配置语法\"></a><strong>配置文件与配置语法</strong></h3><p>logrotate 的配置文件主要是 <code>/etc/logrotate.conf</code> 和 <code>/etc/logrotate.d</code> 目录;<br>/etc/logrotate.conf 文件作为主配置文件, include 了 /etc/logrotate.d 目录下具体的配置内容;<br>以下是 /etc/logrotate.conf 的默认内容:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 默认的历史日志保留周期单位: 周</span></span><br><span class=\"line\">weekly</span><br><span class=\"line\"><span class=\"comment\"># 历史日志保留四个周期单位, 即四周, 一个月</span></span><br><span class=\"line\">rotate 4</span><br><span class=\"line\"><span class=\"comment\"># use the syslog group by default, since this is the owning group of /var/log/syslog.</span></span><br><span class=\"line\">su root syslog</span><br><span class=\"line\"><span class=\"comment\"># 当旧日志作了 rotate 之后, 将会创建一个和旧日志同名的新文件</span></span><br><span class=\"line\">create</span><br><span class=\"line\"><span class=\"comment\"># 默认使用 gzip 压缩旧日志文件</span></span><br><span class=\"line\">compress</span><br><span class=\"line\"><span class=\"comment\"># 将 /etc/logrotate.d 下面的所有独立配置文件都 include 进来</span></span><br><span class=\"line\">include /etc/logrotate.d</span><br></pre></td></tr></table></figure></p>\n<p>/etc/logrotate.conf 的默认配置优先级比 /etc/logrotate.d/ 目录下的独立配置要低, /etc/logrotate.d 下所有的独立配置文件中的配置项可以覆盖 /etc/logrotate.conf;<br>以 rsyslog 的配置文件为例, 以下是 /etc/logrotate.d/rsyslog 的内容:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/var/<span class=\"built_in\">log</span>/syslog &#123;</span><br><span class=\"line\">    <span class=\"comment\"># 以 天 为周期单位, 保留 7 天的日志</span></span><br><span class=\"line\">    daily</span><br><span class=\"line\">    rotate 7</span><br><span class=\"line\">\t</span><br><span class=\"line\">    <span class=\"comment\"># 忽略任何错误, 比如找不到文件</span></span><br><span class=\"line\">    missingok</span><br><span class=\"line\">\t</span><br><span class=\"line\">    <span class=\"comment\"># not if empty, 当日志内容为空时, 不作 rotate</span></span><br><span class=\"line\">    notifempty</span><br><span class=\"line\">\t</span><br><span class=\"line\">    <span class=\"comment\"># 压缩日志, 但是采用延时压缩, 即本轮周期产生的日志不压缩, 而在下一个周期时压缩之</span></span><br><span class=\"line\">    compress</span><br><span class=\"line\">    delaycompress</span><br><span class=\"line\">\t</span><br><span class=\"line\">    <span class=\"comment\"># postrotate/endscript 内的命令, 作为后处理, 会在本轮周期 rotate 之后回调执行</span></span><br><span class=\"line\">    postrotate</span><br><span class=\"line\">\tinvoke-rc.d rsyslog rotate &gt; /dev/null</span><br><span class=\"line\">    endscript</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 可以同时指定多个目标日志使用同一段配置</span></span><br><span class=\"line\">/var/<span class=\"built_in\">log</span>/mail.info</span><br><span class=\"line\">/var/<span class=\"built_in\">log</span>/mail.warn</span><br><span class=\"line\">/var/<span class=\"built_in\">log</span>/mail.err</span><br><span class=\"line\">/var/<span class=\"built_in\">log</span>/mail.log</span><br><span class=\"line\">/var/<span class=\"built_in\">log</span>/daemon.log</span><br><span class=\"line\">/var/<span class=\"built_in\">log</span>/kern.log</span><br><span class=\"line\">/var/<span class=\"built_in\">log</span>/auth.log</span><br><span class=\"line\">/var/<span class=\"built_in\">log</span>/user.log</span><br><span class=\"line\">/var/<span class=\"built_in\">log</span>/lpr.log</span><br><span class=\"line\">/var/<span class=\"built_in\">log</span>/cron.log</span><br><span class=\"line\">/var/<span class=\"built_in\">log</span>/debug</span><br><span class=\"line\">/var/<span class=\"built_in\">log</span>/messages &#123;</span><br><span class=\"line\">    weekly</span><br><span class=\"line\">    rotate 4</span><br><span class=\"line\">\t</span><br><span class=\"line\">    missingok</span><br><span class=\"line\">    notifempty</span><br><span class=\"line\">\t</span><br><span class=\"line\">    compress</span><br><span class=\"line\">    delaycompress</span><br><span class=\"line\">\t</span><br><span class=\"line\">    <span class=\"comment\"># 共享处理脚本, 仅对 prerotate/postrotate 定义时生效</span></span><br><span class=\"line\">    sharedscripts</span><br><span class=\"line\">\t</span><br><span class=\"line\">    postrotate</span><br><span class=\"line\">\tinvoke-rc.d rsyslog rotate &gt; /dev/null</span><br><span class=\"line\">    endscript</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>注意:</p>\n<ol>\n<li><code>sharedscripts</code> 选项打开后, 所有使用该段配置作 rotate 的目标日志名都会作为参数一次性传给 prerotate/postrotate;<br>而默认的选项 <code>nosharedscripts</code> 则是将每一个日志名分别作为参数传给 prerotate/postrotate;</li>\n<li>logrotate 支持的周期单位, 有 hourly, daily, weekly, monthly; 但是这里有坑: hourly 默认是不生效的, 具体原因见本文第三节;</li>\n</ol>\n<p>&nbsp;<br>如上所叙, prerotate/postrotate 是一种在 rotate 过程中某个时机回调的一段脚本, 像这样类似的配置项总共有如下几种 (所有的配置项必须与 <code>endscript</code> 成对出现):<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 在所有匹配的日志 rotate 之前, 仅执行一次</span></span><br><span class=\"line\">firstaction/endscript</span><br><span class=\"line\"><span class=\"comment\"># 在日志 rotate 之前回调</span></span><br><span class=\"line\">prerotate/endscript</span><br><span class=\"line\"><span class=\"comment\"># 在日志 rotate 之后回调</span></span><br><span class=\"line\">postrotate/endscript</span><br><span class=\"line\"><span class=\"comment\"># 在所有匹配的日志 rotate 之后, 仅执行一次</span></span><br><span class=\"line\">lastaction/endscript</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 在某个日志将要被删除之前回调执行</span></span><br><span class=\"line\">preremove/endscript</span><br></pre></td></tr></table></figure></p>\n<p>这几种回调时间点的设计, 不禁让人想到 junit 测试类几种注解的方法执行时机, 不得不说有异曲同工之妙;<br>&nbsp;<br>rsyslog 的 logrotate 配置是一个典型, 但同时 logrotate 还有着其他的个性化配置选项:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 以下是另一段案例</span></span><br><span class=\"line\">/var/<span class=\"built_in\">log</span>/test.log &#123;</span><br><span class=\"line\">    <span class=\"comment\"># 不以时间为周期单位, 而是以 日志size 为周期单位, 当日志大小达到 100MB 时, 作一次 rotate, 日志保留 5 个周期</span></span><br><span class=\"line\">    size=100M</span><br><span class=\"line\">    rotate 5</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># 使用日期命名 rotate 后的旧文件, 日期格式采用 -%Y-%m-%d</span></span><br><span class=\"line\">    dateext</span><br><span class=\"line\">    dateformat -%Y-%m-%d</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># 以指定的权限掩码, owner/group 创建 rotate 后的新文件</span></span><br><span class=\"line\">    create 644 root root</span><br><span class=\"line\">    </span><br><span class=\"line\">    postrotate</span><br><span class=\"line\">        /usr/bin/killall -HUP rsyslogd</span><br><span class=\"line\">    endscript</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"logrotate-命令的常用运维选项\"><a href=\"#logrotate-命令的常用运维选项\" class=\"headerlink\" title=\"logrotate 命令的常用运维选项\"></a><strong>logrotate 命令的常用运维选项</strong></h3><p>1.指定目标配置文件, 手动执行:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 将会执行 /etc/logrotate.d/ 下所有的配置</span></span><br><span class=\"line\">logrotate /etc/logrotate.conf</span><br><span class=\"line\"><span class=\"comment\"># 将会只执行指定配置文件中的配置</span></span><br><span class=\"line\">logrotate /etc/logrotate.d/xxx.log</span><br></pre></td></tr></table></figure></p>\n<p>2.debug 验证配置文件正误:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># -d:   --debug</span></span><br><span class=\"line\">&gt; logrotate -d /etc/logrotate.d/redis-server.log</span><br><span class=\"line\"><span class=\"comment\"># output</span></span><br><span class=\"line\">reading config file /etc/logrotate.d/redis-server</span><br><span class=\"line\">Handling 1 logs</span><br><span class=\"line\">rotating pattern: /var/<span class=\"built_in\">log</span>/redis/redis-server*.<span class=\"built_in\">log</span>  weekly (12 rotations)</span><br><span class=\"line\">empty <span class=\"built_in\">log</span> files are not rotated, old logs are removed</span><br><span class=\"line\">considering <span class=\"built_in\">log</span> /var/<span class=\"built_in\">log</span>/redis/redis-server.log</span><br><span class=\"line\">  <span class=\"built_in\">log</span> does not need rotating</span><br></pre></td></tr></table></figure></p>\n<p>3.强制 rotate:<br>即便当前不满足 rotate 的条件, force rotate 也会强制作一次 rotate, 而那些超过指定轮数的旧日志将会被删除;<br>force rotate 比较适用于加入了新的配置文件, 需要对其存量历史立即作一次 rotate;<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># -f:   --force</span></span><br><span class=\"line\">logrotate -f /etc/logrotate.d/xxx.log</span><br></pre></td></tr></table></figure></p>\n<p>4.verbose 详细信息:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># -v:   --verbose</span></span><br><span class=\"line\">logrotate -vf /etc/logrotate.d/xxx.log</span><br></pre></td></tr></table></figure></p>\n<p>5.指定 logrotate 自身的日志文件路径:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># -s:   --state</span></span><br><span class=\"line\"><span class=\"comment\"># 默认 logrotate 的日志路径: /var/lib/logrotate/status</span></span><br><span class=\"line\">logrotate -s /tmp/logrotate.log /etc/logrotate.conf</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"logrotate-的运行原理及其缺陷\"><a href=\"#logrotate-的运行原理及其缺陷\" class=\"headerlink\" title=\"logrotate 的运行原理及其缺陷\"></a><strong>logrotate 的运行原理及其缺陷</strong></h3><p>logrotate 并不是一个 daemon service, 其本质上只是一个 ‘什么时候调用就什么时候立即执行一次’ 的 C 程序;<br>所以 logrotate 的执行, 依赖于其他 daemon service 的调用, 那么最自然的就是通过 crond 定时任务来调用了;<br>默认情况下, logrotate 是一天被调用一次的, 因为与它相关的 crontab 配置在 <code>/etc/cron.daily</code> 里:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#!/bin/sh</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Clean non existent log file entries from status file</span></span><br><span class=\"line\"><span class=\"built_in\">cd</span> /var/lib/logrotate</span><br><span class=\"line\"><span class=\"built_in\">test</span> -e status || touch status</span><br><span class=\"line\">head -1 status &gt; status.clean</span><br><span class=\"line\">sed <span class=\"string\">'s/\"//g'</span> status | <span class=\"keyword\">while</span> <span class=\"built_in\">read</span> logfile date</span><br><span class=\"line\"><span class=\"keyword\">do</span></span><br><span class=\"line\">    [ -e <span class=\"string\">\"<span class=\"variable\">$logfile</span>\"</span> ] &amp;&amp; <span class=\"built_in\">echo</span> <span class=\"string\">\"\\\"<span class=\"variable\">$logfile</span>\\\" <span class=\"variable\">$date</span>\"</span></span><br><span class=\"line\"><span class=\"keyword\">done</span> &gt;&gt; status.clean</span><br><span class=\"line\">mv status.clean status</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">test</span> -x /usr/sbin/logrotate || <span class=\"built_in\">exit</span> 0</span><br><span class=\"line\">/usr/sbin/logrotate /etc/logrotate.conf</span><br></pre></td></tr></table></figure></p>\n<p>如本文第二节所述, 由于 logrotate 的执行方式是通过 cron 默认 1 天执行一次, 所以按小时 rotate 的 <code>hourly</code> 配置项, 默认是不生效的; logrotate 的 manual 文档里也有说明:</p>\n<blockquote>\n<p><code>hourly</code> Log files are rotated every hour. Note that usually logrotate is configured to be run by cron daily. You have to change this configuration and run logrotate hourly to be able to really rotate logs hourly.</p>\n</blockquote>\n<p>不过, 这还不是最大的问题, 毕竟我们只要把上述脚本放到 <code>cron.hourly</code> 里, 就能解决该问题;<br>这种靠定时任务来运行的方式, 最大的问题是: 当我们对某个日志配置成按 <code>size</code> 来 rotate 时, 无法做到当日志触达 size 条件时及时切分, 其所能实现的最小延时是一分钟 (当把 logrotate 脚本的定时任务配成 * * * * *, 即每分钟执行一次时), 没法更短了;</p>\n<h3 id=\"其他的特殊场景\"><a href=\"#其他的特殊场景\" class=\"headerlink\" title=\"其他的特殊场景\"></a><strong>其他的特殊场景</strong></h3><p>logrotate 集日志切分, 日志压缩, 删除旧日志, 邮件提醒等功能为一体, 提供了非常完整的日志管理策略; 不过, 并不是所有的系统日志, 自身都不具有上述功能, 都需要依赖 logrotate 来管理自己;<br>有一个非常典型, 而且使用十分广泛的场景: tomcat web 服务器; 当我们在 tomcat 上部署的服务使用了诸如 logback 之类的第三方日志框架时, 日志切分, 日志压缩等服务它自己便能够胜任了 (与 logback 相关功能的文章请见: <a href=\"\">logback appender 使用总结</a>), 而且我们绝大部分人 (去哪儿网), 即便不怎么接触 logback 的日志压缩功能, 也至少都习惯于使用 logback  <code>RollingFileAppender</code> 的基础功能去作日志切分;<br>基于以上, 我们只需要一个简单的脚本, 便能够满足日常的 tomcat web 服务器日志运维:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#!/bin/bash</span></span><br><span class=\"line\">HOUR1=$(date -d <span class=\"string\">\"1 hours ago\"</span> +%F-%H)</span><br><span class=\"line\">DATE7=$(date -d <span class=\"string\">\"7 days ago\"</span> +%F-%H)</span><br><span class=\"line\"><span class=\"comment\"># for example: /home/web/my_server/logs</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> `find /home/web/ -maxdepth 2 \\( -<span class=\"built_in\">type</span> d -o -<span class=\"built_in\">type</span> l \\) -name logs`; <span class=\"keyword\">do</span></span><br><span class=\"line\">        find -L <span class=\"variable\">$i</span> -maxdepth 1 -<span class=\"built_in\">type</span> f \\( -name <span class=\"string\">\"*<span class=\"variable\">$&#123;HOUR1&#125;</span>*\"</span> -a ! -name <span class=\"string\">\"*.gz\"</span> \\) -<span class=\"built_in\">exec</span> gzip &#123;&#125; \\;</span><br><span class=\"line\">        find -L <span class=\"variable\">$i</span> -maxdepth 1 -<span class=\"built_in\">type</span> f \\( -name <span class=\"string\">\"*<span class=\"variable\">$&#123;DATE7&#125;</span>*\"</span> -a -name <span class=\"string\">\"*.gz\"</span> \\) -<span class=\"built_in\">exec</span> rm -f &#123;&#125; \\;</span><br><span class=\"line\"><span class=\"keyword\">done</span></span><br></pre></td></tr></table></figure></p>\n<p>本节内容讨论的是针对 tomcat web 系统上的日志切分, 压缩, 以及删除等常规运维内容; 其实, 针对公司各业务线 web 系统的业务日志, 除此之外至少还有另外两项重要的运维内容: <em>日志冷备份收集</em> 与 <em>日志实时收集及其可视化 (ELK)</em>; 与之相关的内容请参见如下文章: </p>\n<ol>\n<li><a href=\"\">改造 flume-ng: 融入公司的技术体系</a>;</li>\n<li><a href=\"\">日志冷备份收集的方案选型</a>;</li>\n</ol>\n<h3 id=\"站内相关文章\"><a href=\"#站内相关文章\" class=\"headerlink\" title=\"站内相关文章\"></a><strong>站内相关文章</strong></h3><ul>\n<li><a href=\"\">cron 相关全梳理</a></li>\n<li><a href=\"\">logback appender 使用总结</a></li>\n<li><a href=\"\">改造 flume-ng: 融入公司的技术体系</a></li>\n<li><a href=\"\">日志冷备份收集的方案选型</a></li>\n</ul>\n<h3 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a><strong>参考链接</strong></h3><ul>\n<li><a href=\"https://linux.cn/article-4126-1.html\" target=\"_blank\" rel=\"noopener\">Linux日志文件总管——logrotate</a></li>\n<li><a href=\"https://huoding.com/2013/04/21/246\" target=\"_blank\" rel=\"noopener\">被遗忘的 Logrotate</a></li>\n</ul>"},{"title":"python 模块导入: 相关基础知识梳理","date":"2017-03-12T13:35:04.000Z","_content":"\n> python 有一个关键字和 java 一样: `import`, 其功能也类似: 在代码中引入其他的依赖(模块)以使用;\n不过, 不像 java 那么单纯, python 还要区分为 import module 和 import names 两大类; 作为一个 python 新手, 这些使用上的区别有时会令人感到迷惑;\npython 包和 java 包在概念上也有类似之处, 不过 python 的 \\__init\\__.py 规范更讲究一些, java 的 package-info.java 重要性没有那么强, python 初学者在此也很容易栽跟头;\n在使用了一段时间的 python 之后, 我突然发现, 关于模块引入相关的知识, 我还从来没有过一个系统性的整理; 故作此文以备将来查阅;\n\n<!--more-->\n\n------\n\n下面所示的是一个 python 工程结构, 包括了一个父 package 和其下的子 package , 结构比较完整; 本文将以此工程结构为例, 展开内容;\n``` python\nMyPackage\n    ├── connections.py\n    ├── constants\n    │   ├── CLIENT.py\n    │   ├── CR.py\n    │   ├── ER.py\n    │   ├── FIELD_TYPE.py\n    │   ├── FLAG.py\n    │   ├── __init__.py\n    │   ├── REFRESH.py\n    ├── converters.py\n    ├── cursors.py\n    ├── __init__.py\n    ├── release.py\n    ├── times.py\n```\n其中, 假设 connections.py 中定义了 Connection 类:\n``` python\n# connections.py\nimport _mysql\nclass Connection(_mysql.connection):\n    def __init__(self, *args, **kwargs):\n        ...\n```\n下面开始本文的内容;\n\n### **基础预备知识**\n#### **对象的 \\__name\\__ 字段**\n所有 python 程序的执行必须要有一个入口, 而我们经常见到的入口会有这么一行代码:\n``` python\nif __name__ == '__main__':\n```\n这里面涉及到了一个模块的属性: `__name__`:\n当一个模块以主模块被执行时, 该模块的 \\__name\\__ 就被解释器设定为 '\\__main\\__';\n当一个模块被其他模块引入时, 该模块的 \\__name\\__ 就被解释器设定为 该模块的文件名;\n\n#### **内建方法: dir()**\npython 中有一个全局内建方法 `dir(p_object=None)` 可以返回目标作用域里所有的成员 (names);\n当方法参数 p_object 为 None 时, 默认返回当前作用域内的所有成员:\n``` python\n# 在 python shell 里执行, 作用域为主模块, 展示模块属性\n>>> import MyPackage\n>>> dir()\n['MyPackage', '__builtins__', '__doc__', '__name__', '__package__']\n```\n\n``` python\n# 在方法内部执行, 作用域为方法内, 展示方法的字段\ndef print_dir(num=1, str=None):\n    print dir()\n    \nif __name__ == '__main__':\n    print_dir()\n\noutput:\n['num', 'str']\n```\n如果指定了目标作用域(对象), 则无论在哪里指定 dir () 方法, 都只打印指定目标的成员;\n``` python\nfrom MyPackage.connections import Connection\n# 指定作用域\ndef print_dir(obj=None):\n    print dir(obj)\n\nif __name__ == '__main__':\n    conn = Connection()\n    print_dir(conn)\n\noutput:\n['__doc__', '__init__', '__module__']\n```\n\n#### **import 的规则语法**\npython 导入其他模块分为两种: import module/package 与 import names (包括变量, 函数, 类等);\nimport module/package 的语法如下:\n``` python\nimport MyPackage\nimport MyPackage.connections\n```\nimport names 的语法如下:\n``` python\n# 引入类\nfrom MyPackage.connections import Connection\n# 引入方法\nfrom MyPackage.connections import numeric_part\n# 引入 __all__ 指定的所有 names\nfrom MyPackage import *\n```\n对于不同的 package, 不同的 \\__init\\__.py 文件, 这些 import 语句所产生的效果都不尽相同, 详细的区别将在下一节描述;\n\n### **\\__init\\__.py 文件的功能**\n对于 python 的每一个包来说, \\__init\\__.py 是必须的, 它控制着包的导入行为, 并可以表达非常丰富的信息; 如果没有 \\__init\\__.py 文件, 那这个包只能算是一个普通目录, 目录下的任何 python 文件都不能作为模块被导入;\n以下是几种常见的 \\__init\\__.py 文件的内容:\n\n#### **\\__init\\__.py 文件内容为空**\n\\__init\\__.py 文件必须有, 但可以是空文件, 这将是最简单的形式, 当然其所提供的功能也最简单: 标识这是一个 python 包, 仅此而已;\n如果将该包作为一个模块导入, 其实是等于什么都没导入:\n``` python\n>>> import MyPackage\n>>> dir()\n['MyPackage', '__builtins__', '__doc__', '__name__', '__package__']\n>>> dir(MyPackage)\n['__builtins__', '__doc__', '__file__', '__name__', '__package__', '__path__']\n```\n通过 dir() 内建方法可以发现, 无论是当前主模块, 还是 MyPackage 包, 除了一些保留 names, 不再有其他任何自定义符号, 这时将无法直接使用 MyPackage 下的任何模块:\n``` python\n# 直接 使用 connections.py 下的 Connection 类\n>>> conn = MyPackage.connections.Connection()\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'MyPackage' is not defined\n```\n\n不过, 既然 \\__init\\__.py 已经标识了这是一个 python 包, 所以对于包下所有其他的模块文件, 我们可以主动引入它们, 这算是空 \\__init\\__.py 的唯一作用:\n``` python\n# 主动引入模块\n>>> import MyPackage.connections\n>>> dir(MyPackage)\n['__builtins__', '__doc__', '__file__', '__name__', '__package__', '__path__', 'connections']\n>>> dir(MyPackage.connections)\n['Connection', '__builtins__', '__doc__', '__file__', '__name__', '__package__', 'numeric_part']\n```\n这时可以发现, dir(MyPackage) 列表里有了 connections 模块, dir(MyPackage.connections) 列表里有了 Connection 类; 这时带着 python 路径, 就可以使用 target name 了:\n``` python\n>>> conn = MyPackage.connections.Connection()\n```\n另外, 如果使用 from ... import ... 主动引入目标符号:\n``` python\n>>> from MyPackage.connections import Connection\n>>> dir()\n['Connection', '__builtins__', '__doc__', '__name__', '__package__']\n```\n便可以直接将目标符号引入当前作用域, 不需要使用模块路径, 就可以直接使用:\n``` python\n>>> conn = Connection()\n```\n\n#### **在 \\__init\\__.py 中 import 其他模块**\n\\__init\\__.py 中自己主动 import 第三方模块是一种常见的操作:\n``` python\n# __init__.py\nimport connections\n```\n``` python\n>>> import MyPackage\n>>> dir(MyPackage)\n['__builtins__', '__doc__', '__file__', '__name__', '__package__', '__path__', 'connections']\n# 路径是 MyPackage.connections\n>>> conn = MyPackage.connections.Connection()\n```\n或者使用 from ... import ... 语法:\n``` python\n# __init__.py\nfrom connections import Connection\n```\n``` python\n>>> import MyPackage\n>>> dir(MyPackage)\n['Connection', '__builtins__', '__doc__', '__file__', '__name__', '__package__', '__path__', 'connections']\n# 路径是 MyPackage\n>>> conn = MyPackage.Connection()\n```\n对于以上两种 import 方式, 结合 dir() 内建方法的展示, 可以发现在具体使用目标符号时所带路径的区别;\n\n#### **\\__init\\__.py 中的保留字段**\n(1) \\__all\\__ 字段:\n如果在代码中使用了如下的引用方式:\n``` python\nfrom MyPackage import *\n```\n解释器便会试图去指定的模块中寻找 `__all__` 字段, 将该列表中列举的所有 names 全部引入:\n``` python\n__all__ = [ 'BINARY', 'Binary', 'Connect', 'Connection', 'DATE',\n    'Date', 'Time', 'Timestamp', 'DateFromTicks', 'TimeFromTicks',\n    'TimestampFromTicks', 'DataError', 'DatabaseError', 'Error',\n    'FIELD_TYPE', 'IntegrityError', 'InterfaceError', 'InternalError',\n    'MySQLError', 'NULL', 'NUMBER', 'NotSupportedError', 'DBAPISet',\n    'OperationalError', 'ProgrammingError', 'ROWID', 'STRING', 'TIME',\n    'TIMESTAMP', 'Warning', 'apilevel', 'connect', 'connections',\n    'constants', 'converters', 'cursors', 'debug', 'escape', 'escape_dict',\n    'escape_sequence', 'escape_string', 'get_client_info',\n    'paramstyle', 'string_literal', 'threadsafety', 'version_info']\n```\n不过, 这种情况下不能完全清楚引入了什么 names, 有可能覆盖自己定义的 names, 最好谨慎使用;\n(2) 其他信息, 如版本, 作者:\n``` python\n# 作者\n__author__ = \"Andy Dustman <farcepest@gmail.com>\"\n# 版本信息\nversion_info = (1,2,5,'final',1)\n__version__ = \"1.2.5\"\n```\n\n#### **在 \\__init\\__.py 中定义方法/类**\n\\__init\\__.py 也是 python 源文件, 在其中亦可以定义方法, 类, 或者执行代码段:\n``` python\n# MyPackage: __init__.py\ndef test_DBAPISet_set_equality():\n    assert STRING == STRING\n    \ndef Binary(x):\n    return str(x)\n```\n此时, import 了 MyPackage 之后, 便可以正常使用定义的内容;\n\n### **python 的工作/搜索路径**\n当导入一个 python 模块时, 解释器的查找路径如下:\n\n1. 在当前的包中查找;\n2. 在 `__buildin__` 模块中查找;\n3. 在 sys.path 给定的路径中中查找;\n\n其中, 第一点自不必说;\n关于 \\__buildin\\__ 模块, 更多的信息请参见另一篇文章: [python module 使用总结: \\__buildin\\__](); 上文描述的 dir() 方法其实就是 \\__buildin\\__ 模块中的内建方法, 不需要额外引入其他模块便能直接使用;\n而关于 sys.path, 其初始构成内容又包含了以下几处地方:\n\n1. 程序的主目录;\n2. PYTHONPATH 中定义的路径;\n3. 标准链接库, 例如: /usr/lib/python2.7, /usr/local/lib/python2.7 等;\n\n``` python\n>>> import sys\n>>> sys.path\n['', '/usr/lib64/python27.zip', '/usr/lib64/python2.7', '/usr/lib/python2.7/plat-linux2', '/usr/lib/python2.7/lib-tk', '/usr/lib/python2.7/lib-old', '/usr/lib/python2.7/lib-dynload', '/usr/lib/python2.7/site-packages', '/usr/lib/python2.7/site-packages']\n```\n如上所述, 从运行主模块的角度考虑:\n\n1. 如果引入的模块是第三方模块, 那么大部分情况下, 所需要的模块在标准链接库 dist-packages 中都有, python 能够成功引到;\n2. 如果引入的模块是自己的子模块, 由于子模块一定在主模块的子目录下, 所以 python 也能成功引到;\n3. 如果引入的模块是自己的父模块或者兄弟模块, 这时 python 能否成功引到, 就得分情况了:\n\n如果工程在自己创建的目录中运行, 引入父模块或者兄弟模块, 在默认的搜索路径里是找不到的;\n这时要想成功引到目标模块, 有两种办法:\n(1) 向 sys.path 中拓展添加目标路径:\n``` python\nimport sys\nsys.path.append(os.path.abspath('xxx/yyy/zzz'))\n```\n(2) 使用 PYTHONPATH, 向其中添加目标路径:\n``` bash\n# /etc/profile\nexport PATH=${PATH}:${target_path}\nexport PYTHONPATH=${PYTHONPATH}:${target_path}\n```\n至于这两种方法的好坏, 就是仁者见仁, 智者见智的问题了;\n使用 sys.path.append, 比较灵活, 每个模块都可以自己定义, 但缺点是需要多添加两行代码, 比较繁琐;\n使用 PYTHONPATH, 优点是不需要在自己的模块中添加额外的代码, 但是如果自己创建的工程路径比较零散, PYTHONPATH 就需要不停地补充新路径;\n不过, 如果有诸如公司规范之类的, 将 python 项目都部署在约定的公共目录下, 那么 PYTHONPATH 只需要添加这一个公共路径即可, 这样问题便简单了;\n&nbsp;\n至此, 关于 python 模块导入的基础性问题就讲完了;\n最后要说的是, 其实本文最开始所列出的那个自定义模块 MyPackage, 其原型是 `MySQLdb`;\n\n### **站内相关文章**\n- [python module 使用总结: \\__buildin\\__]()\n\n### **参考链接**\n- [Python 中 if \\__name\\__ == '\\__main\\__' 理解](http://www.cnblogs.com/huwang-sun/p/6993980.html)\n- [Python 中的包 ImportError](https://www.cnblogs.com/AlwinXu/p/5658787.html)\n- [python import 工程内模块显示错误](https://segmentfault.com/q/1010000007837183?_ea=1477413)\n- [Python模块包中\\__init\\__.py文件的作用](http://blog.csdn.net/yxmmxy7913/article/details/4233420)\n- [Be Pythonic: \\__init\\__.py](http://mikegrouchy.com/blog/2012/05/be-pythonic-__init__py.html)\n- [Python类、模块、包的区别](https://www.cnblogs.com/kex1n/p/5977051.html)\n- [Python环境变量PYTHONPATH设置](http://blog.csdn.net/qw_xingzhe/article/details/52695486)\n\n","source":"_posts/python--python模块导入_相关基础知识梳理.md","raw":"---\ntitle: \"python 模块导入: 相关基础知识梳理\"\ndate: 2017-03-12 21:35:04\ncategories:\n - python\ntags:\n - python:module\n---\n\n> python 有一个关键字和 java 一样: `import`, 其功能也类似: 在代码中引入其他的依赖(模块)以使用;\n不过, 不像 java 那么单纯, python 还要区分为 import module 和 import names 两大类; 作为一个 python 新手, 这些使用上的区别有时会令人感到迷惑;\npython 包和 java 包在概念上也有类似之处, 不过 python 的 \\__init\\__.py 规范更讲究一些, java 的 package-info.java 重要性没有那么强, python 初学者在此也很容易栽跟头;\n在使用了一段时间的 python 之后, 我突然发现, 关于模块引入相关的知识, 我还从来没有过一个系统性的整理; 故作此文以备将来查阅;\n\n<!--more-->\n\n------\n\n下面所示的是一个 python 工程结构, 包括了一个父 package 和其下的子 package , 结构比较完整; 本文将以此工程结构为例, 展开内容;\n``` python\nMyPackage\n    ├── connections.py\n    ├── constants\n    │   ├── CLIENT.py\n    │   ├── CR.py\n    │   ├── ER.py\n    │   ├── FIELD_TYPE.py\n    │   ├── FLAG.py\n    │   ├── __init__.py\n    │   ├── REFRESH.py\n    ├── converters.py\n    ├── cursors.py\n    ├── __init__.py\n    ├── release.py\n    ├── times.py\n```\n其中, 假设 connections.py 中定义了 Connection 类:\n``` python\n# connections.py\nimport _mysql\nclass Connection(_mysql.connection):\n    def __init__(self, *args, **kwargs):\n        ...\n```\n下面开始本文的内容;\n\n### **基础预备知识**\n#### **对象的 \\__name\\__ 字段**\n所有 python 程序的执行必须要有一个入口, 而我们经常见到的入口会有这么一行代码:\n``` python\nif __name__ == '__main__':\n```\n这里面涉及到了一个模块的属性: `__name__`:\n当一个模块以主模块被执行时, 该模块的 \\__name\\__ 就被解释器设定为 '\\__main\\__';\n当一个模块被其他模块引入时, 该模块的 \\__name\\__ 就被解释器设定为 该模块的文件名;\n\n#### **内建方法: dir()**\npython 中有一个全局内建方法 `dir(p_object=None)` 可以返回目标作用域里所有的成员 (names);\n当方法参数 p_object 为 None 时, 默认返回当前作用域内的所有成员:\n``` python\n# 在 python shell 里执行, 作用域为主模块, 展示模块属性\n>>> import MyPackage\n>>> dir()\n['MyPackage', '__builtins__', '__doc__', '__name__', '__package__']\n```\n\n``` python\n# 在方法内部执行, 作用域为方法内, 展示方法的字段\ndef print_dir(num=1, str=None):\n    print dir()\n    \nif __name__ == '__main__':\n    print_dir()\n\noutput:\n['num', 'str']\n```\n如果指定了目标作用域(对象), 则无论在哪里指定 dir () 方法, 都只打印指定目标的成员;\n``` python\nfrom MyPackage.connections import Connection\n# 指定作用域\ndef print_dir(obj=None):\n    print dir(obj)\n\nif __name__ == '__main__':\n    conn = Connection()\n    print_dir(conn)\n\noutput:\n['__doc__', '__init__', '__module__']\n```\n\n#### **import 的规则语法**\npython 导入其他模块分为两种: import module/package 与 import names (包括变量, 函数, 类等);\nimport module/package 的语法如下:\n``` python\nimport MyPackage\nimport MyPackage.connections\n```\nimport names 的语法如下:\n``` python\n# 引入类\nfrom MyPackage.connections import Connection\n# 引入方法\nfrom MyPackage.connections import numeric_part\n# 引入 __all__ 指定的所有 names\nfrom MyPackage import *\n```\n对于不同的 package, 不同的 \\__init\\__.py 文件, 这些 import 语句所产生的效果都不尽相同, 详细的区别将在下一节描述;\n\n### **\\__init\\__.py 文件的功能**\n对于 python 的每一个包来说, \\__init\\__.py 是必须的, 它控制着包的导入行为, 并可以表达非常丰富的信息; 如果没有 \\__init\\__.py 文件, 那这个包只能算是一个普通目录, 目录下的任何 python 文件都不能作为模块被导入;\n以下是几种常见的 \\__init\\__.py 文件的内容:\n\n#### **\\__init\\__.py 文件内容为空**\n\\__init\\__.py 文件必须有, 但可以是空文件, 这将是最简单的形式, 当然其所提供的功能也最简单: 标识这是一个 python 包, 仅此而已;\n如果将该包作为一个模块导入, 其实是等于什么都没导入:\n``` python\n>>> import MyPackage\n>>> dir()\n['MyPackage', '__builtins__', '__doc__', '__name__', '__package__']\n>>> dir(MyPackage)\n['__builtins__', '__doc__', '__file__', '__name__', '__package__', '__path__']\n```\n通过 dir() 内建方法可以发现, 无论是当前主模块, 还是 MyPackage 包, 除了一些保留 names, 不再有其他任何自定义符号, 这时将无法直接使用 MyPackage 下的任何模块:\n``` python\n# 直接 使用 connections.py 下的 Connection 类\n>>> conn = MyPackage.connections.Connection()\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'MyPackage' is not defined\n```\n\n不过, 既然 \\__init\\__.py 已经标识了这是一个 python 包, 所以对于包下所有其他的模块文件, 我们可以主动引入它们, 这算是空 \\__init\\__.py 的唯一作用:\n``` python\n# 主动引入模块\n>>> import MyPackage.connections\n>>> dir(MyPackage)\n['__builtins__', '__doc__', '__file__', '__name__', '__package__', '__path__', 'connections']\n>>> dir(MyPackage.connections)\n['Connection', '__builtins__', '__doc__', '__file__', '__name__', '__package__', 'numeric_part']\n```\n这时可以发现, dir(MyPackage) 列表里有了 connections 模块, dir(MyPackage.connections) 列表里有了 Connection 类; 这时带着 python 路径, 就可以使用 target name 了:\n``` python\n>>> conn = MyPackage.connections.Connection()\n```\n另外, 如果使用 from ... import ... 主动引入目标符号:\n``` python\n>>> from MyPackage.connections import Connection\n>>> dir()\n['Connection', '__builtins__', '__doc__', '__name__', '__package__']\n```\n便可以直接将目标符号引入当前作用域, 不需要使用模块路径, 就可以直接使用:\n``` python\n>>> conn = Connection()\n```\n\n#### **在 \\__init\\__.py 中 import 其他模块**\n\\__init\\__.py 中自己主动 import 第三方模块是一种常见的操作:\n``` python\n# __init__.py\nimport connections\n```\n``` python\n>>> import MyPackage\n>>> dir(MyPackage)\n['__builtins__', '__doc__', '__file__', '__name__', '__package__', '__path__', 'connections']\n# 路径是 MyPackage.connections\n>>> conn = MyPackage.connections.Connection()\n```\n或者使用 from ... import ... 语法:\n``` python\n# __init__.py\nfrom connections import Connection\n```\n``` python\n>>> import MyPackage\n>>> dir(MyPackage)\n['Connection', '__builtins__', '__doc__', '__file__', '__name__', '__package__', '__path__', 'connections']\n# 路径是 MyPackage\n>>> conn = MyPackage.Connection()\n```\n对于以上两种 import 方式, 结合 dir() 内建方法的展示, 可以发现在具体使用目标符号时所带路径的区别;\n\n#### **\\__init\\__.py 中的保留字段**\n(1) \\__all\\__ 字段:\n如果在代码中使用了如下的引用方式:\n``` python\nfrom MyPackage import *\n```\n解释器便会试图去指定的模块中寻找 `__all__` 字段, 将该列表中列举的所有 names 全部引入:\n``` python\n__all__ = [ 'BINARY', 'Binary', 'Connect', 'Connection', 'DATE',\n    'Date', 'Time', 'Timestamp', 'DateFromTicks', 'TimeFromTicks',\n    'TimestampFromTicks', 'DataError', 'DatabaseError', 'Error',\n    'FIELD_TYPE', 'IntegrityError', 'InterfaceError', 'InternalError',\n    'MySQLError', 'NULL', 'NUMBER', 'NotSupportedError', 'DBAPISet',\n    'OperationalError', 'ProgrammingError', 'ROWID', 'STRING', 'TIME',\n    'TIMESTAMP', 'Warning', 'apilevel', 'connect', 'connections',\n    'constants', 'converters', 'cursors', 'debug', 'escape', 'escape_dict',\n    'escape_sequence', 'escape_string', 'get_client_info',\n    'paramstyle', 'string_literal', 'threadsafety', 'version_info']\n```\n不过, 这种情况下不能完全清楚引入了什么 names, 有可能覆盖自己定义的 names, 最好谨慎使用;\n(2) 其他信息, 如版本, 作者:\n``` python\n# 作者\n__author__ = \"Andy Dustman <farcepest@gmail.com>\"\n# 版本信息\nversion_info = (1,2,5,'final',1)\n__version__ = \"1.2.5\"\n```\n\n#### **在 \\__init\\__.py 中定义方法/类**\n\\__init\\__.py 也是 python 源文件, 在其中亦可以定义方法, 类, 或者执行代码段:\n``` python\n# MyPackage: __init__.py\ndef test_DBAPISet_set_equality():\n    assert STRING == STRING\n    \ndef Binary(x):\n    return str(x)\n```\n此时, import 了 MyPackage 之后, 便可以正常使用定义的内容;\n\n### **python 的工作/搜索路径**\n当导入一个 python 模块时, 解释器的查找路径如下:\n\n1. 在当前的包中查找;\n2. 在 `__buildin__` 模块中查找;\n3. 在 sys.path 给定的路径中中查找;\n\n其中, 第一点自不必说;\n关于 \\__buildin\\__ 模块, 更多的信息请参见另一篇文章: [python module 使用总结: \\__buildin\\__](); 上文描述的 dir() 方法其实就是 \\__buildin\\__ 模块中的内建方法, 不需要额外引入其他模块便能直接使用;\n而关于 sys.path, 其初始构成内容又包含了以下几处地方:\n\n1. 程序的主目录;\n2. PYTHONPATH 中定义的路径;\n3. 标准链接库, 例如: /usr/lib/python2.7, /usr/local/lib/python2.7 等;\n\n``` python\n>>> import sys\n>>> sys.path\n['', '/usr/lib64/python27.zip', '/usr/lib64/python2.7', '/usr/lib/python2.7/plat-linux2', '/usr/lib/python2.7/lib-tk', '/usr/lib/python2.7/lib-old', '/usr/lib/python2.7/lib-dynload', '/usr/lib/python2.7/site-packages', '/usr/lib/python2.7/site-packages']\n```\n如上所述, 从运行主模块的角度考虑:\n\n1. 如果引入的模块是第三方模块, 那么大部分情况下, 所需要的模块在标准链接库 dist-packages 中都有, python 能够成功引到;\n2. 如果引入的模块是自己的子模块, 由于子模块一定在主模块的子目录下, 所以 python 也能成功引到;\n3. 如果引入的模块是自己的父模块或者兄弟模块, 这时 python 能否成功引到, 就得分情况了:\n\n如果工程在自己创建的目录中运行, 引入父模块或者兄弟模块, 在默认的搜索路径里是找不到的;\n这时要想成功引到目标模块, 有两种办法:\n(1) 向 sys.path 中拓展添加目标路径:\n``` python\nimport sys\nsys.path.append(os.path.abspath('xxx/yyy/zzz'))\n```\n(2) 使用 PYTHONPATH, 向其中添加目标路径:\n``` bash\n# /etc/profile\nexport PATH=${PATH}:${target_path}\nexport PYTHONPATH=${PYTHONPATH}:${target_path}\n```\n至于这两种方法的好坏, 就是仁者见仁, 智者见智的问题了;\n使用 sys.path.append, 比较灵活, 每个模块都可以自己定义, 但缺点是需要多添加两行代码, 比较繁琐;\n使用 PYTHONPATH, 优点是不需要在自己的模块中添加额外的代码, 但是如果自己创建的工程路径比较零散, PYTHONPATH 就需要不停地补充新路径;\n不过, 如果有诸如公司规范之类的, 将 python 项目都部署在约定的公共目录下, 那么 PYTHONPATH 只需要添加这一个公共路径即可, 这样问题便简单了;\n&nbsp;\n至此, 关于 python 模块导入的基础性问题就讲完了;\n最后要说的是, 其实本文最开始所列出的那个自定义模块 MyPackage, 其原型是 `MySQLdb`;\n\n### **站内相关文章**\n- [python module 使用总结: \\__buildin\\__]()\n\n### **参考链接**\n- [Python 中 if \\__name\\__ == '\\__main\\__' 理解](http://www.cnblogs.com/huwang-sun/p/6993980.html)\n- [Python 中的包 ImportError](https://www.cnblogs.com/AlwinXu/p/5658787.html)\n- [python import 工程内模块显示错误](https://segmentfault.com/q/1010000007837183?_ea=1477413)\n- [Python模块包中\\__init\\__.py文件的作用](http://blog.csdn.net/yxmmxy7913/article/details/4233420)\n- [Be Pythonic: \\__init\\__.py](http://mikegrouchy.com/blog/2012/05/be-pythonic-__init__py.html)\n- [Python类、模块、包的区别](https://www.cnblogs.com/kex1n/p/5977051.html)\n- [Python环境变量PYTHONPATH设置](http://blog.csdn.net/qw_xingzhe/article/details/52695486)\n\n","slug":"python--python模块导入_相关基础知识梳理","published":1,"updated":"2018-02-25T01:46:49.117Z","_id":"cje24mxu1000ej1jxyui2n0jf","comments":1,"layout":"post","photos":[],"link":"","content":"<blockquote>\n<p>python 有一个关键字和 java 一样: <code>import</code>, 其功能也类似: 在代码中引入其他的依赖(模块)以使用;<br>不过, 不像 java 那么单纯, python 还要区分为 import module 和 import names 两大类; 作为一个 python 新手, 这些使用上的区别有时会令人感到迷惑;<br>python 包和 java 包在概念上也有类似之处, 不过 python 的 __init__.py 规范更讲究一些, java 的 package-info.java 重要性没有那么强, python 初学者在此也很容易栽跟头;<br>在使用了一段时间的 python 之后, 我突然发现, 关于模块引入相关的知识, 我还从来没有过一个系统性的整理; 故作此文以备将来查阅;</p>\n</blockquote>\n<a id=\"more\"></a>\n<hr>\n<p>下面所示的是一个 python 工程结构, 包括了一个父 package 和其下的子 package , 结构比较完整; 本文将以此工程结构为例, 展开内容;<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MyPackage</span><br><span class=\"line\">    ├── connections.py</span><br><span class=\"line\">    ├── constants</span><br><span class=\"line\">    │   ├── CLIENT.py</span><br><span class=\"line\">    │   ├── CR.py</span><br><span class=\"line\">    │   ├── ER.py</span><br><span class=\"line\">    │   ├── FIELD_TYPE.py</span><br><span class=\"line\">    │   ├── FLAG.py</span><br><span class=\"line\">    │   ├── __init__.py</span><br><span class=\"line\">    │   ├── REFRESH.py</span><br><span class=\"line\">    ├── converters.py</span><br><span class=\"line\">    ├── cursors.py</span><br><span class=\"line\">    ├── __init__.py</span><br><span class=\"line\">    ├── release.py</span><br><span class=\"line\">    ├── times.py</span><br></pre></td></tr></table></figure></p>\n<p>其中, 假设 connections.py 中定义了 Connection 类:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># connections.py</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> _mysql</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Connection</span><span class=\"params\">(_mysql.connection)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, *args, **kwargs)</span>:</span></span><br><span class=\"line\">        ...</span><br></pre></td></tr></table></figure></p>\n<p>下面开始本文的内容;</p>\n<h3 id=\"基础预备知识\"><a href=\"#基础预备知识\" class=\"headerlink\" title=\"基础预备知识\"></a><strong>基础预备知识</strong></h3><h4 id=\"对象的-name-字段\"><a href=\"#对象的-name-字段\" class=\"headerlink\" title=\"对象的 __name__ 字段\"></a><strong>对象的 __name__ 字段</strong></h4><p>所有 python 程序的执行必须要有一个入口, 而我们经常见到的入口会有这么一行代码:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br></pre></td></tr></table></figure></p>\n<p>这里面涉及到了一个模块的属性: <code>__name__</code>:<br>当一个模块以主模块被执行时, 该模块的 __name__ 就被解释器设定为 ‘__main__’;<br>当一个模块被其他模块引入时, 该模块的 __name__ 就被解释器设定为 该模块的文件名;</p>\n<h4 id=\"内建方法-dir\"><a href=\"#内建方法-dir\" class=\"headerlink\" title=\"内建方法: dir()\"></a><strong>内建方法: dir()</strong></h4><p>python 中有一个全局内建方法 <code>dir(p_object=None)</code> 可以返回目标作用域里所有的成员 (names);<br>当方法参数 p_object 为 None 时, 默认返回当前作用域内的所有成员:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 在 python shell 里执行, 作用域为主模块, 展示模块属性</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">import</span> MyPackage</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>dir()</span><br><span class=\"line\">[<span class=\"string\">'MyPackage'</span>, <span class=\"string\">'__builtins__'</span>, <span class=\"string\">'__doc__'</span>, <span class=\"string\">'__name__'</span>, <span class=\"string\">'__package__'</span>]</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 在方法内部执行, 作用域为方法内, 展示方法的字段</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">print_dir</span><span class=\"params\">(num=<span class=\"number\">1</span>, str=None)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> dir()</span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    print_dir()</span><br><span class=\"line\"></span><br><span class=\"line\">output:</span><br><span class=\"line\">[<span class=\"string\">'num'</span>, <span class=\"string\">'str'</span>]</span><br></pre></td></tr></table></figure>\n<p>如果指定了目标作用域(对象), 则无论在哪里指定 dir () 方法, 都只打印指定目标的成员;<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> MyPackage.connections <span class=\"keyword\">import</span> Connection</span><br><span class=\"line\"><span class=\"comment\"># 指定作用域</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">print_dir</span><span class=\"params\">(obj=None)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> dir(obj)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    conn = Connection()</span><br><span class=\"line\">    print_dir(conn)</span><br><span class=\"line\"></span><br><span class=\"line\">output:</span><br><span class=\"line\">[<span class=\"string\">'__doc__'</span>, <span class=\"string\">'__init__'</span>, <span class=\"string\">'__module__'</span>]</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"import-的规则语法\"><a href=\"#import-的规则语法\" class=\"headerlink\" title=\"import 的规则语法\"></a><strong>import 的规则语法</strong></h4><p>python 导入其他模块分为两种: import module/package 与 import names (包括变量, 函数, 类等);<br>import module/package 的语法如下:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> MyPackage</span><br><span class=\"line\"><span class=\"keyword\">import</span> MyPackage.connections</span><br></pre></td></tr></table></figure></p>\n<p>import names 的语法如下:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 引入类</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> MyPackage.connections <span class=\"keyword\">import</span> Connection</span><br><span class=\"line\"><span class=\"comment\"># 引入方法</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> MyPackage.connections <span class=\"keyword\">import</span> numeric_part</span><br><span class=\"line\"><span class=\"comment\"># 引入 __all__ 指定的所有 names</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> MyPackage <span class=\"keyword\">import</span> *</span><br></pre></td></tr></table></figure></p>\n<p>对于不同的 package, 不同的 __init__.py 文件, 这些 import 语句所产生的效果都不尽相同, 详细的区别将在下一节描述;</p>\n<h3 id=\"init-py-文件的功能\"><a href=\"#init-py-文件的功能\" class=\"headerlink\" title=\"__init__.py 文件的功能\"></a><strong>__init__.py 文件的功能</strong></h3><p>对于 python 的每一个包来说, __init__.py 是必须的, 它控制着包的导入行为, 并可以表达非常丰富的信息; 如果没有 __init__.py 文件, 那这个包只能算是一个普通目录, 目录下的任何 python 文件都不能作为模块被导入;<br>以下是几种常见的 __init__.py 文件的内容:</p>\n<h4 id=\"init-py-文件内容为空\"><a href=\"#init-py-文件内容为空\" class=\"headerlink\" title=\"__init__.py 文件内容为空\"></a><strong>__init__.py 文件内容为空</strong></h4><p>__init__.py 文件必须有, 但可以是空文件, 这将是最简单的形式, 当然其所提供的功能也最简单: 标识这是一个 python 包, 仅此而已;<br>如果将该包作为一个模块导入, 其实是等于什么都没导入:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">import</span> MyPackage</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>dir()</span><br><span class=\"line\">[<span class=\"string\">'MyPackage'</span>, <span class=\"string\">'__builtins__'</span>, <span class=\"string\">'__doc__'</span>, <span class=\"string\">'__name__'</span>, <span class=\"string\">'__package__'</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>dir(MyPackage)</span><br><span class=\"line\">[<span class=\"string\">'__builtins__'</span>, <span class=\"string\">'__doc__'</span>, <span class=\"string\">'__file__'</span>, <span class=\"string\">'__name__'</span>, <span class=\"string\">'__package__'</span>, <span class=\"string\">'__path__'</span>]</span><br></pre></td></tr></table></figure></p>\n<p>通过 dir() 内建方法可以发现, 无论是当前主模块, 还是 MyPackage 包, 除了一些保留 names, 不再有其他任何自定义符号, 这时将无法直接使用 MyPackage 下的任何模块:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 直接 使用 connections.py 下的 Connection 类</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>conn = MyPackage.connections.Connection()</span><br><span class=\"line\">Traceback (most recent call last):</span><br><span class=\"line\">  File <span class=\"string\">\"&lt;stdin&gt;\"</span>, line <span class=\"number\">1</span>, <span class=\"keyword\">in</span> &lt;module&gt;</span><br><span class=\"line\">NameError: name <span class=\"string\">'MyPackage'</span> <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> defined</span><br></pre></td></tr></table></figure></p>\n<p>不过, 既然 __init__.py 已经标识了这是一个 python 包, 所以对于包下所有其他的模块文件, 我们可以主动引入它们, 这算是空 __init__.py 的唯一作用:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 主动引入模块</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">import</span> MyPackage.connections</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>dir(MyPackage)</span><br><span class=\"line\">[<span class=\"string\">'__builtins__'</span>, <span class=\"string\">'__doc__'</span>, <span class=\"string\">'__file__'</span>, <span class=\"string\">'__name__'</span>, <span class=\"string\">'__package__'</span>, <span class=\"string\">'__path__'</span>, <span class=\"string\">'connections'</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>dir(MyPackage.connections)</span><br><span class=\"line\">[<span class=\"string\">'Connection'</span>, <span class=\"string\">'__builtins__'</span>, <span class=\"string\">'__doc__'</span>, <span class=\"string\">'__file__'</span>, <span class=\"string\">'__name__'</span>, <span class=\"string\">'__package__'</span>, <span class=\"string\">'numeric_part'</span>]</span><br></pre></td></tr></table></figure></p>\n<p>这时可以发现, dir(MyPackage) 列表里有了 connections 模块, dir(MyPackage.connections) 列表里有了 Connection 类; 这时带着 python 路径, 就可以使用 target name 了:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>conn = MyPackage.connections.Connection()</span><br></pre></td></tr></table></figure></p>\n<p>另外, 如果使用 from … import … 主动引入目标符号:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">from</span> MyPackage.connections <span class=\"keyword\">import</span> Connection</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>dir()</span><br><span class=\"line\">[<span class=\"string\">'Connection'</span>, <span class=\"string\">'__builtins__'</span>, <span class=\"string\">'__doc__'</span>, <span class=\"string\">'__name__'</span>, <span class=\"string\">'__package__'</span>]</span><br></pre></td></tr></table></figure></p>\n<p>便可以直接将目标符号引入当前作用域, 不需要使用模块路径, 就可以直接使用:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>conn = Connection()</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"在-init-py-中-import-其他模块\"><a href=\"#在-init-py-中-import-其他模块\" class=\"headerlink\" title=\"在 __init__.py 中 import 其他模块\"></a><strong>在 __init__.py 中 import 其他模块</strong></h4><p>__init__.py 中自己主动 import 第三方模块是一种常见的操作:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># __init__.py</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> connections</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">import</span> MyPackage</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>dir(MyPackage)</span><br><span class=\"line\">[<span class=\"string\">'__builtins__'</span>, <span class=\"string\">'__doc__'</span>, <span class=\"string\">'__file__'</span>, <span class=\"string\">'__name__'</span>, <span class=\"string\">'__package__'</span>, <span class=\"string\">'__path__'</span>, <span class=\"string\">'connections'</span>]</span><br><span class=\"line\"><span class=\"comment\"># 路径是 MyPackage.connections</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>conn = MyPackage.connections.Connection()</span><br></pre></td></tr></table></figure>\n<p>或者使用 from … import … 语法:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># __init__.py</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> connections <span class=\"keyword\">import</span> Connection</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">import</span> MyPackage</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>dir(MyPackage)</span><br><span class=\"line\">[<span class=\"string\">'Connection'</span>, <span class=\"string\">'__builtins__'</span>, <span class=\"string\">'__doc__'</span>, <span class=\"string\">'__file__'</span>, <span class=\"string\">'__name__'</span>, <span class=\"string\">'__package__'</span>, <span class=\"string\">'__path__'</span>, <span class=\"string\">'connections'</span>]</span><br><span class=\"line\"><span class=\"comment\"># 路径是 MyPackage</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>conn = MyPackage.Connection()</span><br></pre></td></tr></table></figure>\n<p>对于以上两种 import 方式, 结合 dir() 内建方法的展示, 可以发现在具体使用目标符号时所带路径的区别;</p>\n<h4 id=\"init-py-中的保留字段\"><a href=\"#init-py-中的保留字段\" class=\"headerlink\" title=\"__init__.py 中的保留字段\"></a><strong>__init__.py 中的保留字段</strong></h4><p>(1) __all__ 字段:<br>如果在代码中使用了如下的引用方式:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> MyPackage <span class=\"keyword\">import</span> *</span><br></pre></td></tr></table></figure></p>\n<p>解释器便会试图去指定的模块中寻找 <code>__all__</code> 字段, 将该列表中列举的所有 names 全部引入:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">__all__ = [ <span class=\"string\">'BINARY'</span>, <span class=\"string\">'Binary'</span>, <span class=\"string\">'Connect'</span>, <span class=\"string\">'Connection'</span>, <span class=\"string\">'DATE'</span>,</span><br><span class=\"line\">    <span class=\"string\">'Date'</span>, <span class=\"string\">'Time'</span>, <span class=\"string\">'Timestamp'</span>, <span class=\"string\">'DateFromTicks'</span>, <span class=\"string\">'TimeFromTicks'</span>,</span><br><span class=\"line\">    <span class=\"string\">'TimestampFromTicks'</span>, <span class=\"string\">'DataError'</span>, <span class=\"string\">'DatabaseError'</span>, <span class=\"string\">'Error'</span>,</span><br><span class=\"line\">    <span class=\"string\">'FIELD_TYPE'</span>, <span class=\"string\">'IntegrityError'</span>, <span class=\"string\">'InterfaceError'</span>, <span class=\"string\">'InternalError'</span>,</span><br><span class=\"line\">    <span class=\"string\">'MySQLError'</span>, <span class=\"string\">'NULL'</span>, <span class=\"string\">'NUMBER'</span>, <span class=\"string\">'NotSupportedError'</span>, <span class=\"string\">'DBAPISet'</span>,</span><br><span class=\"line\">    <span class=\"string\">'OperationalError'</span>, <span class=\"string\">'ProgrammingError'</span>, <span class=\"string\">'ROWID'</span>, <span class=\"string\">'STRING'</span>, <span class=\"string\">'TIME'</span>,</span><br><span class=\"line\">    <span class=\"string\">'TIMESTAMP'</span>, <span class=\"string\">'Warning'</span>, <span class=\"string\">'apilevel'</span>, <span class=\"string\">'connect'</span>, <span class=\"string\">'connections'</span>,</span><br><span class=\"line\">    <span class=\"string\">'constants'</span>, <span class=\"string\">'converters'</span>, <span class=\"string\">'cursors'</span>, <span class=\"string\">'debug'</span>, <span class=\"string\">'escape'</span>, <span class=\"string\">'escape_dict'</span>,</span><br><span class=\"line\">    <span class=\"string\">'escape_sequence'</span>, <span class=\"string\">'escape_string'</span>, <span class=\"string\">'get_client_info'</span>,</span><br><span class=\"line\">    <span class=\"string\">'paramstyle'</span>, <span class=\"string\">'string_literal'</span>, <span class=\"string\">'threadsafety'</span>, <span class=\"string\">'version_info'</span>]</span><br></pre></td></tr></table></figure></p>\n<p>不过, 这种情况下不能完全清楚引入了什么 names, 有可能覆盖自己定义的 names, 最好谨慎使用;<br>(2) 其他信息, 如版本, 作者:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 作者</span></span><br><span class=\"line\">__author__ = <span class=\"string\">\"Andy Dustman &lt;farcepest@gmail.com&gt;\"</span></span><br><span class=\"line\"><span class=\"comment\"># 版本信息</span></span><br><span class=\"line\">version_info = (<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">5</span>,<span class=\"string\">'final'</span>,<span class=\"number\">1</span>)</span><br><span class=\"line\">__version__ = <span class=\"string\">\"1.2.5\"</span></span><br></pre></td></tr></table></figure></p>\n<h4 id=\"在-init-py-中定义方法-类\"><a href=\"#在-init-py-中定义方法-类\" class=\"headerlink\" title=\"在 __init__.py 中定义方法/类\"></a><strong>在 __init__.py 中定义方法/类</strong></h4><p>__init__.py 也是 python 源文件, 在其中亦可以定义方法, 类, 或者执行代码段:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># MyPackage: __init__.py</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">test_DBAPISet_set_equality</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">assert</span> STRING == STRING</span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">Binary</span><span class=\"params\">(x)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> str(x)</span><br></pre></td></tr></table></figure></p>\n<p>此时, import 了 MyPackage 之后, 便可以正常使用定义的内容;</p>\n<h3 id=\"python-的工作-搜索路径\"><a href=\"#python-的工作-搜索路径\" class=\"headerlink\" title=\"python 的工作/搜索路径\"></a><strong>python 的工作/搜索路径</strong></h3><p>当导入一个 python 模块时, 解释器的查找路径如下:</p>\n<ol>\n<li>在当前的包中查找;</li>\n<li>在 <code>__buildin__</code> 模块中查找;</li>\n<li>在 sys.path 给定的路径中中查找;</li>\n</ol>\n<p>其中, 第一点自不必说;<br>关于 __buildin__ 模块, 更多的信息请参见另一篇文章: <a href=\"\">python module 使用总结: __buildin__</a>; 上文描述的 dir() 方法其实就是 __buildin__ 模块中的内建方法, 不需要额外引入其他模块便能直接使用;<br>而关于 sys.path, 其初始构成内容又包含了以下几处地方:</p>\n<ol>\n<li>程序的主目录;</li>\n<li>PYTHONPATH 中定义的路径;</li>\n<li>标准链接库, 例如: /usr/lib/python2.7, /usr/local/lib/python2.7 等;</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">import</span> sys</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>sys.path</span><br><span class=\"line\">[<span class=\"string\">''</span>, <span class=\"string\">'/usr/lib64/python27.zip'</span>, <span class=\"string\">'/usr/lib64/python2.7'</span>, <span class=\"string\">'/usr/lib/python2.7/plat-linux2'</span>, <span class=\"string\">'/usr/lib/python2.7/lib-tk'</span>, <span class=\"string\">'/usr/lib/python2.7/lib-old'</span>, <span class=\"string\">'/usr/lib/python2.7/lib-dynload'</span>, <span class=\"string\">'/usr/lib/python2.7/site-packages'</span>, <span class=\"string\">'/usr/lib/python2.7/site-packages'</span>]</span><br></pre></td></tr></table></figure>\n<p>如上所述, 从运行主模块的角度考虑:</p>\n<ol>\n<li>如果引入的模块是第三方模块, 那么大部分情况下, 所需要的模块在标准链接库 dist-packages 中都有, python 能够成功引到;</li>\n<li>如果引入的模块是自己的子模块, 由于子模块一定在主模块的子目录下, 所以 python 也能成功引到;</li>\n<li>如果引入的模块是自己的父模块或者兄弟模块, 这时 python 能否成功引到, 就得分情况了:</li>\n</ol>\n<p>如果工程在自己创建的目录中运行, 引入父模块或者兄弟模块, 在默认的搜索路径里是找不到的;<br>这时要想成功引到目标模块, 有两种办法:<br>(1) 向 sys.path 中拓展添加目标路径:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> sys</span><br><span class=\"line\">sys.path.append(os.path.abspath(<span class=\"string\">'xxx/yyy/zzz'</span>))</span><br></pre></td></tr></table></figure></p>\n<p>(2) 使用 PYTHONPATH, 向其中添加目标路径:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># /etc/profile</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$&#123;PATH&#125;</span>:<span class=\"variable\">$&#123;target_path&#125;</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> PYTHONPATH=<span class=\"variable\">$&#123;PYTHONPATH&#125;</span>:<span class=\"variable\">$&#123;target_path&#125;</span></span><br></pre></td></tr></table></figure></p>\n<p>至于这两种方法的好坏, 就是仁者见仁, 智者见智的问题了;<br>使用 sys.path.append, 比较灵活, 每个模块都可以自己定义, 但缺点是需要多添加两行代码, 比较繁琐;<br>使用 PYTHONPATH, 优点是不需要在自己的模块中添加额外的代码, 但是如果自己创建的工程路径比较零散, PYTHONPATH 就需要不停地补充新路径;<br>不过, 如果有诸如公司规范之类的, 将 python 项目都部署在约定的公共目录下, 那么 PYTHONPATH 只需要添加这一个公共路径即可, 这样问题便简单了;<br>&nbsp;<br>至此, 关于 python 模块导入的基础性问题就讲完了;<br>最后要说的是, 其实本文最开始所列出的那个自定义模块 MyPackage, 其原型是 <code>MySQLdb</code>;</p>\n<h3 id=\"站内相关文章\"><a href=\"#站内相关文章\" class=\"headerlink\" title=\"站内相关文章\"></a><strong>站内相关文章</strong></h3><ul>\n<li><a href=\"\">python module 使用总结: __buildin__</a></li>\n</ul>\n<h3 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a><strong>参考链接</strong></h3><ul>\n<li><a href=\"http://www.cnblogs.com/huwang-sun/p/6993980.html\" target=\"_blank\" rel=\"noopener\">Python 中 if __name__ == ‘__main__’ 理解</a></li>\n<li><a href=\"https://www.cnblogs.com/AlwinXu/p/5658787.html\" target=\"_blank\" rel=\"noopener\">Python 中的包 ImportError</a></li>\n<li><a href=\"https://segmentfault.com/q/1010000007837183?_ea=1477413\" target=\"_blank\" rel=\"noopener\">python import 工程内模块显示错误</a></li>\n<li><a href=\"http://blog.csdn.net/yxmmxy7913/article/details/4233420\" target=\"_blank\" rel=\"noopener\">Python模块包中__init__.py文件的作用</a></li>\n<li><a href=\"http://mikegrouchy.com/blog/2012/05/be-pythonic-__init__py.html\" target=\"_blank\" rel=\"noopener\">Be Pythonic: __init__.py</a></li>\n<li><a href=\"https://www.cnblogs.com/kex1n/p/5977051.html\" target=\"_blank\" rel=\"noopener\">Python类、模块、包的区别</a></li>\n<li><a href=\"http://blog.csdn.net/qw_xingzhe/article/details/52695486\" target=\"_blank\" rel=\"noopener\">Python环境变量PYTHONPATH设置</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>python 有一个关键字和 java 一样: <code>import</code>, 其功能也类似: 在代码中引入其他的依赖(模块)以使用;<br>不过, 不像 java 那么单纯, python 还要区分为 import module 和 import names 两大类; 作为一个 python 新手, 这些使用上的区别有时会令人感到迷惑;<br>python 包和 java 包在概念上也有类似之处, 不过 python 的 __init__.py 规范更讲究一些, java 的 package-info.java 重要性没有那么强, python 初学者在此也很容易栽跟头;<br>在使用了一段时间的 python 之后, 我突然发现, 关于模块引入相关的知识, 我还从来没有过一个系统性的整理; 故作此文以备将来查阅;</p>\n</blockquote>","more":"<hr>\n<p>下面所示的是一个 python 工程结构, 包括了一个父 package 和其下的子 package , 结构比较完整; 本文将以此工程结构为例, 展开内容;<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MyPackage</span><br><span class=\"line\">    ├── connections.py</span><br><span class=\"line\">    ├── constants</span><br><span class=\"line\">    │   ├── CLIENT.py</span><br><span class=\"line\">    │   ├── CR.py</span><br><span class=\"line\">    │   ├── ER.py</span><br><span class=\"line\">    │   ├── FIELD_TYPE.py</span><br><span class=\"line\">    │   ├── FLAG.py</span><br><span class=\"line\">    │   ├── __init__.py</span><br><span class=\"line\">    │   ├── REFRESH.py</span><br><span class=\"line\">    ├── converters.py</span><br><span class=\"line\">    ├── cursors.py</span><br><span class=\"line\">    ├── __init__.py</span><br><span class=\"line\">    ├── release.py</span><br><span class=\"line\">    ├── times.py</span><br></pre></td></tr></table></figure></p>\n<p>其中, 假设 connections.py 中定义了 Connection 类:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># connections.py</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> _mysql</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Connection</span><span class=\"params\">(_mysql.connection)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, *args, **kwargs)</span>:</span></span><br><span class=\"line\">        ...</span><br></pre></td></tr></table></figure></p>\n<p>下面开始本文的内容;</p>\n<h3 id=\"基础预备知识\"><a href=\"#基础预备知识\" class=\"headerlink\" title=\"基础预备知识\"></a><strong>基础预备知识</strong></h3><h4 id=\"对象的-name-字段\"><a href=\"#对象的-name-字段\" class=\"headerlink\" title=\"对象的 __name__ 字段\"></a><strong>对象的 __name__ 字段</strong></h4><p>所有 python 程序的执行必须要有一个入口, 而我们经常见到的入口会有这么一行代码:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br></pre></td></tr></table></figure></p>\n<p>这里面涉及到了一个模块的属性: <code>__name__</code>:<br>当一个模块以主模块被执行时, 该模块的 __name__ 就被解释器设定为 ‘__main__’;<br>当一个模块被其他模块引入时, 该模块的 __name__ 就被解释器设定为 该模块的文件名;</p>\n<h4 id=\"内建方法-dir\"><a href=\"#内建方法-dir\" class=\"headerlink\" title=\"内建方法: dir()\"></a><strong>内建方法: dir()</strong></h4><p>python 中有一个全局内建方法 <code>dir(p_object=None)</code> 可以返回目标作用域里所有的成员 (names);<br>当方法参数 p_object 为 None 时, 默认返回当前作用域内的所有成员:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 在 python shell 里执行, 作用域为主模块, 展示模块属性</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">import</span> MyPackage</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>dir()</span><br><span class=\"line\">[<span class=\"string\">'MyPackage'</span>, <span class=\"string\">'__builtins__'</span>, <span class=\"string\">'__doc__'</span>, <span class=\"string\">'__name__'</span>, <span class=\"string\">'__package__'</span>]</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 在方法内部执行, 作用域为方法内, 展示方法的字段</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">print_dir</span><span class=\"params\">(num=<span class=\"number\">1</span>, str=None)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> dir()</span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    print_dir()</span><br><span class=\"line\"></span><br><span class=\"line\">output:</span><br><span class=\"line\">[<span class=\"string\">'num'</span>, <span class=\"string\">'str'</span>]</span><br></pre></td></tr></table></figure>\n<p>如果指定了目标作用域(对象), 则无论在哪里指定 dir () 方法, 都只打印指定目标的成员;<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> MyPackage.connections <span class=\"keyword\">import</span> Connection</span><br><span class=\"line\"><span class=\"comment\"># 指定作用域</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">print_dir</span><span class=\"params\">(obj=None)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> dir(obj)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    conn = Connection()</span><br><span class=\"line\">    print_dir(conn)</span><br><span class=\"line\"></span><br><span class=\"line\">output:</span><br><span class=\"line\">[<span class=\"string\">'__doc__'</span>, <span class=\"string\">'__init__'</span>, <span class=\"string\">'__module__'</span>]</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"import-的规则语法\"><a href=\"#import-的规则语法\" class=\"headerlink\" title=\"import 的规则语法\"></a><strong>import 的规则语法</strong></h4><p>python 导入其他模块分为两种: import module/package 与 import names (包括变量, 函数, 类等);<br>import module/package 的语法如下:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> MyPackage</span><br><span class=\"line\"><span class=\"keyword\">import</span> MyPackage.connections</span><br></pre></td></tr></table></figure></p>\n<p>import names 的语法如下:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 引入类</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> MyPackage.connections <span class=\"keyword\">import</span> Connection</span><br><span class=\"line\"><span class=\"comment\"># 引入方法</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> MyPackage.connections <span class=\"keyword\">import</span> numeric_part</span><br><span class=\"line\"><span class=\"comment\"># 引入 __all__ 指定的所有 names</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> MyPackage <span class=\"keyword\">import</span> *</span><br></pre></td></tr></table></figure></p>\n<p>对于不同的 package, 不同的 __init__.py 文件, 这些 import 语句所产生的效果都不尽相同, 详细的区别将在下一节描述;</p>\n<h3 id=\"init-py-文件的功能\"><a href=\"#init-py-文件的功能\" class=\"headerlink\" title=\"__init__.py 文件的功能\"></a><strong>__init__.py 文件的功能</strong></h3><p>对于 python 的每一个包来说, __init__.py 是必须的, 它控制着包的导入行为, 并可以表达非常丰富的信息; 如果没有 __init__.py 文件, 那这个包只能算是一个普通目录, 目录下的任何 python 文件都不能作为模块被导入;<br>以下是几种常见的 __init__.py 文件的内容:</p>\n<h4 id=\"init-py-文件内容为空\"><a href=\"#init-py-文件内容为空\" class=\"headerlink\" title=\"__init__.py 文件内容为空\"></a><strong>__init__.py 文件内容为空</strong></h4><p>__init__.py 文件必须有, 但可以是空文件, 这将是最简单的形式, 当然其所提供的功能也最简单: 标识这是一个 python 包, 仅此而已;<br>如果将该包作为一个模块导入, 其实是等于什么都没导入:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">import</span> MyPackage</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>dir()</span><br><span class=\"line\">[<span class=\"string\">'MyPackage'</span>, <span class=\"string\">'__builtins__'</span>, <span class=\"string\">'__doc__'</span>, <span class=\"string\">'__name__'</span>, <span class=\"string\">'__package__'</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>dir(MyPackage)</span><br><span class=\"line\">[<span class=\"string\">'__builtins__'</span>, <span class=\"string\">'__doc__'</span>, <span class=\"string\">'__file__'</span>, <span class=\"string\">'__name__'</span>, <span class=\"string\">'__package__'</span>, <span class=\"string\">'__path__'</span>]</span><br></pre></td></tr></table></figure></p>\n<p>通过 dir() 内建方法可以发现, 无论是当前主模块, 还是 MyPackage 包, 除了一些保留 names, 不再有其他任何自定义符号, 这时将无法直接使用 MyPackage 下的任何模块:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 直接 使用 connections.py 下的 Connection 类</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>conn = MyPackage.connections.Connection()</span><br><span class=\"line\">Traceback (most recent call last):</span><br><span class=\"line\">  File <span class=\"string\">\"&lt;stdin&gt;\"</span>, line <span class=\"number\">1</span>, <span class=\"keyword\">in</span> &lt;module&gt;</span><br><span class=\"line\">NameError: name <span class=\"string\">'MyPackage'</span> <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> defined</span><br></pre></td></tr></table></figure></p>\n<p>不过, 既然 __init__.py 已经标识了这是一个 python 包, 所以对于包下所有其他的模块文件, 我们可以主动引入它们, 这算是空 __init__.py 的唯一作用:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 主动引入模块</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">import</span> MyPackage.connections</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>dir(MyPackage)</span><br><span class=\"line\">[<span class=\"string\">'__builtins__'</span>, <span class=\"string\">'__doc__'</span>, <span class=\"string\">'__file__'</span>, <span class=\"string\">'__name__'</span>, <span class=\"string\">'__package__'</span>, <span class=\"string\">'__path__'</span>, <span class=\"string\">'connections'</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>dir(MyPackage.connections)</span><br><span class=\"line\">[<span class=\"string\">'Connection'</span>, <span class=\"string\">'__builtins__'</span>, <span class=\"string\">'__doc__'</span>, <span class=\"string\">'__file__'</span>, <span class=\"string\">'__name__'</span>, <span class=\"string\">'__package__'</span>, <span class=\"string\">'numeric_part'</span>]</span><br></pre></td></tr></table></figure></p>\n<p>这时可以发现, dir(MyPackage) 列表里有了 connections 模块, dir(MyPackage.connections) 列表里有了 Connection 类; 这时带着 python 路径, 就可以使用 target name 了:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>conn = MyPackage.connections.Connection()</span><br></pre></td></tr></table></figure></p>\n<p>另外, 如果使用 from … import … 主动引入目标符号:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">from</span> MyPackage.connections <span class=\"keyword\">import</span> Connection</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>dir()</span><br><span class=\"line\">[<span class=\"string\">'Connection'</span>, <span class=\"string\">'__builtins__'</span>, <span class=\"string\">'__doc__'</span>, <span class=\"string\">'__name__'</span>, <span class=\"string\">'__package__'</span>]</span><br></pre></td></tr></table></figure></p>\n<p>便可以直接将目标符号引入当前作用域, 不需要使用模块路径, 就可以直接使用:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>conn = Connection()</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"在-init-py-中-import-其他模块\"><a href=\"#在-init-py-中-import-其他模块\" class=\"headerlink\" title=\"在 __init__.py 中 import 其他模块\"></a><strong>在 __init__.py 中 import 其他模块</strong></h4><p>__init__.py 中自己主动 import 第三方模块是一种常见的操作:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># __init__.py</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> connections</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">import</span> MyPackage</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>dir(MyPackage)</span><br><span class=\"line\">[<span class=\"string\">'__builtins__'</span>, <span class=\"string\">'__doc__'</span>, <span class=\"string\">'__file__'</span>, <span class=\"string\">'__name__'</span>, <span class=\"string\">'__package__'</span>, <span class=\"string\">'__path__'</span>, <span class=\"string\">'connections'</span>]</span><br><span class=\"line\"><span class=\"comment\"># 路径是 MyPackage.connections</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>conn = MyPackage.connections.Connection()</span><br></pre></td></tr></table></figure>\n<p>或者使用 from … import … 语法:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># __init__.py</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> connections <span class=\"keyword\">import</span> Connection</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">import</span> MyPackage</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>dir(MyPackage)</span><br><span class=\"line\">[<span class=\"string\">'Connection'</span>, <span class=\"string\">'__builtins__'</span>, <span class=\"string\">'__doc__'</span>, <span class=\"string\">'__file__'</span>, <span class=\"string\">'__name__'</span>, <span class=\"string\">'__package__'</span>, <span class=\"string\">'__path__'</span>, <span class=\"string\">'connections'</span>]</span><br><span class=\"line\"><span class=\"comment\"># 路径是 MyPackage</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>conn = MyPackage.Connection()</span><br></pre></td></tr></table></figure>\n<p>对于以上两种 import 方式, 结合 dir() 内建方法的展示, 可以发现在具体使用目标符号时所带路径的区别;</p>\n<h4 id=\"init-py-中的保留字段\"><a href=\"#init-py-中的保留字段\" class=\"headerlink\" title=\"__init__.py 中的保留字段\"></a><strong>__init__.py 中的保留字段</strong></h4><p>(1) __all__ 字段:<br>如果在代码中使用了如下的引用方式:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> MyPackage <span class=\"keyword\">import</span> *</span><br></pre></td></tr></table></figure></p>\n<p>解释器便会试图去指定的模块中寻找 <code>__all__</code> 字段, 将该列表中列举的所有 names 全部引入:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">__all__ = [ <span class=\"string\">'BINARY'</span>, <span class=\"string\">'Binary'</span>, <span class=\"string\">'Connect'</span>, <span class=\"string\">'Connection'</span>, <span class=\"string\">'DATE'</span>,</span><br><span class=\"line\">    <span class=\"string\">'Date'</span>, <span class=\"string\">'Time'</span>, <span class=\"string\">'Timestamp'</span>, <span class=\"string\">'DateFromTicks'</span>, <span class=\"string\">'TimeFromTicks'</span>,</span><br><span class=\"line\">    <span class=\"string\">'TimestampFromTicks'</span>, <span class=\"string\">'DataError'</span>, <span class=\"string\">'DatabaseError'</span>, <span class=\"string\">'Error'</span>,</span><br><span class=\"line\">    <span class=\"string\">'FIELD_TYPE'</span>, <span class=\"string\">'IntegrityError'</span>, <span class=\"string\">'InterfaceError'</span>, <span class=\"string\">'InternalError'</span>,</span><br><span class=\"line\">    <span class=\"string\">'MySQLError'</span>, <span class=\"string\">'NULL'</span>, <span class=\"string\">'NUMBER'</span>, <span class=\"string\">'NotSupportedError'</span>, <span class=\"string\">'DBAPISet'</span>,</span><br><span class=\"line\">    <span class=\"string\">'OperationalError'</span>, <span class=\"string\">'ProgrammingError'</span>, <span class=\"string\">'ROWID'</span>, <span class=\"string\">'STRING'</span>, <span class=\"string\">'TIME'</span>,</span><br><span class=\"line\">    <span class=\"string\">'TIMESTAMP'</span>, <span class=\"string\">'Warning'</span>, <span class=\"string\">'apilevel'</span>, <span class=\"string\">'connect'</span>, <span class=\"string\">'connections'</span>,</span><br><span class=\"line\">    <span class=\"string\">'constants'</span>, <span class=\"string\">'converters'</span>, <span class=\"string\">'cursors'</span>, <span class=\"string\">'debug'</span>, <span class=\"string\">'escape'</span>, <span class=\"string\">'escape_dict'</span>,</span><br><span class=\"line\">    <span class=\"string\">'escape_sequence'</span>, <span class=\"string\">'escape_string'</span>, <span class=\"string\">'get_client_info'</span>,</span><br><span class=\"line\">    <span class=\"string\">'paramstyle'</span>, <span class=\"string\">'string_literal'</span>, <span class=\"string\">'threadsafety'</span>, <span class=\"string\">'version_info'</span>]</span><br></pre></td></tr></table></figure></p>\n<p>不过, 这种情况下不能完全清楚引入了什么 names, 有可能覆盖自己定义的 names, 最好谨慎使用;<br>(2) 其他信息, 如版本, 作者:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 作者</span></span><br><span class=\"line\">__author__ = <span class=\"string\">\"Andy Dustman &lt;farcepest@gmail.com&gt;\"</span></span><br><span class=\"line\"><span class=\"comment\"># 版本信息</span></span><br><span class=\"line\">version_info = (<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">5</span>,<span class=\"string\">'final'</span>,<span class=\"number\">1</span>)</span><br><span class=\"line\">__version__ = <span class=\"string\">\"1.2.5\"</span></span><br></pre></td></tr></table></figure></p>\n<h4 id=\"在-init-py-中定义方法-类\"><a href=\"#在-init-py-中定义方法-类\" class=\"headerlink\" title=\"在 __init__.py 中定义方法/类\"></a><strong>在 __init__.py 中定义方法/类</strong></h4><p>__init__.py 也是 python 源文件, 在其中亦可以定义方法, 类, 或者执行代码段:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># MyPackage: __init__.py</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">test_DBAPISet_set_equality</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">assert</span> STRING == STRING</span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">Binary</span><span class=\"params\">(x)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> str(x)</span><br></pre></td></tr></table></figure></p>\n<p>此时, import 了 MyPackage 之后, 便可以正常使用定义的内容;</p>\n<h3 id=\"python-的工作-搜索路径\"><a href=\"#python-的工作-搜索路径\" class=\"headerlink\" title=\"python 的工作/搜索路径\"></a><strong>python 的工作/搜索路径</strong></h3><p>当导入一个 python 模块时, 解释器的查找路径如下:</p>\n<ol>\n<li>在当前的包中查找;</li>\n<li>在 <code>__buildin__</code> 模块中查找;</li>\n<li>在 sys.path 给定的路径中中查找;</li>\n</ol>\n<p>其中, 第一点自不必说;<br>关于 __buildin__ 模块, 更多的信息请参见另一篇文章: <a href=\"\">python module 使用总结: __buildin__</a>; 上文描述的 dir() 方法其实就是 __buildin__ 模块中的内建方法, 不需要额外引入其他模块便能直接使用;<br>而关于 sys.path, 其初始构成内容又包含了以下几处地方:</p>\n<ol>\n<li>程序的主目录;</li>\n<li>PYTHONPATH 中定义的路径;</li>\n<li>标准链接库, 例如: /usr/lib/python2.7, /usr/local/lib/python2.7 等;</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">import</span> sys</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>sys.path</span><br><span class=\"line\">[<span class=\"string\">''</span>, <span class=\"string\">'/usr/lib64/python27.zip'</span>, <span class=\"string\">'/usr/lib64/python2.7'</span>, <span class=\"string\">'/usr/lib/python2.7/plat-linux2'</span>, <span class=\"string\">'/usr/lib/python2.7/lib-tk'</span>, <span class=\"string\">'/usr/lib/python2.7/lib-old'</span>, <span class=\"string\">'/usr/lib/python2.7/lib-dynload'</span>, <span class=\"string\">'/usr/lib/python2.7/site-packages'</span>, <span class=\"string\">'/usr/lib/python2.7/site-packages'</span>]</span><br></pre></td></tr></table></figure>\n<p>如上所述, 从运行主模块的角度考虑:</p>\n<ol>\n<li>如果引入的模块是第三方模块, 那么大部分情况下, 所需要的模块在标准链接库 dist-packages 中都有, python 能够成功引到;</li>\n<li>如果引入的模块是自己的子模块, 由于子模块一定在主模块的子目录下, 所以 python 也能成功引到;</li>\n<li>如果引入的模块是自己的父模块或者兄弟模块, 这时 python 能否成功引到, 就得分情况了:</li>\n</ol>\n<p>如果工程在自己创建的目录中运行, 引入父模块或者兄弟模块, 在默认的搜索路径里是找不到的;<br>这时要想成功引到目标模块, 有两种办法:<br>(1) 向 sys.path 中拓展添加目标路径:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> sys</span><br><span class=\"line\">sys.path.append(os.path.abspath(<span class=\"string\">'xxx/yyy/zzz'</span>))</span><br></pre></td></tr></table></figure></p>\n<p>(2) 使用 PYTHONPATH, 向其中添加目标路径:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># /etc/profile</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$&#123;PATH&#125;</span>:<span class=\"variable\">$&#123;target_path&#125;</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> PYTHONPATH=<span class=\"variable\">$&#123;PYTHONPATH&#125;</span>:<span class=\"variable\">$&#123;target_path&#125;</span></span><br></pre></td></tr></table></figure></p>\n<p>至于这两种方法的好坏, 就是仁者见仁, 智者见智的问题了;<br>使用 sys.path.append, 比较灵活, 每个模块都可以自己定义, 但缺点是需要多添加两行代码, 比较繁琐;<br>使用 PYTHONPATH, 优点是不需要在自己的模块中添加额外的代码, 但是如果自己创建的工程路径比较零散, PYTHONPATH 就需要不停地补充新路径;<br>不过, 如果有诸如公司规范之类的, 将 python 项目都部署在约定的公共目录下, 那么 PYTHONPATH 只需要添加这一个公共路径即可, 这样问题便简单了;<br>&nbsp;<br>至此, 关于 python 模块导入的基础性问题就讲完了;<br>最后要说的是, 其实本文最开始所列出的那个自定义模块 MyPackage, 其原型是 <code>MySQLdb</code>;</p>\n<h3 id=\"站内相关文章\"><a href=\"#站内相关文章\" class=\"headerlink\" title=\"站内相关文章\"></a><strong>站内相关文章</strong></h3><ul>\n<li><a href=\"\">python module 使用总结: __buildin__</a></li>\n</ul>\n<h3 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a><strong>参考链接</strong></h3><ul>\n<li><a href=\"http://www.cnblogs.com/huwang-sun/p/6993980.html\" target=\"_blank\" rel=\"noopener\">Python 中 if __name__ == ‘__main__’ 理解</a></li>\n<li><a href=\"https://www.cnblogs.com/AlwinXu/p/5658787.html\" target=\"_blank\" rel=\"noopener\">Python 中的包 ImportError</a></li>\n<li><a href=\"https://segmentfault.com/q/1010000007837183?_ea=1477413\" target=\"_blank\" rel=\"noopener\">python import 工程内模块显示错误</a></li>\n<li><a href=\"http://blog.csdn.net/yxmmxy7913/article/details/4233420\" target=\"_blank\" rel=\"noopener\">Python模块包中__init__.py文件的作用</a></li>\n<li><a href=\"http://mikegrouchy.com/blog/2012/05/be-pythonic-__init__py.html\" target=\"_blank\" rel=\"noopener\">Be Pythonic: __init__.py</a></li>\n<li><a href=\"https://www.cnblogs.com/kex1n/p/5977051.html\" target=\"_blank\" rel=\"noopener\">Python类、模块、包的区别</a></li>\n<li><a href=\"http://blog.csdn.net/qw_xingzhe/article/details/52695486\" target=\"_blank\" rel=\"noopener\">Python环境变量PYTHONPATH设置</a></li>\n</ul>"},{"title":"linux signals 总体认识","date":"2017-04-05T15:24:22.000Z","_content":"\n> linux 的信号系统其实是一个非常重要的概念, 进程间通信的常用方法之一;\n不过长期以来, 我们对 linux 信号的直观认识, 只有 kill (SIGTERM), ctrl + c (SIGINT) 和 kill -9 等进程终止信号; 而 linux 的信号系统中存在 64 种各司其职的信号, 适用于各种各样的场景; 很多信号在实际工作中有着妙用;\n本文正是想对 linux 世界中林林总总的 signals 作一次梳理, 总结一些日常工作中频繁使用以及不太接触但十分有用的信号;\n\n<!--more-->\n\n## **linux signals 总览**\nlinux siginal 可分为如下几大类:\n\n1. 系统错误信号\n2. 进程终止信号\n3. 作业控制信号\n4. AIO 信号\n5. 定时器信号\n6. 操作错误信号\n7. 其他信号\n\n&nbsp;\nlinux signals 的产生源一般分为三类: 硬件方式(除数为 0, 内存非法访问等), IO 方式(键盘事件), 以及软件方式: kill 命令, alarm 定时器等;\n其中我们最熟悉的莫不过 kill 命令了, 详情请见: [kill 命令族及其选项]();\n\n&nbsp;\n使用 kill -l 查看所有信号分布:\n``` bash\n> kill -l\n 1) SIGHUP\t     2) SIGINT\t    \t 3) SIGQUIT\t     4) SIGILL\t    \t 5) SIGTRAP\n 6) SIGABRT\t     7) SIGBUS\t    \t 8) SIGFPE\t     9) SIGKILL\t    \t10) SIGUSR1\n11) SIGSEGV\t    12) SIGUSR2\t    \t13) SIGPIPE\t    14) SIGALRM\t    \t15) SIGTERM\n16) SIGSTKFLT\t    17) SIGCHLD\t    \t18) SIGCONT\t    19) SIGSTOP\t    \t20) SIGTSTP\n21) SIGTTIN\t    22) SIGTTOU\t    \t23) SIGURG\t    24) SIGXCPU\t    \t25) SIGXFSZ\n26) SIGVTALRM\t    27) SIGPROF\t    \t28) SIGWINCH        29) SIGIO\t    \t30) SIGPWR\n31) SIGSYS\t    34) SIGRTMIN    \t35) SIGRTMIN+1      36) SIGRTMIN+2  \t37) SIGRTMIN+3\n38) SIGRTMIN+4\t    39) SIGRTMIN+5  \t40) SIGRTMIN+6      41) SIGRTMIN+7  \t42) SIGRTMIN+8\n43) SIGRTMIN+9\t    44) SIGRTMIN+10 \t45) SIGRTMIN+11     46) SIGRTMIN+12 \t47) SIGRTMIN+13\n48) SIGRTMIN+14\t    49) SIGRTMIN+15 \t50) SIGRTMAX-14     51) SIGRTMAX-13 \t52) SIGRTMAX-12\n53) SIGRTMAX-11\t    54) SIGRTMAX-10 \t55) SIGRTMAX-9      56) SIGRTMAX-8  \t57) SIGRTMAX-7\n58) SIGRTMAX-6\t    59) SIGRTMAX-5  \t60) SIGRTMAX-4      61) SIGRTMAX-3  \t62) SIGRTMAX-2\n63) SIGRTMAX-1\t    64) SIGRTMAX\n```\n\n## **各类别信号整理**\n\n### **进程终止信号**\n进程终止信号是我们日常操作中最常用的一类信号;\n进程终止信号共有五个, 其中除了 SIGKILL 之外, 其他信号都是 可阻塞, 可忽略, 可处理的;\n``` bash\n# terminate, kill 不加任何选项的默认信号, 默认处理是终止进程;\nSIGTERM\n# interrupt, ctrl + c 发出的信号, 默认处理是终止进程;\nSIGINT\n# quit, ctrl + / 发出的信号, 与 SIGINT 类似, 不过其默认处理相比 SIGINT 还增加了一项:\n# 1. 终止进程; 2. 产生进程 core dump 文件;\nSIGQUIT\n# kill, 不可阻塞, 不可忽略, 最强力的终止信号, 通常会导致进程立即终止, 其占有的资源无法释放清理\n# 一般需要在 SIGTERM/SIGINT/SIGQUIT 等信号无法响应之后, 才最后使用\nSIGKILL\n# hang up, 通常在用户退出终端断开 sessiion 时由系统发出该信号给 session\n# session 接收该信号并将其发送给子进程\nSIGHUP\n```\n另外一篇详细梳理与 SIGHUP 相关知识点的链接: [SIGHUP 相关全梳理]();\n该文章主要涉及 SIGHUP 信号发生的条件, 传导, 与 SIGHUP 相关的 nohup, &,  shopt huponexit, disown 等概念, 并包括一些 SIGHUP 的自定义应用;\n\n### **任务控制信号**\n\n### **其他信号**\n其他信号是指未在上述分类中的一些小众信号, 这些信号本身并未有太多关联, 不能用一个类别去统一描述它们;\n&nbsp;\n(1) 用户自定义信号: SIGUSR1 / SIGUSR2\n这两个信号, linux 保证系统自身不会向进程发送, 完全由使用者自己定义该信号的语义以及处理逻辑;\nSIGUSR1 与 SIGUSR2, 在系统层面完全没有区别, 如果可以, linux 其实能再定义一个 SIGUSR3; 所以用户自定义信号的预留数量, 本身是一个模糊的界定;\n以下是 SIGUSR1 / SIGUSR2 的具体使用场景:\n``` bash\n# 通知 nginx 关闭当前句柄, 重新打开日志文件, 用于 logrotate 切割日志\nkill -USR1 `cat /var/run/nginx.pid`\n# 通知 nginx 平滑升级 二进制可执行程序\nkill -s SIGUSR2 `cat /var/run/nginx.pid`\n```\n&nbsp;\n(2) SIGWINCH (winch 译作: 吊车, 摇柄), 默认处理是忽略该信号;\n以下是 SIGWINCH 的具体使用场景:\n``` bash\n# 通知 nginx worker process 不再接受新 request, 并从容关闭\nkill -WINCH `cat /var/run/nginx.pid`\n```\n当然, 通知 worker process 不再接受新请求, nginx 并不需要使用者直接在 linux signals 层面直接处理, nginx 本身提供了平滑重启命令 `sbin/nginx -c conf/nginx.conf -s reload`, SIGWINCH 信号的发送封装在了该命令里;\n&nbsp;\n关于 nginx 与 linux signals 的关系, 在本站另一篇文章中有详细介绍: [nginx signals 处理]();\n\n## **站内相关文章**\n- [kill 命令族及其选项]()\n- [SIGHUP 相关全梳理]()\n- [nginx signals 处理]()\n\n## **参考链接**\n- [24.2.2 Termination Signals](http://www.gnu.org/software/libc/manual/html_node/Termination-Signals.html#Termination-Signals)\n- [24.2.5 Job Control Signals](http://www.gnu.org/software/libc/manual/html_node/Job-Control-Signals.html)\n- [24.2.7 Miscellaneous Signals](http://www.gnu.org/software/libc/manual/html_node/Miscellaneous-Signals.html#Miscellaneous-Signals)\n- [Difference between SIGUSR1 and SIGUSR2](https://stackoverflow.com/questions/27403641/difference-between-sigusr1-and-sigusr2)\n- [linux kill 命令 以及 USR1 信号 解释](http://blog.csdn.net/fuming0210sc/article/details/50906372)\n- [Linux 信号入门详解](http://blog.csdn.net/lisongjia123/article/details/50471854)\n- [文章3: Nginx中与信号有关的内容](http://blog.csdn.net/yankai0219/article/details/8453261)\n\n","source":"_posts/linux-process--linux_signals总体认识.md","raw":"---\ntitle: linux signals 总体认识\ndate: 2017-04-05 23:24:22\ncategories:\n  - linux\n  - process\ntags:\n  - linux:process\n---\n\n> linux 的信号系统其实是一个非常重要的概念, 进程间通信的常用方法之一;\n不过长期以来, 我们对 linux 信号的直观认识, 只有 kill (SIGTERM), ctrl + c (SIGINT) 和 kill -9 等进程终止信号; 而 linux 的信号系统中存在 64 种各司其职的信号, 适用于各种各样的场景; 很多信号在实际工作中有着妙用;\n本文正是想对 linux 世界中林林总总的 signals 作一次梳理, 总结一些日常工作中频繁使用以及不太接触但十分有用的信号;\n\n<!--more-->\n\n## **linux signals 总览**\nlinux siginal 可分为如下几大类:\n\n1. 系统错误信号\n2. 进程终止信号\n3. 作业控制信号\n4. AIO 信号\n5. 定时器信号\n6. 操作错误信号\n7. 其他信号\n\n&nbsp;\nlinux signals 的产生源一般分为三类: 硬件方式(除数为 0, 内存非法访问等), IO 方式(键盘事件), 以及软件方式: kill 命令, alarm 定时器等;\n其中我们最熟悉的莫不过 kill 命令了, 详情请见: [kill 命令族及其选项]();\n\n&nbsp;\n使用 kill -l 查看所有信号分布:\n``` bash\n> kill -l\n 1) SIGHUP\t     2) SIGINT\t    \t 3) SIGQUIT\t     4) SIGILL\t    \t 5) SIGTRAP\n 6) SIGABRT\t     7) SIGBUS\t    \t 8) SIGFPE\t     9) SIGKILL\t    \t10) SIGUSR1\n11) SIGSEGV\t    12) SIGUSR2\t    \t13) SIGPIPE\t    14) SIGALRM\t    \t15) SIGTERM\n16) SIGSTKFLT\t    17) SIGCHLD\t    \t18) SIGCONT\t    19) SIGSTOP\t    \t20) SIGTSTP\n21) SIGTTIN\t    22) SIGTTOU\t    \t23) SIGURG\t    24) SIGXCPU\t    \t25) SIGXFSZ\n26) SIGVTALRM\t    27) SIGPROF\t    \t28) SIGWINCH        29) SIGIO\t    \t30) SIGPWR\n31) SIGSYS\t    34) SIGRTMIN    \t35) SIGRTMIN+1      36) SIGRTMIN+2  \t37) SIGRTMIN+3\n38) SIGRTMIN+4\t    39) SIGRTMIN+5  \t40) SIGRTMIN+6      41) SIGRTMIN+7  \t42) SIGRTMIN+8\n43) SIGRTMIN+9\t    44) SIGRTMIN+10 \t45) SIGRTMIN+11     46) SIGRTMIN+12 \t47) SIGRTMIN+13\n48) SIGRTMIN+14\t    49) SIGRTMIN+15 \t50) SIGRTMAX-14     51) SIGRTMAX-13 \t52) SIGRTMAX-12\n53) SIGRTMAX-11\t    54) SIGRTMAX-10 \t55) SIGRTMAX-9      56) SIGRTMAX-8  \t57) SIGRTMAX-7\n58) SIGRTMAX-6\t    59) SIGRTMAX-5  \t60) SIGRTMAX-4      61) SIGRTMAX-3  \t62) SIGRTMAX-2\n63) SIGRTMAX-1\t    64) SIGRTMAX\n```\n\n## **各类别信号整理**\n\n### **进程终止信号**\n进程终止信号是我们日常操作中最常用的一类信号;\n进程终止信号共有五个, 其中除了 SIGKILL 之外, 其他信号都是 可阻塞, 可忽略, 可处理的;\n``` bash\n# terminate, kill 不加任何选项的默认信号, 默认处理是终止进程;\nSIGTERM\n# interrupt, ctrl + c 发出的信号, 默认处理是终止进程;\nSIGINT\n# quit, ctrl + / 发出的信号, 与 SIGINT 类似, 不过其默认处理相比 SIGINT 还增加了一项:\n# 1. 终止进程; 2. 产生进程 core dump 文件;\nSIGQUIT\n# kill, 不可阻塞, 不可忽略, 最强力的终止信号, 通常会导致进程立即终止, 其占有的资源无法释放清理\n# 一般需要在 SIGTERM/SIGINT/SIGQUIT 等信号无法响应之后, 才最后使用\nSIGKILL\n# hang up, 通常在用户退出终端断开 sessiion 时由系统发出该信号给 session\n# session 接收该信号并将其发送给子进程\nSIGHUP\n```\n另外一篇详细梳理与 SIGHUP 相关知识点的链接: [SIGHUP 相关全梳理]();\n该文章主要涉及 SIGHUP 信号发生的条件, 传导, 与 SIGHUP 相关的 nohup, &,  shopt huponexit, disown 等概念, 并包括一些 SIGHUP 的自定义应用;\n\n### **任务控制信号**\n\n### **其他信号**\n其他信号是指未在上述分类中的一些小众信号, 这些信号本身并未有太多关联, 不能用一个类别去统一描述它们;\n&nbsp;\n(1) 用户自定义信号: SIGUSR1 / SIGUSR2\n这两个信号, linux 保证系统自身不会向进程发送, 完全由使用者自己定义该信号的语义以及处理逻辑;\nSIGUSR1 与 SIGUSR2, 在系统层面完全没有区别, 如果可以, linux 其实能再定义一个 SIGUSR3; 所以用户自定义信号的预留数量, 本身是一个模糊的界定;\n以下是 SIGUSR1 / SIGUSR2 的具体使用场景:\n``` bash\n# 通知 nginx 关闭当前句柄, 重新打开日志文件, 用于 logrotate 切割日志\nkill -USR1 `cat /var/run/nginx.pid`\n# 通知 nginx 平滑升级 二进制可执行程序\nkill -s SIGUSR2 `cat /var/run/nginx.pid`\n```\n&nbsp;\n(2) SIGWINCH (winch 译作: 吊车, 摇柄), 默认处理是忽略该信号;\n以下是 SIGWINCH 的具体使用场景:\n``` bash\n# 通知 nginx worker process 不再接受新 request, 并从容关闭\nkill -WINCH `cat /var/run/nginx.pid`\n```\n当然, 通知 worker process 不再接受新请求, nginx 并不需要使用者直接在 linux signals 层面直接处理, nginx 本身提供了平滑重启命令 `sbin/nginx -c conf/nginx.conf -s reload`, SIGWINCH 信号的发送封装在了该命令里;\n&nbsp;\n关于 nginx 与 linux signals 的关系, 在本站另一篇文章中有详细介绍: [nginx signals 处理]();\n\n## **站内相关文章**\n- [kill 命令族及其选项]()\n- [SIGHUP 相关全梳理]()\n- [nginx signals 处理]()\n\n## **参考链接**\n- [24.2.2 Termination Signals](http://www.gnu.org/software/libc/manual/html_node/Termination-Signals.html#Termination-Signals)\n- [24.2.5 Job Control Signals](http://www.gnu.org/software/libc/manual/html_node/Job-Control-Signals.html)\n- [24.2.7 Miscellaneous Signals](http://www.gnu.org/software/libc/manual/html_node/Miscellaneous-Signals.html#Miscellaneous-Signals)\n- [Difference between SIGUSR1 and SIGUSR2](https://stackoverflow.com/questions/27403641/difference-between-sigusr1-and-sigusr2)\n- [linux kill 命令 以及 USR1 信号 解释](http://blog.csdn.net/fuming0210sc/article/details/50906372)\n- [Linux 信号入门详解](http://blog.csdn.net/lisongjia123/article/details/50471854)\n- [文章3: Nginx中与信号有关的内容](http://blog.csdn.net/yankai0219/article/details/8453261)\n\n","slug":"linux-process--linux_signals总体认识","published":1,"updated":"2018-01-20T12:10:14.216Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cje24mxu3000gj1jxjfg2tuuf","content":"<blockquote>\n<p>linux 的信号系统其实是一个非常重要的概念, 进程间通信的常用方法之一;<br>不过长期以来, 我们对 linux 信号的直观认识, 只有 kill (SIGTERM), ctrl + c (SIGINT) 和 kill -9 等进程终止信号; 而 linux 的信号系统中存在 64 种各司其职的信号, 适用于各种各样的场景; 很多信号在实际工作中有着妙用;<br>本文正是想对 linux 世界中林林总总的 signals 作一次梳理, 总结一些日常工作中频繁使用以及不太接触但十分有用的信号;</p>\n</blockquote>\n<a id=\"more\"></a>\n<h2 id=\"linux-signals-总览\"><a href=\"#linux-signals-总览\" class=\"headerlink\" title=\"linux signals 总览\"></a><strong>linux signals 总览</strong></h2><p>linux siginal 可分为如下几大类:</p>\n<ol>\n<li>系统错误信号</li>\n<li>进程终止信号</li>\n<li>作业控制信号</li>\n<li>AIO 信号</li>\n<li>定时器信号</li>\n<li>操作错误信号</li>\n<li>其他信号</li>\n</ol>\n<p>&nbsp;<br>linux signals 的产生源一般分为三类: 硬件方式(除数为 0, 内存非法访问等), IO 方式(键盘事件), 以及软件方式: kill 命令, alarm 定时器等;<br>其中我们最熟悉的莫不过 kill 命令了, 详情请见: <a href=\"\">kill 命令族及其选项</a>;</p>\n<p>&nbsp;<br>使用 kill -l 查看所有信号分布:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; <span class=\"built_in\">kill</span> -l</span><br><span class=\"line\"> 1) SIGHUP\t     2) SIGINT\t    \t 3) SIGQUIT\t     4) SIGILL\t    \t 5) SIGTRAP</span><br><span class=\"line\"> 6) SIGABRT\t     7) SIGBUS\t    \t 8) SIGFPE\t     9) SIGKILL\t    \t10) SIGUSR1</span><br><span class=\"line\">11) SIGSEGV\t    12) SIGUSR2\t    \t13) SIGPIPE\t    14) SIGALRM\t    \t15) SIGTERM</span><br><span class=\"line\">16) SIGSTKFLT\t    17) SIGCHLD\t    \t18) SIGCONT\t    19) SIGSTOP\t    \t20) SIGTSTP</span><br><span class=\"line\">21) SIGTTIN\t    22) SIGTTOU\t    \t23) SIGURG\t    24) SIGXCPU\t    \t25) SIGXFSZ</span><br><span class=\"line\">26) SIGVTALRM\t    27) SIGPROF\t    \t28) SIGWINCH        29) SIGIO\t    \t30) SIGPWR</span><br><span class=\"line\">31) SIGSYS\t    34) SIGRTMIN    \t35) SIGRTMIN+1      36) SIGRTMIN+2  \t37) SIGRTMIN+3</span><br><span class=\"line\">38) SIGRTMIN+4\t    39) SIGRTMIN+5  \t40) SIGRTMIN+6      41) SIGRTMIN+7  \t42) SIGRTMIN+8</span><br><span class=\"line\">43) SIGRTMIN+9\t    44) SIGRTMIN+10 \t45) SIGRTMIN+11     46) SIGRTMIN+12 \t47) SIGRTMIN+13</span><br><span class=\"line\">48) SIGRTMIN+14\t    49) SIGRTMIN+15 \t50) SIGRTMAX-14     51) SIGRTMAX-13 \t52) SIGRTMAX-12</span><br><span class=\"line\">53) SIGRTMAX-11\t    54) SIGRTMAX-10 \t55) SIGRTMAX-9      56) SIGRTMAX-8  \t57) SIGRTMAX-7</span><br><span class=\"line\">58) SIGRTMAX-6\t    59) SIGRTMAX-5  \t60) SIGRTMAX-4      61) SIGRTMAX-3  \t62) SIGRTMAX-2</span><br><span class=\"line\">63) SIGRTMAX-1\t    64) SIGRTMAX</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"各类别信号整理\"><a href=\"#各类别信号整理\" class=\"headerlink\" title=\"各类别信号整理\"></a><strong>各类别信号整理</strong></h2><h3 id=\"进程终止信号\"><a href=\"#进程终止信号\" class=\"headerlink\" title=\"进程终止信号\"></a><strong>进程终止信号</strong></h3><p>进程终止信号是我们日常操作中最常用的一类信号;<br>进程终止信号共有五个, 其中除了 SIGKILL 之外, 其他信号都是 可阻塞, 可忽略, 可处理的;<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># terminate, kill 不加任何选项的默认信号, 默认处理是终止进程;</span></span><br><span class=\"line\">SIGTERM</span><br><span class=\"line\"><span class=\"comment\"># interrupt, ctrl + c 发出的信号, 默认处理是终止进程;</span></span><br><span class=\"line\">SIGINT</span><br><span class=\"line\"><span class=\"comment\"># quit, ctrl + / 发出的信号, 与 SIGINT 类似, 不过其默认处理相比 SIGINT 还增加了一项:</span></span><br><span class=\"line\"><span class=\"comment\"># 1. 终止进程; 2. 产生进程 core dump 文件;</span></span><br><span class=\"line\">SIGQUIT</span><br><span class=\"line\"><span class=\"comment\"># kill, 不可阻塞, 不可忽略, 最强力的终止信号, 通常会导致进程立即终止, 其占有的资源无法释放清理</span></span><br><span class=\"line\"><span class=\"comment\"># 一般需要在 SIGTERM/SIGINT/SIGQUIT 等信号无法响应之后, 才最后使用</span></span><br><span class=\"line\">SIGKILL</span><br><span class=\"line\"><span class=\"comment\"># hang up, 通常在用户退出终端断开 sessiion 时由系统发出该信号给 session</span></span><br><span class=\"line\"><span class=\"comment\"># session 接收该信号并将其发送给子进程</span></span><br><span class=\"line\">SIGHUP</span><br></pre></td></tr></table></figure></p>\n<p>另外一篇详细梳理与 SIGHUP 相关知识点的链接: <a href=\"\">SIGHUP 相关全梳理</a>;<br>该文章主要涉及 SIGHUP 信号发生的条件, 传导, 与 SIGHUP 相关的 nohup, &amp;,  shopt huponexit, disown 等概念, 并包括一些 SIGHUP 的自定义应用;</p>\n<h3 id=\"任务控制信号\"><a href=\"#任务控制信号\" class=\"headerlink\" title=\"任务控制信号\"></a><strong>任务控制信号</strong></h3><h3 id=\"其他信号\"><a href=\"#其他信号\" class=\"headerlink\" title=\"其他信号\"></a><strong>其他信号</strong></h3><p>其他信号是指未在上述分类中的一些小众信号, 这些信号本身并未有太多关联, 不能用一个类别去统一描述它们;<br>&nbsp;<br>(1) 用户自定义信号: SIGUSR1 / SIGUSR2<br>这两个信号, linux 保证系统自身不会向进程发送, 完全由使用者自己定义该信号的语义以及处理逻辑;<br>SIGUSR1 与 SIGUSR2, 在系统层面完全没有区别, 如果可以, linux 其实能再定义一个 SIGUSR3; 所以用户自定义信号的预留数量, 本身是一个模糊的界定;<br>以下是 SIGUSR1 / SIGUSR2 的具体使用场景:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 通知 nginx 关闭当前句柄, 重新打开日志文件, 用于 logrotate 切割日志</span></span><br><span class=\"line\"><span class=\"built_in\">kill</span> -USR1 `cat /var/run/nginx.pid`</span><br><span class=\"line\"><span class=\"comment\"># 通知 nginx 平滑升级 二进制可执行程序</span></span><br><span class=\"line\"><span class=\"built_in\">kill</span> -s SIGUSR2 `cat /var/run/nginx.pid`</span><br></pre></td></tr></table></figure></p>\n<p>&nbsp;<br>(2) SIGWINCH (winch 译作: 吊车, 摇柄), 默认处理是忽略该信号;<br>以下是 SIGWINCH 的具体使用场景:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 通知 nginx worker process 不再接受新 request, 并从容关闭</span></span><br><span class=\"line\"><span class=\"built_in\">kill</span> -WINCH `cat /var/run/nginx.pid`</span><br></pre></td></tr></table></figure></p>\n<p>当然, 通知 worker process 不再接受新请求, nginx 并不需要使用者直接在 linux signals 层面直接处理, nginx 本身提供了平滑重启命令 <code>sbin/nginx -c conf/nginx.conf -s reload</code>, SIGWINCH 信号的发送封装在了该命令里;<br>&nbsp;<br>关于 nginx 与 linux signals 的关系, 在本站另一篇文章中有详细介绍: <a href=\"\">nginx signals 处理</a>;</p>\n<h2 id=\"站内相关文章\"><a href=\"#站内相关文章\" class=\"headerlink\" title=\"站内相关文章\"></a><strong>站内相关文章</strong></h2><ul>\n<li><a href=\"\">kill 命令族及其选项</a></li>\n<li><a href=\"\">SIGHUP 相关全梳理</a></li>\n<li><a href=\"\">nginx signals 处理</a></li>\n</ul>\n<h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a><strong>参考链接</strong></h2><ul>\n<li><a href=\"http://www.gnu.org/software/libc/manual/html_node/Termination-Signals.html#Termination-Signals\" target=\"_blank\" rel=\"noopener\">24.2.2 Termination Signals</a></li>\n<li><a href=\"http://www.gnu.org/software/libc/manual/html_node/Job-Control-Signals.html\" target=\"_blank\" rel=\"noopener\">24.2.5 Job Control Signals</a></li>\n<li><a href=\"http://www.gnu.org/software/libc/manual/html_node/Miscellaneous-Signals.html#Miscellaneous-Signals\" target=\"_blank\" rel=\"noopener\">24.2.7 Miscellaneous Signals</a></li>\n<li><a href=\"https://stackoverflow.com/questions/27403641/difference-between-sigusr1-and-sigusr2\" target=\"_blank\" rel=\"noopener\">Difference between SIGUSR1 and SIGUSR2</a></li>\n<li><a href=\"http://blog.csdn.net/fuming0210sc/article/details/50906372\" target=\"_blank\" rel=\"noopener\">linux kill 命令 以及 USR1 信号 解释</a></li>\n<li><a href=\"http://blog.csdn.net/lisongjia123/article/details/50471854\" target=\"_blank\" rel=\"noopener\">Linux 信号入门详解</a></li>\n<li><a href=\"http://blog.csdn.net/yankai0219/article/details/8453261\" target=\"_blank\" rel=\"noopener\">文章3: Nginx中与信号有关的内容</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>linux 的信号系统其实是一个非常重要的概念, 进程间通信的常用方法之一;<br>不过长期以来, 我们对 linux 信号的直观认识, 只有 kill (SIGTERM), ctrl + c (SIGINT) 和 kill -9 等进程终止信号; 而 linux 的信号系统中存在 64 种各司其职的信号, 适用于各种各样的场景; 很多信号在实际工作中有着妙用;<br>本文正是想对 linux 世界中林林总总的 signals 作一次梳理, 总结一些日常工作中频繁使用以及不太接触但十分有用的信号;</p>\n</blockquote>","more":"<h2 id=\"linux-signals-总览\"><a href=\"#linux-signals-总览\" class=\"headerlink\" title=\"linux signals 总览\"></a><strong>linux signals 总览</strong></h2><p>linux siginal 可分为如下几大类:</p>\n<ol>\n<li>系统错误信号</li>\n<li>进程终止信号</li>\n<li>作业控制信号</li>\n<li>AIO 信号</li>\n<li>定时器信号</li>\n<li>操作错误信号</li>\n<li>其他信号</li>\n</ol>\n<p>&nbsp;<br>linux signals 的产生源一般分为三类: 硬件方式(除数为 0, 内存非法访问等), IO 方式(键盘事件), 以及软件方式: kill 命令, alarm 定时器等;<br>其中我们最熟悉的莫不过 kill 命令了, 详情请见: <a href=\"\">kill 命令族及其选项</a>;</p>\n<p>&nbsp;<br>使用 kill -l 查看所有信号分布:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; <span class=\"built_in\">kill</span> -l</span><br><span class=\"line\"> 1) SIGHUP\t     2) SIGINT\t    \t 3) SIGQUIT\t     4) SIGILL\t    \t 5) SIGTRAP</span><br><span class=\"line\"> 6) SIGABRT\t     7) SIGBUS\t    \t 8) SIGFPE\t     9) SIGKILL\t    \t10) SIGUSR1</span><br><span class=\"line\">11) SIGSEGV\t    12) SIGUSR2\t    \t13) SIGPIPE\t    14) SIGALRM\t    \t15) SIGTERM</span><br><span class=\"line\">16) SIGSTKFLT\t    17) SIGCHLD\t    \t18) SIGCONT\t    19) SIGSTOP\t    \t20) SIGTSTP</span><br><span class=\"line\">21) SIGTTIN\t    22) SIGTTOU\t    \t23) SIGURG\t    24) SIGXCPU\t    \t25) SIGXFSZ</span><br><span class=\"line\">26) SIGVTALRM\t    27) SIGPROF\t    \t28) SIGWINCH        29) SIGIO\t    \t30) SIGPWR</span><br><span class=\"line\">31) SIGSYS\t    34) SIGRTMIN    \t35) SIGRTMIN+1      36) SIGRTMIN+2  \t37) SIGRTMIN+3</span><br><span class=\"line\">38) SIGRTMIN+4\t    39) SIGRTMIN+5  \t40) SIGRTMIN+6      41) SIGRTMIN+7  \t42) SIGRTMIN+8</span><br><span class=\"line\">43) SIGRTMIN+9\t    44) SIGRTMIN+10 \t45) SIGRTMIN+11     46) SIGRTMIN+12 \t47) SIGRTMIN+13</span><br><span class=\"line\">48) SIGRTMIN+14\t    49) SIGRTMIN+15 \t50) SIGRTMAX-14     51) SIGRTMAX-13 \t52) SIGRTMAX-12</span><br><span class=\"line\">53) SIGRTMAX-11\t    54) SIGRTMAX-10 \t55) SIGRTMAX-9      56) SIGRTMAX-8  \t57) SIGRTMAX-7</span><br><span class=\"line\">58) SIGRTMAX-6\t    59) SIGRTMAX-5  \t60) SIGRTMAX-4      61) SIGRTMAX-3  \t62) SIGRTMAX-2</span><br><span class=\"line\">63) SIGRTMAX-1\t    64) SIGRTMAX</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"各类别信号整理\"><a href=\"#各类别信号整理\" class=\"headerlink\" title=\"各类别信号整理\"></a><strong>各类别信号整理</strong></h2><h3 id=\"进程终止信号\"><a href=\"#进程终止信号\" class=\"headerlink\" title=\"进程终止信号\"></a><strong>进程终止信号</strong></h3><p>进程终止信号是我们日常操作中最常用的一类信号;<br>进程终止信号共有五个, 其中除了 SIGKILL 之外, 其他信号都是 可阻塞, 可忽略, 可处理的;<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># terminate, kill 不加任何选项的默认信号, 默认处理是终止进程;</span></span><br><span class=\"line\">SIGTERM</span><br><span class=\"line\"><span class=\"comment\"># interrupt, ctrl + c 发出的信号, 默认处理是终止进程;</span></span><br><span class=\"line\">SIGINT</span><br><span class=\"line\"><span class=\"comment\"># quit, ctrl + / 发出的信号, 与 SIGINT 类似, 不过其默认处理相比 SIGINT 还增加了一项:</span></span><br><span class=\"line\"><span class=\"comment\"># 1. 终止进程; 2. 产生进程 core dump 文件;</span></span><br><span class=\"line\">SIGQUIT</span><br><span class=\"line\"><span class=\"comment\"># kill, 不可阻塞, 不可忽略, 最强力的终止信号, 通常会导致进程立即终止, 其占有的资源无法释放清理</span></span><br><span class=\"line\"><span class=\"comment\"># 一般需要在 SIGTERM/SIGINT/SIGQUIT 等信号无法响应之后, 才最后使用</span></span><br><span class=\"line\">SIGKILL</span><br><span class=\"line\"><span class=\"comment\"># hang up, 通常在用户退出终端断开 sessiion 时由系统发出该信号给 session</span></span><br><span class=\"line\"><span class=\"comment\"># session 接收该信号并将其发送给子进程</span></span><br><span class=\"line\">SIGHUP</span><br></pre></td></tr></table></figure></p>\n<p>另外一篇详细梳理与 SIGHUP 相关知识点的链接: <a href=\"\">SIGHUP 相关全梳理</a>;<br>该文章主要涉及 SIGHUP 信号发生的条件, 传导, 与 SIGHUP 相关的 nohup, &amp;,  shopt huponexit, disown 等概念, 并包括一些 SIGHUP 的自定义应用;</p>\n<h3 id=\"任务控制信号\"><a href=\"#任务控制信号\" class=\"headerlink\" title=\"任务控制信号\"></a><strong>任务控制信号</strong></h3><h3 id=\"其他信号\"><a href=\"#其他信号\" class=\"headerlink\" title=\"其他信号\"></a><strong>其他信号</strong></h3><p>其他信号是指未在上述分类中的一些小众信号, 这些信号本身并未有太多关联, 不能用一个类别去统一描述它们;<br>&nbsp;<br>(1) 用户自定义信号: SIGUSR1 / SIGUSR2<br>这两个信号, linux 保证系统自身不会向进程发送, 完全由使用者自己定义该信号的语义以及处理逻辑;<br>SIGUSR1 与 SIGUSR2, 在系统层面完全没有区别, 如果可以, linux 其实能再定义一个 SIGUSR3; 所以用户自定义信号的预留数量, 本身是一个模糊的界定;<br>以下是 SIGUSR1 / SIGUSR2 的具体使用场景:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 通知 nginx 关闭当前句柄, 重新打开日志文件, 用于 logrotate 切割日志</span></span><br><span class=\"line\"><span class=\"built_in\">kill</span> -USR1 `cat /var/run/nginx.pid`</span><br><span class=\"line\"><span class=\"comment\"># 通知 nginx 平滑升级 二进制可执行程序</span></span><br><span class=\"line\"><span class=\"built_in\">kill</span> -s SIGUSR2 `cat /var/run/nginx.pid`</span><br></pre></td></tr></table></figure></p>\n<p>&nbsp;<br>(2) SIGWINCH (winch 译作: 吊车, 摇柄), 默认处理是忽略该信号;<br>以下是 SIGWINCH 的具体使用场景:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 通知 nginx worker process 不再接受新 request, 并从容关闭</span></span><br><span class=\"line\"><span class=\"built_in\">kill</span> -WINCH `cat /var/run/nginx.pid`</span><br></pre></td></tr></table></figure></p>\n<p>当然, 通知 worker process 不再接受新请求, nginx 并不需要使用者直接在 linux signals 层面直接处理, nginx 本身提供了平滑重启命令 <code>sbin/nginx -c conf/nginx.conf -s reload</code>, SIGWINCH 信号的发送封装在了该命令里;<br>&nbsp;<br>关于 nginx 与 linux signals 的关系, 在本站另一篇文章中有详细介绍: <a href=\"\">nginx signals 处理</a>;</p>\n<h2 id=\"站内相关文章\"><a href=\"#站内相关文章\" class=\"headerlink\" title=\"站内相关文章\"></a><strong>站内相关文章</strong></h2><ul>\n<li><a href=\"\">kill 命令族及其选项</a></li>\n<li><a href=\"\">SIGHUP 相关全梳理</a></li>\n<li><a href=\"\">nginx signals 处理</a></li>\n</ul>\n<h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a><strong>参考链接</strong></h2><ul>\n<li><a href=\"http://www.gnu.org/software/libc/manual/html_node/Termination-Signals.html#Termination-Signals\" target=\"_blank\" rel=\"noopener\">24.2.2 Termination Signals</a></li>\n<li><a href=\"http://www.gnu.org/software/libc/manual/html_node/Job-Control-Signals.html\" target=\"_blank\" rel=\"noopener\">24.2.5 Job Control Signals</a></li>\n<li><a href=\"http://www.gnu.org/software/libc/manual/html_node/Miscellaneous-Signals.html#Miscellaneous-Signals\" target=\"_blank\" rel=\"noopener\">24.2.7 Miscellaneous Signals</a></li>\n<li><a href=\"https://stackoverflow.com/questions/27403641/difference-between-sigusr1-and-sigusr2\" target=\"_blank\" rel=\"noopener\">Difference between SIGUSR1 and SIGUSR2</a></li>\n<li><a href=\"http://blog.csdn.net/fuming0210sc/article/details/50906372\" target=\"_blank\" rel=\"noopener\">linux kill 命令 以及 USR1 信号 解释</a></li>\n<li><a href=\"http://blog.csdn.net/lisongjia123/article/details/50471854\" target=\"_blank\" rel=\"noopener\">Linux 信号入门详解</a></li>\n<li><a href=\"http://blog.csdn.net/yankai0219/article/details/8453261\" target=\"_blank\" rel=\"noopener\">文章3: Nginx中与信号有关的内容</a></li>\n</ul>"},{"title":"rsyncd 配置与运维","date":"2017-10-14T15:20:21.000Z","_content":"\n> 本文主要梳理 rsync server 的基本配置与使用方式;\n\n<!--more-->\n\n### **rsync server 的几个关键配置文件**\n1. /etc/rsyncd.conf: 主配置文件;\n2. /etc/rsyncd.password/rsyncd.secrets: 秘钥文件;\n3. /etc/rsyncd.motd: rysnc 服务器元信息, 非必须;\n\n其中, rsyncd.password 秘钥文件的掩码必须是 600:\n``` bash\n> ll /etc/ | grep rsyncd\n-rw-r--r--   1 root root    361 Apr  6  2017 rsyncd.conf\n-rw-------   1 root root     24 Apr  6  2017 rsyncd.password\n```\n\n### **rsyncd.conf 配置说明**\n一个典型的 rsyncd.conf 文件如下:\n``` bash\n# rsyncd 守护进程运行系统用户全局配置, 可在具体的块中配置\nuid=nobody\ngid=nobody\n\n# 是否需要 chroot, 若为 yes, 当客户端连接某模块时, 首先 chroot 到 模块的 path 目录下\nuser chroot = no\n\nmax connections = 200\ntimeout = 600\n\npid file = /data1/trans_file/rsyncd.pid\nlock file = /data1/trans_file/rsyncd.lock\nlog file = /data1/trans_file/rsyncd.log\n# 用户秘钥文件, 可在具体的模块中配置\nsecrets file = /etc/rsyncd.password\n# 服务器元信息, 非必选\n# motd file = /etc/rsyncd/rsyncd.motd\n# 指定不需要压缩就可以直接传输的文件类型\ndont compress = *.gz *.tgz *.zip *.z *.Z *.rpm *.deb *.bz2\n\n# 模块配置\n[wireless_log]\n# 模块使用的 user, 此模块将使用 rsyncd.password 文件中 sync 用户对应的秘钥进行文件传输\nauth users = sync\npath = /data1/trans_file/files/wireless_log\nignore errors\n# 是否只读\nread only = no\n# 是否允许列出模块里的内容\nlist = no\n```\n\n### **rsyncd.password / rsyncd.secrets 配置说明**\n以 `:` 分隔, 用户名和密码, 每行一个:\n```\nuser1:password1\nuser2:password2\n```\n\n### **rsyncd 启动方式**\n``` bash\n# 当负载高时, 以守护进程的方式运行 rsyncd\nsudo /usr/bin/rsync --daemon --config=/etc/rsyncd.conf\n```\n\n### **参考链接**\n- [centos下配置rsyncd服务器](https://segmentfault.com/a/1190000000444614)\n- [RSync实现文件备份同步](http://www.cnblogs.com/itech/archive/2009/08/10/1542945.html)\n\n","source":"_posts/rsync--rsyncd配置与运行.md","raw":"---\ntitle: rsyncd 配置与运维\ndate: 2017-10-14 23:20:21\ntags:\n  - rsync\ncategories:\n  - rsync\n---\n\n> 本文主要梳理 rsync server 的基本配置与使用方式;\n\n<!--more-->\n\n### **rsync server 的几个关键配置文件**\n1. /etc/rsyncd.conf: 主配置文件;\n2. /etc/rsyncd.password/rsyncd.secrets: 秘钥文件;\n3. /etc/rsyncd.motd: rysnc 服务器元信息, 非必须;\n\n其中, rsyncd.password 秘钥文件的掩码必须是 600:\n``` bash\n> ll /etc/ | grep rsyncd\n-rw-r--r--   1 root root    361 Apr  6  2017 rsyncd.conf\n-rw-------   1 root root     24 Apr  6  2017 rsyncd.password\n```\n\n### **rsyncd.conf 配置说明**\n一个典型的 rsyncd.conf 文件如下:\n``` bash\n# rsyncd 守护进程运行系统用户全局配置, 可在具体的块中配置\nuid=nobody\ngid=nobody\n\n# 是否需要 chroot, 若为 yes, 当客户端连接某模块时, 首先 chroot 到 模块的 path 目录下\nuser chroot = no\n\nmax connections = 200\ntimeout = 600\n\npid file = /data1/trans_file/rsyncd.pid\nlock file = /data1/trans_file/rsyncd.lock\nlog file = /data1/trans_file/rsyncd.log\n# 用户秘钥文件, 可在具体的模块中配置\nsecrets file = /etc/rsyncd.password\n# 服务器元信息, 非必选\n# motd file = /etc/rsyncd/rsyncd.motd\n# 指定不需要压缩就可以直接传输的文件类型\ndont compress = *.gz *.tgz *.zip *.z *.Z *.rpm *.deb *.bz2\n\n# 模块配置\n[wireless_log]\n# 模块使用的 user, 此模块将使用 rsyncd.password 文件中 sync 用户对应的秘钥进行文件传输\nauth users = sync\npath = /data1/trans_file/files/wireless_log\nignore errors\n# 是否只读\nread only = no\n# 是否允许列出模块里的内容\nlist = no\n```\n\n### **rsyncd.password / rsyncd.secrets 配置说明**\n以 `:` 分隔, 用户名和密码, 每行一个:\n```\nuser1:password1\nuser2:password2\n```\n\n### **rsyncd 启动方式**\n``` bash\n# 当负载高时, 以守护进程的方式运行 rsyncd\nsudo /usr/bin/rsync --daemon --config=/etc/rsyncd.conf\n```\n\n### **参考链接**\n- [centos下配置rsyncd服务器](https://segmentfault.com/a/1190000000444614)\n- [RSync实现文件备份同步](http://www.cnblogs.com/itech/archive/2009/08/10/1542945.html)\n\n","slug":"rsync--rsyncd配置与运行","published":1,"updated":"2018-01-27T14:53:07.577Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cje24mxu5000jj1jxeuengj70","content":"<blockquote>\n<p>本文主要梳理 rsync server 的基本配置与使用方式;</p>\n</blockquote>\n<a id=\"more\"></a>\n<h3 id=\"rsync-server-的几个关键配置文件\"><a href=\"#rsync-server-的几个关键配置文件\" class=\"headerlink\" title=\"rsync server 的几个关键配置文件\"></a><strong>rsync server 的几个关键配置文件</strong></h3><ol>\n<li>/etc/rsyncd.conf: 主配置文件;</li>\n<li>/etc/rsyncd.password/rsyncd.secrets: 秘钥文件;</li>\n<li>/etc/rsyncd.motd: rysnc 服务器元信息, 非必须;</li>\n</ol>\n<p>其中, rsyncd.password 秘钥文件的掩码必须是 600:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; ll /etc/ | grep rsyncd</span><br><span class=\"line\">-rw-r--r--   1 root root    361 Apr  6  2017 rsyncd.conf</span><br><span class=\"line\">-rw-------   1 root root     24 Apr  6  2017 rsyncd.password</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"rsyncd-conf-配置说明\"><a href=\"#rsyncd-conf-配置说明\" class=\"headerlink\" title=\"rsyncd.conf 配置说明\"></a><strong>rsyncd.conf 配置说明</strong></h3><p>一个典型的 rsyncd.conf 文件如下:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># rsyncd 守护进程运行系统用户全局配置, 可在具体的块中配置</span></span><br><span class=\"line\">uid=nobody</span><br><span class=\"line\">gid=nobody</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 是否需要 chroot, 若为 yes, 当客户端连接某模块时, 首先 chroot 到 模块的 path 目录下</span></span><br><span class=\"line\">user chroot = no</span><br><span class=\"line\"></span><br><span class=\"line\">max connections = 200</span><br><span class=\"line\">timeout = 600</span><br><span class=\"line\"></span><br><span class=\"line\">pid file = /data1/trans_file/rsyncd.pid</span><br><span class=\"line\">lock file = /data1/trans_file/rsyncd.lock</span><br><span class=\"line\"><span class=\"built_in\">log</span> file = /data1/trans_file/rsyncd.log</span><br><span class=\"line\"><span class=\"comment\"># 用户秘钥文件, 可在具体的模块中配置</span></span><br><span class=\"line\">secrets file = /etc/rsyncd.password</span><br><span class=\"line\"><span class=\"comment\"># 服务器元信息, 非必选</span></span><br><span class=\"line\"><span class=\"comment\"># motd file = /etc/rsyncd/rsyncd.motd</span></span><br><span class=\"line\"><span class=\"comment\"># 指定不需要压缩就可以直接传输的文件类型</span></span><br><span class=\"line\">dont compress = *.gz *.tgz *.zip *.z *.Z *.rpm *.deb *.bz2</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 模块配置</span></span><br><span class=\"line\">[wireless_log]</span><br><span class=\"line\"><span class=\"comment\"># 模块使用的 user, 此模块将使用 rsyncd.password 文件中 sync 用户对应的秘钥进行文件传输</span></span><br><span class=\"line\">auth users = sync</span><br><span class=\"line\">path = /data1/trans_file/files/wireless_log</span><br><span class=\"line\">ignore errors</span><br><span class=\"line\"><span class=\"comment\"># 是否只读</span></span><br><span class=\"line\"><span class=\"built_in\">read</span> only = no</span><br><span class=\"line\"><span class=\"comment\"># 是否允许列出模块里的内容</span></span><br><span class=\"line\">list = no</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"rsyncd-password-rsyncd-secrets-配置说明\"><a href=\"#rsyncd-password-rsyncd-secrets-配置说明\" class=\"headerlink\" title=\"rsyncd.password / rsyncd.secrets 配置说明\"></a><strong>rsyncd.password / rsyncd.secrets 配置说明</strong></h3><p>以 <code>:</code> 分隔, 用户名和密码, 每行一个:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">user1:password1</span><br><span class=\"line\">user2:password2</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"rsyncd-启动方式\"><a href=\"#rsyncd-启动方式\" class=\"headerlink\" title=\"rsyncd 启动方式\"></a><strong>rsyncd 启动方式</strong></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 当负载高时, 以守护进程的方式运行 rsyncd</span></span><br><span class=\"line\">sudo /usr/bin/rsync --daemon --config=/etc/rsyncd.conf</span><br></pre></td></tr></table></figure>\n<h3 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a><strong>参考链接</strong></h3><ul>\n<li><a href=\"https://segmentfault.com/a/1190000000444614\" target=\"_blank\" rel=\"noopener\">centos下配置rsyncd服务器</a></li>\n<li><a href=\"http://www.cnblogs.com/itech/archive/2009/08/10/1542945.html\" target=\"_blank\" rel=\"noopener\">RSync实现文件备份同步</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>本文主要梳理 rsync server 的基本配置与使用方式;</p>\n</blockquote>","more":"<h3 id=\"rsync-server-的几个关键配置文件\"><a href=\"#rsync-server-的几个关键配置文件\" class=\"headerlink\" title=\"rsync server 的几个关键配置文件\"></a><strong>rsync server 的几个关键配置文件</strong></h3><ol>\n<li>/etc/rsyncd.conf: 主配置文件;</li>\n<li>/etc/rsyncd.password/rsyncd.secrets: 秘钥文件;</li>\n<li>/etc/rsyncd.motd: rysnc 服务器元信息, 非必须;</li>\n</ol>\n<p>其中, rsyncd.password 秘钥文件的掩码必须是 600:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; ll /etc/ | grep rsyncd</span><br><span class=\"line\">-rw-r--r--   1 root root    361 Apr  6  2017 rsyncd.conf</span><br><span class=\"line\">-rw-------   1 root root     24 Apr  6  2017 rsyncd.password</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"rsyncd-conf-配置说明\"><a href=\"#rsyncd-conf-配置说明\" class=\"headerlink\" title=\"rsyncd.conf 配置说明\"></a><strong>rsyncd.conf 配置说明</strong></h3><p>一个典型的 rsyncd.conf 文件如下:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># rsyncd 守护进程运行系统用户全局配置, 可在具体的块中配置</span></span><br><span class=\"line\">uid=nobody</span><br><span class=\"line\">gid=nobody</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 是否需要 chroot, 若为 yes, 当客户端连接某模块时, 首先 chroot 到 模块的 path 目录下</span></span><br><span class=\"line\">user chroot = no</span><br><span class=\"line\"></span><br><span class=\"line\">max connections = 200</span><br><span class=\"line\">timeout = 600</span><br><span class=\"line\"></span><br><span class=\"line\">pid file = /data1/trans_file/rsyncd.pid</span><br><span class=\"line\">lock file = /data1/trans_file/rsyncd.lock</span><br><span class=\"line\"><span class=\"built_in\">log</span> file = /data1/trans_file/rsyncd.log</span><br><span class=\"line\"><span class=\"comment\"># 用户秘钥文件, 可在具体的模块中配置</span></span><br><span class=\"line\">secrets file = /etc/rsyncd.password</span><br><span class=\"line\"><span class=\"comment\"># 服务器元信息, 非必选</span></span><br><span class=\"line\"><span class=\"comment\"># motd file = /etc/rsyncd/rsyncd.motd</span></span><br><span class=\"line\"><span class=\"comment\"># 指定不需要压缩就可以直接传输的文件类型</span></span><br><span class=\"line\">dont compress = *.gz *.tgz *.zip *.z *.Z *.rpm *.deb *.bz2</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 模块配置</span></span><br><span class=\"line\">[wireless_log]</span><br><span class=\"line\"><span class=\"comment\"># 模块使用的 user, 此模块将使用 rsyncd.password 文件中 sync 用户对应的秘钥进行文件传输</span></span><br><span class=\"line\">auth users = sync</span><br><span class=\"line\">path = /data1/trans_file/files/wireless_log</span><br><span class=\"line\">ignore errors</span><br><span class=\"line\"><span class=\"comment\"># 是否只读</span></span><br><span class=\"line\"><span class=\"built_in\">read</span> only = no</span><br><span class=\"line\"><span class=\"comment\"># 是否允许列出模块里的内容</span></span><br><span class=\"line\">list = no</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"rsyncd-password-rsyncd-secrets-配置说明\"><a href=\"#rsyncd-password-rsyncd-secrets-配置说明\" class=\"headerlink\" title=\"rsyncd.password / rsyncd.secrets 配置说明\"></a><strong>rsyncd.password / rsyncd.secrets 配置说明</strong></h3><p>以 <code>:</code> 分隔, 用户名和密码, 每行一个:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">user1:password1</span><br><span class=\"line\">user2:password2</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"rsyncd-启动方式\"><a href=\"#rsyncd-启动方式\" class=\"headerlink\" title=\"rsyncd 启动方式\"></a><strong>rsyncd 启动方式</strong></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 当负载高时, 以守护进程的方式运行 rsyncd</span></span><br><span class=\"line\">sudo /usr/bin/rsync --daemon --config=/etc/rsyncd.conf</span><br></pre></td></tr></table></figure>\n<h3 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a><strong>参考链接</strong></h3><ul>\n<li><a href=\"https://segmentfault.com/a/1190000000444614\" target=\"_blank\" rel=\"noopener\">centos下配置rsyncd服务器</a></li>\n<li><a href=\"http://www.cnblogs.com/itech/archive/2009/08/10/1542945.html\" target=\"_blank\" rel=\"noopener\">RSync实现文件备份同步</a></li>\n</ul>"},{"title":"saltstack cheat sheet","date":"2017-05-13T13:42:21.000Z","_content":"\n> 本文主要整理日常 saltstack 使用时的最常用的一些命令,以供快速查阅;\n\n<!--more-->\n\n------\n\n### **自由度最大的模块: cmd 模块**\n适用于登录 salt master 机器, 人工操作时执行;\n``` bash\n# cmd.run: 在 minions 上执行任意命令\nsudo salt * cmd.run \"ls -l /etc/localtime\"\nsudo salt * cmd.run uptime\n\n# cmd.script: 在 master 上下发任意脚本至 minions 执行\nsudo salt * cmd.script salt://minion_exeute.sh \"args1 args2\"\n```\n\n### **控制 minions 的定时任务执行情况: cron 模块**\n``` bash\n# 查看指定用户的 cron 内容\nsudo salt * cron.raw_cron root\n# 为指定用户添加指定任务\nsudo salt * cron.set_job root '*' '*' '*' '*' '*' /home/minion_execute.sh 1>/dev/null\n# 为指定用户删除指定任务\nsudo salt * cron.rm_job root '*' '*' '*' '*' '*' /home/minion_execute.sh 1>/dev/null\n```\n\n### **master 与 minions 的文件传输: cp 模块**\n``` bash\n# 推送文件到 minions 指定路径 (只能推送文件, 不能推送目录)\nsudo salt * cp.get_file salt://target_file /minion_path\n# 推送目录到 minions 指定路径\nsuod salt * cp.get_dir salt://target_dir /minion_path\n# 下载指定 url 的内容到 minions 指定路径 (不限于本地路径, 更加广泛)\nsudo salt * cp.get_url salt://target_file /minion_path\nsudo salt * cp.get_url https://d3kbcqa49mib13.cloudfront.net/spark-2.2.0-bin-hadoop2.7.tgz /minion_path\n```\n\n### **服务启停控制: systemd 模块**\nsalt.modules.systemd 模块是以 systemd 与 systemctl 为基础的, 尽管其命令多以 serice 开头, 不过该模块和 sysvinit 的 service 命令应该没什么关系;\n``` bash\n# 分别对应了 systemctl [enable, disable, start, stop, status, restart] httpd.service\nsudo salt * service.enable httpd\nsudo salt * service.disable httpd\n\nsudo salt * service.start httpd\nsudo salt * service.stop httpd\nsudo salt * service.status httpd\nsudo salt * service.restart httpd\n```\n\n### **远程文件控制相关: file 模块**\n``` bash\n# 创建文件\nsudo salt * file.touch /opt/rsync_passwd\n# 创建目录\nsudo salt * file.mkdir /opt/rsync\n# 删除指定文件\nsudo salt * file.remove /opt/rsync_passwd\n# 删除目录\nsudo salt * file.rmdir /opt/rsync\n\n# sudo chown root:root /opt/rsync_passwd\nsudo salt * file.chown /opt/rsync_passwd root root\n# sudo chmod 600 /etc/rsync_passwd\nsudo salt * file.set_mode /etc/rsync_passwd 600\n```\n\n### **salt 常用的状态检测**\n包括:\nmaster 与 minions 之间的连通性 check_ping 检查;\nminions salt version, dependency version, system version 检查;\nminions network ping 外网检查;\n磁盘容量 check_disk 检查;\n等等;\n``` bash\n# 测试 salt 主从连通性\nsudo salt * test.ping\n# 打印 salt 的版本以及 salt 依赖的第三方组件的版本\nsudo salt * test.versions_report\n# 测试 minions 的网络 ping\nsudo salt * network.ping www.qunar.com\n# 查看 minions 的磁盘使用情况\nsudo salt * disk.usage\n```\n\n### **参考链接**\n- [服务自动化部署平台之Saltstack总结](http://blog.csdn.net/shjh369/article/details/49799269)\n- [Saltstack系列3: Saltstack常用模块及API](https://www.cnblogs.com/MacoLee/p/5753640.html)\n- [SALT.MODULES.FILE](https://docs.saltstack.com/en/latest/ref/modules/all/salt.modules.file.html#salt.modules.file.rmdir)\n\n","source":"_posts/saltstack--saltstack_cheat_sheet.md","raw":"---\ntitle: saltstack cheat sheet\ndate: 2017-05-13 21:42:21\ncategories:\n - saltstack\ntags:\n - saltstack\n - cheat sheet\n - 运维自动化\n---\n\n> 本文主要整理日常 saltstack 使用时的最常用的一些命令,以供快速查阅;\n\n<!--more-->\n\n------\n\n### **自由度最大的模块: cmd 模块**\n适用于登录 salt master 机器, 人工操作时执行;\n``` bash\n# cmd.run: 在 minions 上执行任意命令\nsudo salt * cmd.run \"ls -l /etc/localtime\"\nsudo salt * cmd.run uptime\n\n# cmd.script: 在 master 上下发任意脚本至 minions 执行\nsudo salt * cmd.script salt://minion_exeute.sh \"args1 args2\"\n```\n\n### **控制 minions 的定时任务执行情况: cron 模块**\n``` bash\n# 查看指定用户的 cron 内容\nsudo salt * cron.raw_cron root\n# 为指定用户添加指定任务\nsudo salt * cron.set_job root '*' '*' '*' '*' '*' /home/minion_execute.sh 1>/dev/null\n# 为指定用户删除指定任务\nsudo salt * cron.rm_job root '*' '*' '*' '*' '*' /home/minion_execute.sh 1>/dev/null\n```\n\n### **master 与 minions 的文件传输: cp 模块**\n``` bash\n# 推送文件到 minions 指定路径 (只能推送文件, 不能推送目录)\nsudo salt * cp.get_file salt://target_file /minion_path\n# 推送目录到 minions 指定路径\nsuod salt * cp.get_dir salt://target_dir /minion_path\n# 下载指定 url 的内容到 minions 指定路径 (不限于本地路径, 更加广泛)\nsudo salt * cp.get_url salt://target_file /minion_path\nsudo salt * cp.get_url https://d3kbcqa49mib13.cloudfront.net/spark-2.2.0-bin-hadoop2.7.tgz /minion_path\n```\n\n### **服务启停控制: systemd 模块**\nsalt.modules.systemd 模块是以 systemd 与 systemctl 为基础的, 尽管其命令多以 serice 开头, 不过该模块和 sysvinit 的 service 命令应该没什么关系;\n``` bash\n# 分别对应了 systemctl [enable, disable, start, stop, status, restart] httpd.service\nsudo salt * service.enable httpd\nsudo salt * service.disable httpd\n\nsudo salt * service.start httpd\nsudo salt * service.stop httpd\nsudo salt * service.status httpd\nsudo salt * service.restart httpd\n```\n\n### **远程文件控制相关: file 模块**\n``` bash\n# 创建文件\nsudo salt * file.touch /opt/rsync_passwd\n# 创建目录\nsudo salt * file.mkdir /opt/rsync\n# 删除指定文件\nsudo salt * file.remove /opt/rsync_passwd\n# 删除目录\nsudo salt * file.rmdir /opt/rsync\n\n# sudo chown root:root /opt/rsync_passwd\nsudo salt * file.chown /opt/rsync_passwd root root\n# sudo chmod 600 /etc/rsync_passwd\nsudo salt * file.set_mode /etc/rsync_passwd 600\n```\n\n### **salt 常用的状态检测**\n包括:\nmaster 与 minions 之间的连通性 check_ping 检查;\nminions salt version, dependency version, system version 检查;\nminions network ping 外网检查;\n磁盘容量 check_disk 检查;\n等等;\n``` bash\n# 测试 salt 主从连通性\nsudo salt * test.ping\n# 打印 salt 的版本以及 salt 依赖的第三方组件的版本\nsudo salt * test.versions_report\n# 测试 minions 的网络 ping\nsudo salt * network.ping www.qunar.com\n# 查看 minions 的磁盘使用情况\nsudo salt * disk.usage\n```\n\n### **参考链接**\n- [服务自动化部署平台之Saltstack总结](http://blog.csdn.net/shjh369/article/details/49799269)\n- [Saltstack系列3: Saltstack常用模块及API](https://www.cnblogs.com/MacoLee/p/5753640.html)\n- [SALT.MODULES.FILE](https://docs.saltstack.com/en/latest/ref/modules/all/salt.modules.file.html#salt.modules.file.rmdir)\n\n","slug":"saltstack--saltstack_cheat_sheet","published":1,"updated":"2018-01-27T14:53:07.577Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cje24mxu7000lj1jxynelkfy4","content":"<blockquote>\n<p>本文主要整理日常 saltstack 使用时的最常用的一些命令,以供快速查阅;</p>\n</blockquote>\n<a id=\"more\"></a>\n<hr>\n<h3 id=\"自由度最大的模块-cmd-模块\"><a href=\"#自由度最大的模块-cmd-模块\" class=\"headerlink\" title=\"自由度最大的模块: cmd 模块\"></a><strong>自由度最大的模块: cmd 模块</strong></h3><p>适用于登录 salt master 机器, 人工操作时执行;<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># cmd.run: 在 minions 上执行任意命令</span></span><br><span class=\"line\">sudo salt * cmd.run <span class=\"string\">\"ls -l /etc/localtime\"</span></span><br><span class=\"line\">sudo salt * cmd.run uptime</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># cmd.script: 在 master 上下发任意脚本至 minions 执行</span></span><br><span class=\"line\">sudo salt * cmd.script salt://minion_exeute.sh <span class=\"string\">\"args1 args2\"</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"控制-minions-的定时任务执行情况-cron-模块\"><a href=\"#控制-minions-的定时任务执行情况-cron-模块\" class=\"headerlink\" title=\"控制 minions 的定时任务执行情况: cron 模块\"></a><strong>控制 minions 的定时任务执行情况: cron 模块</strong></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 查看指定用户的 cron 内容</span></span><br><span class=\"line\">sudo salt * cron.raw_cron root</span><br><span class=\"line\"><span class=\"comment\"># 为指定用户添加指定任务</span></span><br><span class=\"line\">sudo salt * cron.set_job root <span class=\"string\">'*'</span> <span class=\"string\">'*'</span> <span class=\"string\">'*'</span> <span class=\"string\">'*'</span> <span class=\"string\">'*'</span> /home/minion_execute.sh 1&gt;/dev/null</span><br><span class=\"line\"><span class=\"comment\"># 为指定用户删除指定任务</span></span><br><span class=\"line\">sudo salt * cron.rm_job root <span class=\"string\">'*'</span> <span class=\"string\">'*'</span> <span class=\"string\">'*'</span> <span class=\"string\">'*'</span> <span class=\"string\">'*'</span> /home/minion_execute.sh 1&gt;/dev/null</span><br></pre></td></tr></table></figure>\n<h3 id=\"master-与-minions-的文件传输-cp-模块\"><a href=\"#master-与-minions-的文件传输-cp-模块\" class=\"headerlink\" title=\"master 与 minions 的文件传输: cp 模块\"></a><strong>master 与 minions 的文件传输: cp 模块</strong></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 推送文件到 minions 指定路径 (只能推送文件, 不能推送目录)</span></span><br><span class=\"line\">sudo salt * cp.get_file salt://target_file /minion_path</span><br><span class=\"line\"><span class=\"comment\"># 推送目录到 minions 指定路径</span></span><br><span class=\"line\">suod salt * cp.get_dir salt://target_dir /minion_path</span><br><span class=\"line\"><span class=\"comment\"># 下载指定 url 的内容到 minions 指定路径 (不限于本地路径, 更加广泛)</span></span><br><span class=\"line\">sudo salt * cp.get_url salt://target_file /minion_path</span><br><span class=\"line\">sudo salt * cp.get_url https://d3kbcqa49mib13.cloudfront.net/spark-2.2.0-bin-hadoop2.7.tgz /minion_path</span><br></pre></td></tr></table></figure>\n<h3 id=\"服务启停控制-systemd-模块\"><a href=\"#服务启停控制-systemd-模块\" class=\"headerlink\" title=\"服务启停控制: systemd 模块\"></a><strong>服务启停控制: systemd 模块</strong></h3><p>salt.modules.systemd 模块是以 systemd 与 systemctl 为基础的, 尽管其命令多以 serice 开头, 不过该模块和 sysvinit 的 service 命令应该没什么关系;<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 分别对应了 systemctl [enable, disable, start, stop, status, restart] httpd.service</span></span><br><span class=\"line\">sudo salt * service.enable httpd</span><br><span class=\"line\">sudo salt * service.disable httpd</span><br><span class=\"line\"></span><br><span class=\"line\">sudo salt * service.start httpd</span><br><span class=\"line\">sudo salt * service.stop httpd</span><br><span class=\"line\">sudo salt * service.status httpd</span><br><span class=\"line\">sudo salt * service.restart httpd</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"远程文件控制相关-file-模块\"><a href=\"#远程文件控制相关-file-模块\" class=\"headerlink\" title=\"远程文件控制相关: file 模块\"></a><strong>远程文件控制相关: file 模块</strong></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 创建文件</span></span><br><span class=\"line\">sudo salt * file.touch /opt/rsync_passwd</span><br><span class=\"line\"><span class=\"comment\"># 创建目录</span></span><br><span class=\"line\">sudo salt * file.mkdir /opt/rsync</span><br><span class=\"line\"><span class=\"comment\"># 删除指定文件</span></span><br><span class=\"line\">sudo salt * file.remove /opt/rsync_passwd</span><br><span class=\"line\"><span class=\"comment\"># 删除目录</span></span><br><span class=\"line\">sudo salt * file.rmdir /opt/rsync</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># sudo chown root:root /opt/rsync_passwd</span></span><br><span class=\"line\">sudo salt * file.chown /opt/rsync_passwd root root</span><br><span class=\"line\"><span class=\"comment\"># sudo chmod 600 /etc/rsync_passwd</span></span><br><span class=\"line\">sudo salt * file.set_mode /etc/rsync_passwd 600</span><br></pre></td></tr></table></figure>\n<h3 id=\"salt-常用的状态检测\"><a href=\"#salt-常用的状态检测\" class=\"headerlink\" title=\"salt 常用的状态检测\"></a><strong>salt 常用的状态检测</strong></h3><p>包括:<br>master 与 minions 之间的连通性 check_ping 检查;<br>minions salt version, dependency version, system version 检查;<br>minions network ping 外网检查;<br>磁盘容量 check_disk 检查;<br>等等;<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 测试 salt 主从连通性</span></span><br><span class=\"line\">sudo salt * test.ping</span><br><span class=\"line\"><span class=\"comment\"># 打印 salt 的版本以及 salt 依赖的第三方组件的版本</span></span><br><span class=\"line\">sudo salt * test.versions_report</span><br><span class=\"line\"><span class=\"comment\"># 测试 minions 的网络 ping</span></span><br><span class=\"line\">sudo salt * network.ping www.qunar.com</span><br><span class=\"line\"><span class=\"comment\"># 查看 minions 的磁盘使用情况</span></span><br><span class=\"line\">sudo salt * disk.usage</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a><strong>参考链接</strong></h3><ul>\n<li><a href=\"http://blog.csdn.net/shjh369/article/details/49799269\" target=\"_blank\" rel=\"noopener\">服务自动化部署平台之Saltstack总结</a></li>\n<li><a href=\"https://www.cnblogs.com/MacoLee/p/5753640.html\" target=\"_blank\" rel=\"noopener\">Saltstack系列3: Saltstack常用模块及API</a></li>\n<li><a href=\"https://docs.saltstack.com/en/latest/ref/modules/all/salt.modules.file.html#salt.modules.file.rmdir\" target=\"_blank\" rel=\"noopener\">SALT.MODULES.FILE</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>本文主要整理日常 saltstack 使用时的最常用的一些命令,以供快速查阅;</p>\n</blockquote>","more":"<hr>\n<h3 id=\"自由度最大的模块-cmd-模块\"><a href=\"#自由度最大的模块-cmd-模块\" class=\"headerlink\" title=\"自由度最大的模块: cmd 模块\"></a><strong>自由度最大的模块: cmd 模块</strong></h3><p>适用于登录 salt master 机器, 人工操作时执行;<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># cmd.run: 在 minions 上执行任意命令</span></span><br><span class=\"line\">sudo salt * cmd.run <span class=\"string\">\"ls -l /etc/localtime\"</span></span><br><span class=\"line\">sudo salt * cmd.run uptime</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># cmd.script: 在 master 上下发任意脚本至 minions 执行</span></span><br><span class=\"line\">sudo salt * cmd.script salt://minion_exeute.sh <span class=\"string\">\"args1 args2\"</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"控制-minions-的定时任务执行情况-cron-模块\"><a href=\"#控制-minions-的定时任务执行情况-cron-模块\" class=\"headerlink\" title=\"控制 minions 的定时任务执行情况: cron 模块\"></a><strong>控制 minions 的定时任务执行情况: cron 模块</strong></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 查看指定用户的 cron 内容</span></span><br><span class=\"line\">sudo salt * cron.raw_cron root</span><br><span class=\"line\"><span class=\"comment\"># 为指定用户添加指定任务</span></span><br><span class=\"line\">sudo salt * cron.set_job root <span class=\"string\">'*'</span> <span class=\"string\">'*'</span> <span class=\"string\">'*'</span> <span class=\"string\">'*'</span> <span class=\"string\">'*'</span> /home/minion_execute.sh 1&gt;/dev/null</span><br><span class=\"line\"><span class=\"comment\"># 为指定用户删除指定任务</span></span><br><span class=\"line\">sudo salt * cron.rm_job root <span class=\"string\">'*'</span> <span class=\"string\">'*'</span> <span class=\"string\">'*'</span> <span class=\"string\">'*'</span> <span class=\"string\">'*'</span> /home/minion_execute.sh 1&gt;/dev/null</span><br></pre></td></tr></table></figure>\n<h3 id=\"master-与-minions-的文件传输-cp-模块\"><a href=\"#master-与-minions-的文件传输-cp-模块\" class=\"headerlink\" title=\"master 与 minions 的文件传输: cp 模块\"></a><strong>master 与 minions 的文件传输: cp 模块</strong></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 推送文件到 minions 指定路径 (只能推送文件, 不能推送目录)</span></span><br><span class=\"line\">sudo salt * cp.get_file salt://target_file /minion_path</span><br><span class=\"line\"><span class=\"comment\"># 推送目录到 minions 指定路径</span></span><br><span class=\"line\">suod salt * cp.get_dir salt://target_dir /minion_path</span><br><span class=\"line\"><span class=\"comment\"># 下载指定 url 的内容到 minions 指定路径 (不限于本地路径, 更加广泛)</span></span><br><span class=\"line\">sudo salt * cp.get_url salt://target_file /minion_path</span><br><span class=\"line\">sudo salt * cp.get_url https://d3kbcqa49mib13.cloudfront.net/spark-2.2.0-bin-hadoop2.7.tgz /minion_path</span><br></pre></td></tr></table></figure>\n<h3 id=\"服务启停控制-systemd-模块\"><a href=\"#服务启停控制-systemd-模块\" class=\"headerlink\" title=\"服务启停控制: systemd 模块\"></a><strong>服务启停控制: systemd 模块</strong></h3><p>salt.modules.systemd 模块是以 systemd 与 systemctl 为基础的, 尽管其命令多以 serice 开头, 不过该模块和 sysvinit 的 service 命令应该没什么关系;<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 分别对应了 systemctl [enable, disable, start, stop, status, restart] httpd.service</span></span><br><span class=\"line\">sudo salt * service.enable httpd</span><br><span class=\"line\">sudo salt * service.disable httpd</span><br><span class=\"line\"></span><br><span class=\"line\">sudo salt * service.start httpd</span><br><span class=\"line\">sudo salt * service.stop httpd</span><br><span class=\"line\">sudo salt * service.status httpd</span><br><span class=\"line\">sudo salt * service.restart httpd</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"远程文件控制相关-file-模块\"><a href=\"#远程文件控制相关-file-模块\" class=\"headerlink\" title=\"远程文件控制相关: file 模块\"></a><strong>远程文件控制相关: file 模块</strong></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 创建文件</span></span><br><span class=\"line\">sudo salt * file.touch /opt/rsync_passwd</span><br><span class=\"line\"><span class=\"comment\"># 创建目录</span></span><br><span class=\"line\">sudo salt * file.mkdir /opt/rsync</span><br><span class=\"line\"><span class=\"comment\"># 删除指定文件</span></span><br><span class=\"line\">sudo salt * file.remove /opt/rsync_passwd</span><br><span class=\"line\"><span class=\"comment\"># 删除目录</span></span><br><span class=\"line\">sudo salt * file.rmdir /opt/rsync</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># sudo chown root:root /opt/rsync_passwd</span></span><br><span class=\"line\">sudo salt * file.chown /opt/rsync_passwd root root</span><br><span class=\"line\"><span class=\"comment\"># sudo chmod 600 /etc/rsync_passwd</span></span><br><span class=\"line\">sudo salt * file.set_mode /etc/rsync_passwd 600</span><br></pre></td></tr></table></figure>\n<h3 id=\"salt-常用的状态检测\"><a href=\"#salt-常用的状态检测\" class=\"headerlink\" title=\"salt 常用的状态检测\"></a><strong>salt 常用的状态检测</strong></h3><p>包括:<br>master 与 minions 之间的连通性 check_ping 检查;<br>minions salt version, dependency version, system version 检查;<br>minions network ping 外网检查;<br>磁盘容量 check_disk 检查;<br>等等;<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 测试 salt 主从连通性</span></span><br><span class=\"line\">sudo salt * test.ping</span><br><span class=\"line\"><span class=\"comment\"># 打印 salt 的版本以及 salt 依赖的第三方组件的版本</span></span><br><span class=\"line\">sudo salt * test.versions_report</span><br><span class=\"line\"><span class=\"comment\"># 测试 minions 的网络 ping</span></span><br><span class=\"line\">sudo salt * network.ping www.qunar.com</span><br><span class=\"line\"><span class=\"comment\"># 查看 minions 的磁盘使用情况</span></span><br><span class=\"line\">sudo salt * disk.usage</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a><strong>参考链接</strong></h3><ul>\n<li><a href=\"http://blog.csdn.net/shjh369/article/details/49799269\" target=\"_blank\" rel=\"noopener\">服务自动化部署平台之Saltstack总结</a></li>\n<li><a href=\"https://www.cnblogs.com/MacoLee/p/5753640.html\" target=\"_blank\" rel=\"noopener\">Saltstack系列3: Saltstack常用模块及API</a></li>\n<li><a href=\"https://docs.saltstack.com/en/latest/ref/modules/all/salt.modules.file.html#salt.modules.file.rmdir\" target=\"_blank\" rel=\"noopener\">SALT.MODULES.FILE</a></li>\n</ul>"},{"title":"sed 命令整理","date":"2016-11-04T14:56:47.000Z","_content":"\n> stream editor: 流式文本编辑器;\nsed 命令的侧重点在于对文本的编辑;\n\n<!--more-->\n\n### **sed 的基本模式**\n``` bash\n# 标准模式: 选项, 目标行范围, 命令\nsed  [-nefri] '[target line]command' $file_path\n# 正则模式: 选项, 正则匹配式, 命令\nsed  [-nefri] '/regex/command' $file_path\n# 混合模式: 选项, 目标行与正则式组合范围, 命令\nsed [-nefri] 'line,/regex/command' $file_path\n```\n### **sed 的常用选项**\n``` bash\n1. -n:  silent 静默模式, 只输出被 sed 处理过的行;\n2. -e:  --expression, 指定命令, 可以使用多个 -e 执行多个命令:\n        sed -e '$d' -e '/regex/p' $file_path\n3. -f:  执行给定文件里的命令;\n4. -r:  --regexp-extended, 使 sed 支持拓展的正则表达式语法, 拓展的正则表达式较常规的正则表达式增加支持了如下语法:\n        +, ?, |, ()\n        由于这些拓展语法也非常常见, 所以推荐若使用 sed 的 regex 功能时带上 -r 选项;\n5. -i:  直接在指定的文件里修改编辑, stdout 不输出任何内容;\n```\n### **sed 的 command**\n``` bash\n1. i:   insert 到 目标行的上一行\n2. a:   append 到 目标行的下一行 \n3. c:   replace, 不能使用正则表达式\n4. s:   replace, 使用正则表达式, 一般需要与 -r 配合使用, 模式为:\n        s/regex/new_str/g, 替换文件中所有的 regex;\n        s/regex/new_str, 只替换每行第一个被匹配上的 regex;\n        s/regex/new_str/p, 如果某行被匹配上了就打印出来, 常与 -n 选项一同使用;\n5. d:   delete\n6. p:   print, 一般需要与 -n 选项一同使用, 否则看不出打印效果\n7. y:   按每个字符映射, 模式案例: y/1234567890/ABCDEFGHIJ/\n```\n### **典型示例**\n``` bash\n# 打印最后一行\nsed -n '$p' $file_path\n# 指定两种操作, 删除9到最后一行, 以及向1到3行后追加 'append' 字符串\nsed -i -e '9,$d' -e '1,3a append' $file_path\n# 正则表达式替换(替换全部 regex)\nsed -ri 's/^(test|ping)[a-z]+.$/kill/g' $file_path\n# 打印从第9行开始到以 test 结尾的行之间的每一行\nsed -n '9,/test$/p' $file_path\n```\n``` bash\n# 结合变量, 往最后一行添加一行内容\n# 需使用\"\", 同时表示最后一行的 $ 需要转义\ncron_str='5 * * * *  sh /home/q/tools/bin/log_collect.sh 1>/dev/null'\nsed \"\\$a ${cron_str}\" /var/spool/cron/root\n```\n\n### **参考链接**\n- [linux之sed用法](http://www.cnblogs.com/dong008259/archive/2011/12/07/2279897.html)\n- [linux sed命令详解](http://www.iteye.com/topic/587673)\n\n","source":"_posts/linux-text-sed命令整理.md","raw":"---\ntitle: sed 命令整理\ndate: 2016-11-04 22:56:47\ncategories:\n  - linux\n  - text\ntags:\n  - linux:text\n---\n\n> stream editor: 流式文本编辑器;\nsed 命令的侧重点在于对文本的编辑;\n\n<!--more-->\n\n### **sed 的基本模式**\n``` bash\n# 标准模式: 选项, 目标行范围, 命令\nsed  [-nefri] '[target line]command' $file_path\n# 正则模式: 选项, 正则匹配式, 命令\nsed  [-nefri] '/regex/command' $file_path\n# 混合模式: 选项, 目标行与正则式组合范围, 命令\nsed [-nefri] 'line,/regex/command' $file_path\n```\n### **sed 的常用选项**\n``` bash\n1. -n:  silent 静默模式, 只输出被 sed 处理过的行;\n2. -e:  --expression, 指定命令, 可以使用多个 -e 执行多个命令:\n        sed -e '$d' -e '/regex/p' $file_path\n3. -f:  执行给定文件里的命令;\n4. -r:  --regexp-extended, 使 sed 支持拓展的正则表达式语法, 拓展的正则表达式较常规的正则表达式增加支持了如下语法:\n        +, ?, |, ()\n        由于这些拓展语法也非常常见, 所以推荐若使用 sed 的 regex 功能时带上 -r 选项;\n5. -i:  直接在指定的文件里修改编辑, stdout 不输出任何内容;\n```\n### **sed 的 command**\n``` bash\n1. i:   insert 到 目标行的上一行\n2. a:   append 到 目标行的下一行 \n3. c:   replace, 不能使用正则表达式\n4. s:   replace, 使用正则表达式, 一般需要与 -r 配合使用, 模式为:\n        s/regex/new_str/g, 替换文件中所有的 regex;\n        s/regex/new_str, 只替换每行第一个被匹配上的 regex;\n        s/regex/new_str/p, 如果某行被匹配上了就打印出来, 常与 -n 选项一同使用;\n5. d:   delete\n6. p:   print, 一般需要与 -n 选项一同使用, 否则看不出打印效果\n7. y:   按每个字符映射, 模式案例: y/1234567890/ABCDEFGHIJ/\n```\n### **典型示例**\n``` bash\n# 打印最后一行\nsed -n '$p' $file_path\n# 指定两种操作, 删除9到最后一行, 以及向1到3行后追加 'append' 字符串\nsed -i -e '9,$d' -e '1,3a append' $file_path\n# 正则表达式替换(替换全部 regex)\nsed -ri 's/^(test|ping)[a-z]+.$/kill/g' $file_path\n# 打印从第9行开始到以 test 结尾的行之间的每一行\nsed -n '9,/test$/p' $file_path\n```\n``` bash\n# 结合变量, 往最后一行添加一行内容\n# 需使用\"\", 同时表示最后一行的 $ 需要转义\ncron_str='5 * * * *  sh /home/q/tools/bin/log_collect.sh 1>/dev/null'\nsed \"\\$a ${cron_str}\" /var/spool/cron/root\n```\n\n### **参考链接**\n- [linux之sed用法](http://www.cnblogs.com/dong008259/archive/2011/12/07/2279897.html)\n- [linux sed命令详解](http://www.iteye.com/topic/587673)\n\n","slug":"linux-text-sed命令整理","published":1,"updated":"2018-01-04T14:58:47.480Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cje24mxu9000oj1jxtox3q59e","content":"<blockquote>\n<p>stream editor: 流式文本编辑器;<br>sed 命令的侧重点在于对文本的编辑;</p>\n</blockquote>\n<a id=\"more\"></a>\n<h3 id=\"sed-的基本模式\"><a href=\"#sed-的基本模式\" class=\"headerlink\" title=\"sed 的基本模式\"></a><strong>sed 的基本模式</strong></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 标准模式: 选项, 目标行范围, 命令</span></span><br><span class=\"line\">sed  [-nefri] <span class=\"string\">'[target line]command'</span> <span class=\"variable\">$file_path</span></span><br><span class=\"line\"><span class=\"comment\"># 正则模式: 选项, 正则匹配式, 命令</span></span><br><span class=\"line\">sed  [-nefri] <span class=\"string\">'/regex/command'</span> <span class=\"variable\">$file_path</span></span><br><span class=\"line\"><span class=\"comment\"># 混合模式: 选项, 目标行与正则式组合范围, 命令</span></span><br><span class=\"line\">sed [-nefri] <span class=\"string\">'line,/regex/command'</span> <span class=\"variable\">$file_path</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"sed-的常用选项\"><a href=\"#sed-的常用选项\" class=\"headerlink\" title=\"sed 的常用选项\"></a><strong>sed 的常用选项</strong></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1. -n:  silent 静默模式, 只输出被 sed 处理过的行;</span><br><span class=\"line\">2. -e:  --expression, 指定命令, 可以使用多个 -e 执行多个命令:</span><br><span class=\"line\">        sed -e <span class=\"string\">'$d'</span> -e <span class=\"string\">'/regex/p'</span> <span class=\"variable\">$file_path</span></span><br><span class=\"line\">3. -f:  执行给定文件里的命令;</span><br><span class=\"line\">4. -r:  --regexp-extended, 使 sed 支持拓展的正则表达式语法, 拓展的正则表达式较常规的正则表达式增加支持了如下语法:</span><br><span class=\"line\">        +, ?, |, ()</span><br><span class=\"line\">        由于这些拓展语法也非常常见, 所以推荐若使用 sed 的 regex 功能时带上 -r 选项;</span><br><span class=\"line\">5. -i:  直接在指定的文件里修改编辑, stdout 不输出任何内容;</span><br></pre></td></tr></table></figure>\n<h3 id=\"sed-的-command\"><a href=\"#sed-的-command\" class=\"headerlink\" title=\"sed 的 command\"></a><strong>sed 的 command</strong></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1. i:   insert 到 目标行的上一行</span><br><span class=\"line\">2. a:   append 到 目标行的下一行 </span><br><span class=\"line\">3. c:   replace, 不能使用正则表达式</span><br><span class=\"line\">4. s:   replace, 使用正则表达式, 一般需要与 -r 配合使用, 模式为:</span><br><span class=\"line\">        s/regex/new_str/g, 替换文件中所有的 regex;</span><br><span class=\"line\">        s/regex/new_str, 只替换每行第一个被匹配上的 regex;</span><br><span class=\"line\">        s/regex/new_str/p, 如果某行被匹配上了就打印出来, 常与 -n 选项一同使用;</span><br><span class=\"line\">5. d:   delete</span><br><span class=\"line\">6. p:   <span class=\"built_in\">print</span>, 一般需要与 -n 选项一同使用, 否则看不出打印效果</span><br><span class=\"line\">7. y:   按每个字符映射, 模式案例: y/1234567890/ABCDEFGHIJ/</span><br></pre></td></tr></table></figure>\n<h3 id=\"典型示例\"><a href=\"#典型示例\" class=\"headerlink\" title=\"典型示例\"></a><strong>典型示例</strong></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 打印最后一行</span></span><br><span class=\"line\">sed -n <span class=\"string\">'$p'</span> <span class=\"variable\">$file_path</span></span><br><span class=\"line\"><span class=\"comment\"># 指定两种操作, 删除9到最后一行, 以及向1到3行后追加 'append' 字符串</span></span><br><span class=\"line\">sed -i -e <span class=\"string\">'9,$d'</span> -e <span class=\"string\">'1,3a append'</span> <span class=\"variable\">$file_path</span></span><br><span class=\"line\"><span class=\"comment\"># 正则表达式替换(替换全部 regex)</span></span><br><span class=\"line\">sed -ri <span class=\"string\">'s/^(test|ping)[a-z]+.$/kill/g'</span> <span class=\"variable\">$file_path</span></span><br><span class=\"line\"><span class=\"comment\"># 打印从第9行开始到以 test 结尾的行之间的每一行</span></span><br><span class=\"line\">sed -n <span class=\"string\">'9,/test$/p'</span> <span class=\"variable\">$file_path</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 结合变量, 往最后一行添加一行内容</span></span><br><span class=\"line\"><span class=\"comment\"># 需使用\"\", 同时表示最后一行的 $ 需要转义</span></span><br><span class=\"line\">cron_str=<span class=\"string\">'5 * * * *  sh /home/q/tools/bin/log_collect.sh 1&gt;/dev/null'</span></span><br><span class=\"line\">sed <span class=\"string\">\"\\$a <span class=\"variable\">$&#123;cron_str&#125;</span>\"</span> /var/spool/cron/root</span><br></pre></td></tr></table></figure>\n<h3 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a><strong>参考链接</strong></h3><ul>\n<li><a href=\"http://www.cnblogs.com/dong008259/archive/2011/12/07/2279897.html\" target=\"_blank\" rel=\"noopener\">linux之sed用法</a></li>\n<li><a href=\"http://www.iteye.com/topic/587673\" target=\"_blank\" rel=\"noopener\">linux sed命令详解</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>stream editor: 流式文本编辑器;<br>sed 命令的侧重点在于对文本的编辑;</p>\n</blockquote>","more":"<h3 id=\"sed-的基本模式\"><a href=\"#sed-的基本模式\" class=\"headerlink\" title=\"sed 的基本模式\"></a><strong>sed 的基本模式</strong></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 标准模式: 选项, 目标行范围, 命令</span></span><br><span class=\"line\">sed  [-nefri] <span class=\"string\">'[target line]command'</span> <span class=\"variable\">$file_path</span></span><br><span class=\"line\"><span class=\"comment\"># 正则模式: 选项, 正则匹配式, 命令</span></span><br><span class=\"line\">sed  [-nefri] <span class=\"string\">'/regex/command'</span> <span class=\"variable\">$file_path</span></span><br><span class=\"line\"><span class=\"comment\"># 混合模式: 选项, 目标行与正则式组合范围, 命令</span></span><br><span class=\"line\">sed [-nefri] <span class=\"string\">'line,/regex/command'</span> <span class=\"variable\">$file_path</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"sed-的常用选项\"><a href=\"#sed-的常用选项\" class=\"headerlink\" title=\"sed 的常用选项\"></a><strong>sed 的常用选项</strong></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1. -n:  silent 静默模式, 只输出被 sed 处理过的行;</span><br><span class=\"line\">2. -e:  --expression, 指定命令, 可以使用多个 -e 执行多个命令:</span><br><span class=\"line\">        sed -e <span class=\"string\">'$d'</span> -e <span class=\"string\">'/regex/p'</span> <span class=\"variable\">$file_path</span></span><br><span class=\"line\">3. -f:  执行给定文件里的命令;</span><br><span class=\"line\">4. -r:  --regexp-extended, 使 sed 支持拓展的正则表达式语法, 拓展的正则表达式较常规的正则表达式增加支持了如下语法:</span><br><span class=\"line\">        +, ?, |, ()</span><br><span class=\"line\">        由于这些拓展语法也非常常见, 所以推荐若使用 sed 的 regex 功能时带上 -r 选项;</span><br><span class=\"line\">5. -i:  直接在指定的文件里修改编辑, stdout 不输出任何内容;</span><br></pre></td></tr></table></figure>\n<h3 id=\"sed-的-command\"><a href=\"#sed-的-command\" class=\"headerlink\" title=\"sed 的 command\"></a><strong>sed 的 command</strong></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1. i:   insert 到 目标行的上一行</span><br><span class=\"line\">2. a:   append 到 目标行的下一行 </span><br><span class=\"line\">3. c:   replace, 不能使用正则表达式</span><br><span class=\"line\">4. s:   replace, 使用正则表达式, 一般需要与 -r 配合使用, 模式为:</span><br><span class=\"line\">        s/regex/new_str/g, 替换文件中所有的 regex;</span><br><span class=\"line\">        s/regex/new_str, 只替换每行第一个被匹配上的 regex;</span><br><span class=\"line\">        s/regex/new_str/p, 如果某行被匹配上了就打印出来, 常与 -n 选项一同使用;</span><br><span class=\"line\">5. d:   delete</span><br><span class=\"line\">6. p:   <span class=\"built_in\">print</span>, 一般需要与 -n 选项一同使用, 否则看不出打印效果</span><br><span class=\"line\">7. y:   按每个字符映射, 模式案例: y/1234567890/ABCDEFGHIJ/</span><br></pre></td></tr></table></figure>\n<h3 id=\"典型示例\"><a href=\"#典型示例\" class=\"headerlink\" title=\"典型示例\"></a><strong>典型示例</strong></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 打印最后一行</span></span><br><span class=\"line\">sed -n <span class=\"string\">'$p'</span> <span class=\"variable\">$file_path</span></span><br><span class=\"line\"><span class=\"comment\"># 指定两种操作, 删除9到最后一行, 以及向1到3行后追加 'append' 字符串</span></span><br><span class=\"line\">sed -i -e <span class=\"string\">'9,$d'</span> -e <span class=\"string\">'1,3a append'</span> <span class=\"variable\">$file_path</span></span><br><span class=\"line\"><span class=\"comment\"># 正则表达式替换(替换全部 regex)</span></span><br><span class=\"line\">sed -ri <span class=\"string\">'s/^(test|ping)[a-z]+.$/kill/g'</span> <span class=\"variable\">$file_path</span></span><br><span class=\"line\"><span class=\"comment\"># 打印从第9行开始到以 test 结尾的行之间的每一行</span></span><br><span class=\"line\">sed -n <span class=\"string\">'9,/test$/p'</span> <span class=\"variable\">$file_path</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 结合变量, 往最后一行添加一行内容</span></span><br><span class=\"line\"><span class=\"comment\"># 需使用\"\", 同时表示最后一行的 $ 需要转义</span></span><br><span class=\"line\">cron_str=<span class=\"string\">'5 * * * *  sh /home/q/tools/bin/log_collect.sh 1&gt;/dev/null'</span></span><br><span class=\"line\">sed <span class=\"string\">\"\\$a <span class=\"variable\">$&#123;cron_str&#125;</span>\"</span> /var/spool/cron/root</span><br></pre></td></tr></table></figure>\n<h3 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a><strong>参考链接</strong></h3><ul>\n<li><a href=\"http://www.cnblogs.com/dong008259/archive/2011/12/07/2279897.html\" target=\"_blank\" rel=\"noopener\">linux之sed用法</a></li>\n<li><a href=\"http://www.iteye.com/topic/587673\" target=\"_blank\" rel=\"noopener\">linux sed命令详解</a></li>\n</ul>"},{"title":"maven-assembly-plugin 使用总结","date":"2016-11-19T15:42:40.000Z","_content":"\n> 本文在 Apache Maven 的官方文档上, 结合自己的一些项目经历: [在 Apache Spark 中使用 springframework 的一次实践](), 总结了一些 assembly 插件的使用方式和一些注意事项, 以作备忘;\n另外, 由于 assembly 的 核心配置文件中可配置项种类繁多, 为了体现直观性, 文本直接在一段 '丰富而典型' 的配置文件 case 上, 以注释的形式作为每个配置项的释义;\n\n<!--more-->\n\n------\n\n### **pom.xml 中的配置项**\n一段典型的 assembly 插件的 mvn 配置:\n``` xml\n<plugin>\n    <artifactId>maven-assembly-plugin</artifactId>\n    <version>${assembly.plugin.version}</version>\n    \n    <configuration>\n        <!-- 打包后的包名是否需要追加 assembly 配置文件的 id -->\n        <appendAssemblyId>false</appendAssemblyId>\n        <!-- 最终生成的打包文件输出的路径 -->\n        <outputDirectory>${project.build.directory}/target</outputDirectory>\n        <!-- 定义核心配置文件的访问路径 -->\n        <descriptors>\n            <descriptor>${basedir}/src/main/assembly/client.xml</descriptor>\n            <descriptor>${basedir}/src/main/assembly/server.xml</descriptor>\n        </descriptors>\n    </configuration>\n    \n    <executions>\n        <execution>\n            <!-- 一般运行在 package phase -->\n            <phase>package</phase>\n            <goals>\n                <!-- assembly 插件中唯一的核心 goal, 另外一个 goal 是 assembly:help -->\n                <goal>single</goal>\n            </goals>\n        </execution>\n    </executions>\n</plugin>\n```\n\n&nbsp;\n### **核心配置文件**\n以下 assembly 核心配置文件包含了最常用的几种配置项, 该文件习惯上放置在 `${basedir}/src/main/assembly/` 目录里, 并如上一节所示, 在 `configuration -> descriptors` 路径下定义加载:\n``` xml\n<assembly xmlns=\"http://maven.apache.org/ASSEMBLY/2.0.0\"\n          xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n          xsi:schemaLocation=\"http://maven.apache.org/ASSEMBLY/2.0.0 http://maven.apache.org/xsd/assembly-2.0.0.xsd\">\n          \n    <!-- assembly 配置文件id -->\n    <id>deploy</id>\n    <!-- \n        目标打包文件的格式, 支持格式如下:\n            jar, war, zip, tar, tar.gz, tar.bz2 等 \n    -->\n    <formats>\n        <format>jar</format>\n    </formats>\n    \n    <!-- 是否以 ${project.build.finalName}, 作为所有被打包文件的基目录, 默认 true -->\n    <includeBaseDirectory>false</includeBaseDirectory>\n    <!-- 显式定义 所有被打包文件的基目录 -->\n    <baseDirectory>${project.build.finalName}</baseDirectory>\n    \n    <!-- 独立文件的收集 -->\n    <files>\n        <file>\n            <!-- 待收集的文件名 -->\n            <source>LICENSE.txt</source>\n            <!-- 收集到目标文件的相对路径 -->\n            <outputDirectory>/</outputDirectory>\n        </file>\n        <file>\n            <source>NOTICE.txt</source>\n            <outputDirectory>/</outputDirectory>\n            <!-- 将 ${...} 占位符 替换为实际的内容, 默认 false -->\n            <filtered>true</filtered>\n        </file>\n    </files>\n    \n    <!-- 目录的收集 -->\n    <fileSets>\n        <fileSet>\n            <!-- 目录名 -->\n            <directory>${project.basedir}/src/main/resources</directory>\n            <outputDirectory>/</outputDirectory>\n        </fileSet>\n        <fileSet>\n            <directory>${project.basedir}/src/doc</directory>\n            <!-- 是否使用默认的排除项, 排除范围包括版本控制程序产生的 metadata 等, 默认 true -->\n            <useDefaultExcludes>true</useDefaultExcludes>\n            <outputDirectory>/doc</outputDirectory>\n        </fileSet>\n    </fileSets>\n    \n    <!-- 依赖的收集 -->\n    <dependencySets>\n        <dependencySet>\n            <outputDirectory>/lib</outputDirectory>\n            <!-- 是否将本次构建过程中生成的 主构件 加入到依赖的收集中, 默认 true -->\n            <useProjectArtifact>true</useProjectArtifact>\n            <!-- 是否将本次构建过程中生成的 附加构件 也加入到依赖的收集中, 默认 false -->\n            <useProjectAttachments>false</useProjectAttachments>\n            <!-- 是否将依赖都解包为普通的目录文件放入 outputDirectory, 默认 false -->\n            <unpack>false</unpack>\n            <!--  -->\n            <scope>runtime</scope>\n            <!-- 是否让该 dependencySets 收集具有传递性, 即递归地将 dependency 间接依赖的 dependencies 都收集到打包文件中, 默认 true -->\n            <useTransitiveDependencies>true</useTransitiveDependencies>\n            <!-- \n                includes/excludes 的格式:\n                    groupId:artifactId:type:classifier\n                    groupId:artifactId\n                    groupId:artifactId:type:classifier:version\n                支持使用 * 通配, * 可以完整匹配由多个 ':' 分割的 section;\n            -->\n            <excludes>\n                <exclude>org.apache.commons:commons-logging:jar</exclude>\n                <exclude>*:war</exclude>\n            </excludes>\n            <!-- 是否让 includes/excludes 具有传递性, 即递归地让指定的 dependency 间接依赖的 dependencies 都被 include/exclude, 默认 false -->\n            <useTransitiveFiltering>true</useTransitiveFiltering>\n        </dependencySet>\n    </dependencySets>\n    \n</assembly>\n```\n\n&nbsp;\n### **使用 assembly 的一些注意事项**\n* 使用 assembly 打包成需要独立运行的 jar 时, 若无特殊需要显式定义 CLASSPATH,  则在核心配置文件中不应该定义 `baseDirectory`, 并将 `includeBaseDirectory` 置为 `false`;\n因为 assembly 生成的 jar 包在 `/META-INF/MANIFEST.MF` 文件中默认不会定义 `Class-Path`, 即 CLASSPATH 默认就是 jar 中的基目录;\n\n``` bash\n# assembly 生成的 /META-INF/MANIFEST.MF\nManifest-Version: 1.0\nArchiver-Version: Plexus Archiver\nCreated-By: 25.151-b12 (Oracle Corporation)\n```\n* 核心配置文件中的 `outputDirectory` 皆是以目标打包文件的根为相对路径的; 无论是否在路径最前面添加 `/`, 都不会有影响;\n* assembly 2.2 之前的版本, 在涉及到一些复杂第三方依赖, 多个不同的 jar 包中含有同名的文件 (如 org.springframework) 时, 使用 assembly 打包时会遇到一个 bug:\nassembly 只把第一次遇到的同名文件加入目标打包文件, 其后遇到的同名文件, 则被 skip 掉 ( 详见官方 issue: [When using mulitple Spring dependencies, the files from META-INF (from the Spring jars) overwrite each other in an executable jar-with-dependencies](http://jira.codehaus.org/browse/MASSEMBLY-360) );\n当然, 在这个 issue 当中, 触发此 bug 还有一个必要条件是将 dependencySet 中的 unpack 置为 true, 这样多个 spring artifact META-INF/ 中的 spring.handlers / spring.schemas / spring.tooling 等文件才会同名冲突;\n\n&nbsp;\n### **关于 assembly 命令**\n除了上述以 配置文件 + maven core phase 回调的形式使用 assembly 插件之外, assembly 插件的 goals 也可以命令的形式执行:\n``` bash\nmvn clean assembly:single\nmvn assembly:help\n```\n由于使用 assembly 命令的场景不多见, 此处不再详述, 详见 maven 官方介绍: [assembly:single](http://maven.apache.org/plugins/maven-assembly-plugin/single-mojo.html)\n\n&nbsp;\n### **站内相关文章**\n- [在 Apache Spark 中使用 springframework 的一次实践]()\n\n&nbsp;\n### **参考链接**\n- [Apache Maven Assembly Plugin: Assembly](http://maven.apache.org/plugins/maven-assembly-plugin/assembly.html)\n- [Filtering Some Distribution Files](https://maven.apache.org/plugins/maven-assembly-plugin/examples/single/filtering-some-distribution-files.html)\n- [8.5. Controlling the Contents of an Assembly](http://books.sonatype.com/mvnref-book/reference/assemblies-sect-controlling-contents.html)\n- [Quick Note on All includes and excludes Patterns](https://maven.apache.org/plugins/maven-assembly-plugin/advanced-descriptor-topics.html)\n\n","source":"_posts/tools-maven--assembly_plugin.md","raw":"---\ntitle: maven-assembly-plugin 使用总结\ndate: 2016-11-19 23:42:40\ncategories:\n - tools\n - maven\ntags:\n - mvn:plugins\n---\n\n> 本文在 Apache Maven 的官方文档上, 结合自己的一些项目经历: [在 Apache Spark 中使用 springframework 的一次实践](), 总结了一些 assembly 插件的使用方式和一些注意事项, 以作备忘;\n另外, 由于 assembly 的 核心配置文件中可配置项种类繁多, 为了体现直观性, 文本直接在一段 '丰富而典型' 的配置文件 case 上, 以注释的形式作为每个配置项的释义;\n\n<!--more-->\n\n------\n\n### **pom.xml 中的配置项**\n一段典型的 assembly 插件的 mvn 配置:\n``` xml\n<plugin>\n    <artifactId>maven-assembly-plugin</artifactId>\n    <version>${assembly.plugin.version}</version>\n    \n    <configuration>\n        <!-- 打包后的包名是否需要追加 assembly 配置文件的 id -->\n        <appendAssemblyId>false</appendAssemblyId>\n        <!-- 最终生成的打包文件输出的路径 -->\n        <outputDirectory>${project.build.directory}/target</outputDirectory>\n        <!-- 定义核心配置文件的访问路径 -->\n        <descriptors>\n            <descriptor>${basedir}/src/main/assembly/client.xml</descriptor>\n            <descriptor>${basedir}/src/main/assembly/server.xml</descriptor>\n        </descriptors>\n    </configuration>\n    \n    <executions>\n        <execution>\n            <!-- 一般运行在 package phase -->\n            <phase>package</phase>\n            <goals>\n                <!-- assembly 插件中唯一的核心 goal, 另外一个 goal 是 assembly:help -->\n                <goal>single</goal>\n            </goals>\n        </execution>\n    </executions>\n</plugin>\n```\n\n&nbsp;\n### **核心配置文件**\n以下 assembly 核心配置文件包含了最常用的几种配置项, 该文件习惯上放置在 `${basedir}/src/main/assembly/` 目录里, 并如上一节所示, 在 `configuration -> descriptors` 路径下定义加载:\n``` xml\n<assembly xmlns=\"http://maven.apache.org/ASSEMBLY/2.0.0\"\n          xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n          xsi:schemaLocation=\"http://maven.apache.org/ASSEMBLY/2.0.0 http://maven.apache.org/xsd/assembly-2.0.0.xsd\">\n          \n    <!-- assembly 配置文件id -->\n    <id>deploy</id>\n    <!-- \n        目标打包文件的格式, 支持格式如下:\n            jar, war, zip, tar, tar.gz, tar.bz2 等 \n    -->\n    <formats>\n        <format>jar</format>\n    </formats>\n    \n    <!-- 是否以 ${project.build.finalName}, 作为所有被打包文件的基目录, 默认 true -->\n    <includeBaseDirectory>false</includeBaseDirectory>\n    <!-- 显式定义 所有被打包文件的基目录 -->\n    <baseDirectory>${project.build.finalName}</baseDirectory>\n    \n    <!-- 独立文件的收集 -->\n    <files>\n        <file>\n            <!-- 待收集的文件名 -->\n            <source>LICENSE.txt</source>\n            <!-- 收集到目标文件的相对路径 -->\n            <outputDirectory>/</outputDirectory>\n        </file>\n        <file>\n            <source>NOTICE.txt</source>\n            <outputDirectory>/</outputDirectory>\n            <!-- 将 ${...} 占位符 替换为实际的内容, 默认 false -->\n            <filtered>true</filtered>\n        </file>\n    </files>\n    \n    <!-- 目录的收集 -->\n    <fileSets>\n        <fileSet>\n            <!-- 目录名 -->\n            <directory>${project.basedir}/src/main/resources</directory>\n            <outputDirectory>/</outputDirectory>\n        </fileSet>\n        <fileSet>\n            <directory>${project.basedir}/src/doc</directory>\n            <!-- 是否使用默认的排除项, 排除范围包括版本控制程序产生的 metadata 等, 默认 true -->\n            <useDefaultExcludes>true</useDefaultExcludes>\n            <outputDirectory>/doc</outputDirectory>\n        </fileSet>\n    </fileSets>\n    \n    <!-- 依赖的收集 -->\n    <dependencySets>\n        <dependencySet>\n            <outputDirectory>/lib</outputDirectory>\n            <!-- 是否将本次构建过程中生成的 主构件 加入到依赖的收集中, 默认 true -->\n            <useProjectArtifact>true</useProjectArtifact>\n            <!-- 是否将本次构建过程中生成的 附加构件 也加入到依赖的收集中, 默认 false -->\n            <useProjectAttachments>false</useProjectAttachments>\n            <!-- 是否将依赖都解包为普通的目录文件放入 outputDirectory, 默认 false -->\n            <unpack>false</unpack>\n            <!--  -->\n            <scope>runtime</scope>\n            <!-- 是否让该 dependencySets 收集具有传递性, 即递归地将 dependency 间接依赖的 dependencies 都收集到打包文件中, 默认 true -->\n            <useTransitiveDependencies>true</useTransitiveDependencies>\n            <!-- \n                includes/excludes 的格式:\n                    groupId:artifactId:type:classifier\n                    groupId:artifactId\n                    groupId:artifactId:type:classifier:version\n                支持使用 * 通配, * 可以完整匹配由多个 ':' 分割的 section;\n            -->\n            <excludes>\n                <exclude>org.apache.commons:commons-logging:jar</exclude>\n                <exclude>*:war</exclude>\n            </excludes>\n            <!-- 是否让 includes/excludes 具有传递性, 即递归地让指定的 dependency 间接依赖的 dependencies 都被 include/exclude, 默认 false -->\n            <useTransitiveFiltering>true</useTransitiveFiltering>\n        </dependencySet>\n    </dependencySets>\n    \n</assembly>\n```\n\n&nbsp;\n### **使用 assembly 的一些注意事项**\n* 使用 assembly 打包成需要独立运行的 jar 时, 若无特殊需要显式定义 CLASSPATH,  则在核心配置文件中不应该定义 `baseDirectory`, 并将 `includeBaseDirectory` 置为 `false`;\n因为 assembly 生成的 jar 包在 `/META-INF/MANIFEST.MF` 文件中默认不会定义 `Class-Path`, 即 CLASSPATH 默认就是 jar 中的基目录;\n\n``` bash\n# assembly 生成的 /META-INF/MANIFEST.MF\nManifest-Version: 1.0\nArchiver-Version: Plexus Archiver\nCreated-By: 25.151-b12 (Oracle Corporation)\n```\n* 核心配置文件中的 `outputDirectory` 皆是以目标打包文件的根为相对路径的; 无论是否在路径最前面添加 `/`, 都不会有影响;\n* assembly 2.2 之前的版本, 在涉及到一些复杂第三方依赖, 多个不同的 jar 包中含有同名的文件 (如 org.springframework) 时, 使用 assembly 打包时会遇到一个 bug:\nassembly 只把第一次遇到的同名文件加入目标打包文件, 其后遇到的同名文件, 则被 skip 掉 ( 详见官方 issue: [When using mulitple Spring dependencies, the files from META-INF (from the Spring jars) overwrite each other in an executable jar-with-dependencies](http://jira.codehaus.org/browse/MASSEMBLY-360) );\n当然, 在这个 issue 当中, 触发此 bug 还有一个必要条件是将 dependencySet 中的 unpack 置为 true, 这样多个 spring artifact META-INF/ 中的 spring.handlers / spring.schemas / spring.tooling 等文件才会同名冲突;\n\n&nbsp;\n### **关于 assembly 命令**\n除了上述以 配置文件 + maven core phase 回调的形式使用 assembly 插件之外, assembly 插件的 goals 也可以命令的形式执行:\n``` bash\nmvn clean assembly:single\nmvn assembly:help\n```\n由于使用 assembly 命令的场景不多见, 此处不再详述, 详见 maven 官方介绍: [assembly:single](http://maven.apache.org/plugins/maven-assembly-plugin/single-mojo.html)\n\n&nbsp;\n### **站内相关文章**\n- [在 Apache Spark 中使用 springframework 的一次实践]()\n\n&nbsp;\n### **参考链接**\n- [Apache Maven Assembly Plugin: Assembly](http://maven.apache.org/plugins/maven-assembly-plugin/assembly.html)\n- [Filtering Some Distribution Files](https://maven.apache.org/plugins/maven-assembly-plugin/examples/single/filtering-some-distribution-files.html)\n- [8.5. Controlling the Contents of an Assembly](http://books.sonatype.com/mvnref-book/reference/assemblies-sect-controlling-contents.html)\n- [Quick Note on All includes and excludes Patterns](https://maven.apache.org/plugins/maven-assembly-plugin/advanced-descriptor-topics.html)\n\n","slug":"tools-maven--assembly_plugin","published":1,"updated":"2018-01-20T13:20:30.547Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cje24mxub000pj1jxs4giahxo","content":"<blockquote>\n<p>本文在 Apache Maven 的官方文档上, 结合自己的一些项目经历: <a href=\"\">在 Apache Spark 中使用 springframework 的一次实践</a>, 总结了一些 assembly 插件的使用方式和一些注意事项, 以作备忘;<br>另外, 由于 assembly 的 核心配置文件中可配置项种类繁多, 为了体现直观性, 文本直接在一段 ‘丰富而典型’ 的配置文件 case 上, 以注释的形式作为每个配置项的释义;</p>\n</blockquote>\n<a id=\"more\"></a>\n<hr>\n<h3 id=\"pom-xml-中的配置项\"><a href=\"#pom-xml-中的配置项\" class=\"headerlink\" title=\"pom.xml 中的配置项\"></a><strong>pom.xml 中的配置项</strong></h3><p>一段典型的 assembly 插件的 mvn 配置:<br><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-assembly-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>$&#123;assembly.plugin.version&#125;<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">        <span class=\"comment\">&lt;!-- 打包后的包名是否需要追加 assembly 配置文件的 id --&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">appendAssemblyId</span>&gt;</span>false<span class=\"tag\">&lt;/<span class=\"name\">appendAssemblyId</span>&gt;</span></span><br><span class=\"line\">        <span class=\"comment\">&lt;!-- 最终生成的打包文件输出的路径 --&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">outputDirectory</span>&gt;</span>$&#123;project.build.directory&#125;/target<span class=\"tag\">&lt;/<span class=\"name\">outputDirectory</span>&gt;</span></span><br><span class=\"line\">        <span class=\"comment\">&lt;!-- 定义核心配置文件的访问路径 --&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">descriptors</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">descriptor</span>&gt;</span>$&#123;basedir&#125;/src/main/assembly/client.xml<span class=\"tag\">&lt;/<span class=\"name\">descriptor</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">descriptor</span>&gt;</span>$&#123;basedir&#125;/src/main/assembly/server.xml<span class=\"tag\">&lt;/<span class=\"name\">descriptor</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">descriptors</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">executions</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">            <span class=\"comment\">&lt;!-- 一般运行在 package phase --&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">phase</span>&gt;</span>package<span class=\"tag\">&lt;/<span class=\"name\">phase</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">                <span class=\"comment\">&lt;!-- assembly 插件中唯一的核心 goal, 另外一个 goal 是 assembly:help --&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">goal</span>&gt;</span>single<span class=\"tag\">&lt;/<span class=\"name\">goal</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">executions</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure></p>\n<p>&nbsp;</p>\n<h3 id=\"核心配置文件\"><a href=\"#核心配置文件\" class=\"headerlink\" title=\"核心配置文件\"></a><strong>核心配置文件</strong></h3><p>以下 assembly 核心配置文件包含了最常用的几种配置项, 该文件习惯上放置在 <code>${basedir}/src/main/assembly/</code> 目录里, 并如上一节所示, 在 <code>configuration -&gt; descriptors</code> 路径下定义加载:<br><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">assembly</span> <span class=\"attr\">xmlns</span>=<span class=\"string\">\"http://maven.apache.org/ASSEMBLY/2.0.0\"</span></span></span><br><span class=\"line\"><span class=\"tag\">          <span class=\"attr\">xmlns:xsi</span>=<span class=\"string\">\"http://www.w3.org/2001/XMLSchema-instance\"</span></span></span><br><span class=\"line\"><span class=\"tag\">          <span class=\"attr\">xsi:schemaLocation</span>=<span class=\"string\">\"http://maven.apache.org/ASSEMBLY/2.0.0 http://maven.apache.org/xsd/assembly-2.0.0.xsd\"</span>&gt;</span></span><br><span class=\"line\">          </span><br><span class=\"line\">    <span class=\"comment\">&lt;!-- assembly 配置文件id --&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>deploy<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">    <span class=\"comment\">&lt;!-- </span></span><br><span class=\"line\"><span class=\"comment\">        目标打包文件的格式, 支持格式如下:</span></span><br><span class=\"line\"><span class=\"comment\">            jar, war, zip, tar, tar.gz, tar.bz2 等 </span></span><br><span class=\"line\"><span class=\"comment\">    --&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">formats</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">format</span>&gt;</span>jar<span class=\"tag\">&lt;/<span class=\"name\">format</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">formats</span>&gt;</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">&lt;!-- 是否以 $&#123;project.build.finalName&#125;, 作为所有被打包文件的基目录, 默认 true --&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">includeBaseDirectory</span>&gt;</span>false<span class=\"tag\">&lt;/<span class=\"name\">includeBaseDirectory</span>&gt;</span></span><br><span class=\"line\">    <span class=\"comment\">&lt;!-- 显式定义 所有被打包文件的基目录 --&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">baseDirectory</span>&gt;</span>$&#123;project.build.finalName&#125;<span class=\"tag\">&lt;/<span class=\"name\">baseDirectory</span>&gt;</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">&lt;!-- 独立文件的收集 --&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">files</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">file</span>&gt;</span></span><br><span class=\"line\">            <span class=\"comment\">&lt;!-- 待收集的文件名 --&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">source</span>&gt;</span>LICENSE.txt<span class=\"tag\">&lt;/<span class=\"name\">source</span>&gt;</span></span><br><span class=\"line\">            <span class=\"comment\">&lt;!-- 收集到目标文件的相对路径 --&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">outputDirectory</span>&gt;</span>/<span class=\"tag\">&lt;/<span class=\"name\">outputDirectory</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">file</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">file</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">source</span>&gt;</span>NOTICE.txt<span class=\"tag\">&lt;/<span class=\"name\">source</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">outputDirectory</span>&gt;</span>/<span class=\"tag\">&lt;/<span class=\"name\">outputDirectory</span>&gt;</span></span><br><span class=\"line\">            <span class=\"comment\">&lt;!-- 将 $&#123;...&#125; 占位符 替换为实际的内容, 默认 false --&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">filtered</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">filtered</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">file</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">files</span>&gt;</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">&lt;!-- 目录的收集 --&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">fileSets</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">fileSet</span>&gt;</span></span><br><span class=\"line\">            <span class=\"comment\">&lt;!-- 目录名 --&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">directory</span>&gt;</span>$&#123;project.basedir&#125;/src/main/resources<span class=\"tag\">&lt;/<span class=\"name\">directory</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">outputDirectory</span>&gt;</span>/<span class=\"tag\">&lt;/<span class=\"name\">outputDirectory</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">fileSet</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">fileSet</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">directory</span>&gt;</span>$&#123;project.basedir&#125;/src/doc<span class=\"tag\">&lt;/<span class=\"name\">directory</span>&gt;</span></span><br><span class=\"line\">            <span class=\"comment\">&lt;!-- 是否使用默认的排除项, 排除范围包括版本控制程序产生的 metadata 等, 默认 true --&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">useDefaultExcludes</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">useDefaultExcludes</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">outputDirectory</span>&gt;</span>/doc<span class=\"tag\">&lt;/<span class=\"name\">outputDirectory</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">fileSet</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">fileSets</span>&gt;</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">&lt;!-- 依赖的收集 --&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">dependencySets</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">dependencySet</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">outputDirectory</span>&gt;</span>/lib<span class=\"tag\">&lt;/<span class=\"name\">outputDirectory</span>&gt;</span></span><br><span class=\"line\">            <span class=\"comment\">&lt;!-- 是否将本次构建过程中生成的 主构件 加入到依赖的收集中, 默认 true --&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">useProjectArtifact</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">useProjectArtifact</span>&gt;</span></span><br><span class=\"line\">            <span class=\"comment\">&lt;!-- 是否将本次构建过程中生成的 附加构件 也加入到依赖的收集中, 默认 false --&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">useProjectAttachments</span>&gt;</span>false<span class=\"tag\">&lt;/<span class=\"name\">useProjectAttachments</span>&gt;</span></span><br><span class=\"line\">            <span class=\"comment\">&lt;!-- 是否将依赖都解包为普通的目录文件放入 outputDirectory, 默认 false --&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">unpack</span>&gt;</span>false<span class=\"tag\">&lt;/<span class=\"name\">unpack</span>&gt;</span></span><br><span class=\"line\">            <span class=\"comment\">&lt;!--  --&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">scope</span>&gt;</span>runtime<span class=\"tag\">&lt;/<span class=\"name\">scope</span>&gt;</span></span><br><span class=\"line\">            <span class=\"comment\">&lt;!-- 是否让该 dependencySets 收集具有传递性, 即递归地将 dependency 间接依赖的 dependencies 都收集到打包文件中, 默认 true --&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">useTransitiveDependencies</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">useTransitiveDependencies</span>&gt;</span></span><br><span class=\"line\">            <span class=\"comment\">&lt;!-- </span></span><br><span class=\"line\"><span class=\"comment\">                includes/excludes 的格式:</span></span><br><span class=\"line\"><span class=\"comment\">                    groupId:artifactId:type:classifier</span></span><br><span class=\"line\"><span class=\"comment\">                    groupId:artifactId</span></span><br><span class=\"line\"><span class=\"comment\">                    groupId:artifactId:type:classifier:version</span></span><br><span class=\"line\"><span class=\"comment\">                支持使用 * 通配, * 可以完整匹配由多个 ':' 分割的 section;</span></span><br><span class=\"line\"><span class=\"comment\">            --&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">excludes</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">exclude</span>&gt;</span>org.apache.commons:commons-logging:jar<span class=\"tag\">&lt;/<span class=\"name\">exclude</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">exclude</span>&gt;</span>*:war<span class=\"tag\">&lt;/<span class=\"name\">exclude</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">excludes</span>&gt;</span></span><br><span class=\"line\">            <span class=\"comment\">&lt;!-- 是否让 includes/excludes 具有传递性, 即递归地让指定的 dependency 间接依赖的 dependencies 都被 include/exclude, 默认 false --&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">useTransitiveFiltering</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">useTransitiveFiltering</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">dependencySet</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">dependencySets</span>&gt;</span></span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">assembly</span>&gt;</span></span><br></pre></td></tr></table></figure></p>\n<p>&nbsp;</p>\n<h3 id=\"使用-assembly-的一些注意事项\"><a href=\"#使用-assembly-的一些注意事项\" class=\"headerlink\" title=\"使用 assembly 的一些注意事项\"></a><strong>使用 assembly 的一些注意事项</strong></h3><ul>\n<li>使用 assembly 打包成需要独立运行的 jar 时, 若无特殊需要显式定义 CLASSPATH,  则在核心配置文件中不应该定义 <code>baseDirectory</code>, 并将 <code>includeBaseDirectory</code> 置为 <code>false</code>;<br>因为 assembly 生成的 jar 包在 <code>/META-INF/MANIFEST.MF</code> 文件中默认不会定义 <code>Class-Path</code>, 即 CLASSPATH 默认就是 jar 中的基目录;</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># assembly 生成的 /META-INF/MANIFEST.MF</span></span><br><span class=\"line\">Manifest-Version: 1.0</span><br><span class=\"line\">Archiver-Version: Plexus Archiver</span><br><span class=\"line\">Created-By: 25.151-b12 (Oracle Corporation)</span><br></pre></td></tr></table></figure>\n<ul>\n<li>核心配置文件中的 <code>outputDirectory</code> 皆是以目标打包文件的根为相对路径的; 无论是否在路径最前面添加 <code>/</code>, 都不会有影响;</li>\n<li>assembly 2.2 之前的版本, 在涉及到一些复杂第三方依赖, 多个不同的 jar 包中含有同名的文件 (如 org.springframework) 时, 使用 assembly 打包时会遇到一个 bug:<br>assembly 只把第一次遇到的同名文件加入目标打包文件, 其后遇到的同名文件, 则被 skip 掉 ( 详见官方 issue: <a href=\"http://jira.codehaus.org/browse/MASSEMBLY-360\" target=\"_blank\" rel=\"noopener\">When using mulitple Spring dependencies, the files from META-INF (from the Spring jars) overwrite each other in an executable jar-with-dependencies</a> );<br>当然, 在这个 issue 当中, 触发此 bug 还有一个必要条件是将 dependencySet 中的 unpack 置为 true, 这样多个 spring artifact META-INF/ 中的 spring.handlers / spring.schemas / spring.tooling 等文件才会同名冲突;</li>\n</ul>\n<p>&nbsp;</p>\n<h3 id=\"关于-assembly-命令\"><a href=\"#关于-assembly-命令\" class=\"headerlink\" title=\"关于 assembly 命令\"></a><strong>关于 assembly 命令</strong></h3><p>除了上述以 配置文件 + maven core phase 回调的形式使用 assembly 插件之外, assembly 插件的 goals 也可以命令的形式执行:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mvn clean assembly:single</span><br><span class=\"line\">mvn assembly:<span class=\"built_in\">help</span></span><br></pre></td></tr></table></figure></p>\n<p>由于使用 assembly 命令的场景不多见, 此处不再详述, 详见 maven 官方介绍: <a href=\"http://maven.apache.org/plugins/maven-assembly-plugin/single-mojo.html\" target=\"_blank\" rel=\"noopener\">assembly:single</a></p>\n<p>&nbsp;</p>\n<h3 id=\"站内相关文章\"><a href=\"#站内相关文章\" class=\"headerlink\" title=\"站内相关文章\"></a><strong>站内相关文章</strong></h3><ul>\n<li><a href=\"\">在 Apache Spark 中使用 springframework 的一次实践</a></li>\n</ul>\n<p>&nbsp;</p>\n<h3 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a><strong>参考链接</strong></h3><ul>\n<li><a href=\"http://maven.apache.org/plugins/maven-assembly-plugin/assembly.html\" target=\"_blank\" rel=\"noopener\">Apache Maven Assembly Plugin: Assembly</a></li>\n<li><a href=\"https://maven.apache.org/plugins/maven-assembly-plugin/examples/single/filtering-some-distribution-files.html\" target=\"_blank\" rel=\"noopener\">Filtering Some Distribution Files</a></li>\n<li><a href=\"http://books.sonatype.com/mvnref-book/reference/assemblies-sect-controlling-contents.html\" target=\"_blank\" rel=\"noopener\">8.5. Controlling the Contents of an Assembly</a></li>\n<li><a href=\"https://maven.apache.org/plugins/maven-assembly-plugin/advanced-descriptor-topics.html\" target=\"_blank\" rel=\"noopener\">Quick Note on All includes and excludes Patterns</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>本文在 Apache Maven 的官方文档上, 结合自己的一些项目经历: <a href=\"\">在 Apache Spark 中使用 springframework 的一次实践</a>, 总结了一些 assembly 插件的使用方式和一些注意事项, 以作备忘;<br>另外, 由于 assembly 的 核心配置文件中可配置项种类繁多, 为了体现直观性, 文本直接在一段 ‘丰富而典型’ 的配置文件 case 上, 以注释的形式作为每个配置项的释义;</p>\n</blockquote>","more":"<hr>\n<h3 id=\"pom-xml-中的配置项\"><a href=\"#pom-xml-中的配置项\" class=\"headerlink\" title=\"pom.xml 中的配置项\"></a><strong>pom.xml 中的配置项</strong></h3><p>一段典型的 assembly 插件的 mvn 配置:<br><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-assembly-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>$&#123;assembly.plugin.version&#125;<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">        <span class=\"comment\">&lt;!-- 打包后的包名是否需要追加 assembly 配置文件的 id --&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">appendAssemblyId</span>&gt;</span>false<span class=\"tag\">&lt;/<span class=\"name\">appendAssemblyId</span>&gt;</span></span><br><span class=\"line\">        <span class=\"comment\">&lt;!-- 最终生成的打包文件输出的路径 --&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">outputDirectory</span>&gt;</span>$&#123;project.build.directory&#125;/target<span class=\"tag\">&lt;/<span class=\"name\">outputDirectory</span>&gt;</span></span><br><span class=\"line\">        <span class=\"comment\">&lt;!-- 定义核心配置文件的访问路径 --&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">descriptors</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">descriptor</span>&gt;</span>$&#123;basedir&#125;/src/main/assembly/client.xml<span class=\"tag\">&lt;/<span class=\"name\">descriptor</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">descriptor</span>&gt;</span>$&#123;basedir&#125;/src/main/assembly/server.xml<span class=\"tag\">&lt;/<span class=\"name\">descriptor</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">descriptors</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">executions</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">            <span class=\"comment\">&lt;!-- 一般运行在 package phase --&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">phase</span>&gt;</span>package<span class=\"tag\">&lt;/<span class=\"name\">phase</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">                <span class=\"comment\">&lt;!-- assembly 插件中唯一的核心 goal, 另外一个 goal 是 assembly:help --&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">goal</span>&gt;</span>single<span class=\"tag\">&lt;/<span class=\"name\">goal</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">executions</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure></p>\n<p>&nbsp;</p>\n<h3 id=\"核心配置文件\"><a href=\"#核心配置文件\" class=\"headerlink\" title=\"核心配置文件\"></a><strong>核心配置文件</strong></h3><p>以下 assembly 核心配置文件包含了最常用的几种配置项, 该文件习惯上放置在 <code>${basedir}/src/main/assembly/</code> 目录里, 并如上一节所示, 在 <code>configuration -&gt; descriptors</code> 路径下定义加载:<br><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">assembly</span> <span class=\"attr\">xmlns</span>=<span class=\"string\">\"http://maven.apache.org/ASSEMBLY/2.0.0\"</span></span></span><br><span class=\"line\"><span class=\"tag\">          <span class=\"attr\">xmlns:xsi</span>=<span class=\"string\">\"http://www.w3.org/2001/XMLSchema-instance\"</span></span></span><br><span class=\"line\"><span class=\"tag\">          <span class=\"attr\">xsi:schemaLocation</span>=<span class=\"string\">\"http://maven.apache.org/ASSEMBLY/2.0.0 http://maven.apache.org/xsd/assembly-2.0.0.xsd\"</span>&gt;</span></span><br><span class=\"line\">          </span><br><span class=\"line\">    <span class=\"comment\">&lt;!-- assembly 配置文件id --&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>deploy<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">    <span class=\"comment\">&lt;!-- </span></span><br><span class=\"line\"><span class=\"comment\">        目标打包文件的格式, 支持格式如下:</span></span><br><span class=\"line\"><span class=\"comment\">            jar, war, zip, tar, tar.gz, tar.bz2 等 </span></span><br><span class=\"line\"><span class=\"comment\">    --&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">formats</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">format</span>&gt;</span>jar<span class=\"tag\">&lt;/<span class=\"name\">format</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">formats</span>&gt;</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">&lt;!-- 是否以 $&#123;project.build.finalName&#125;, 作为所有被打包文件的基目录, 默认 true --&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">includeBaseDirectory</span>&gt;</span>false<span class=\"tag\">&lt;/<span class=\"name\">includeBaseDirectory</span>&gt;</span></span><br><span class=\"line\">    <span class=\"comment\">&lt;!-- 显式定义 所有被打包文件的基目录 --&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">baseDirectory</span>&gt;</span>$&#123;project.build.finalName&#125;<span class=\"tag\">&lt;/<span class=\"name\">baseDirectory</span>&gt;</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">&lt;!-- 独立文件的收集 --&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">files</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">file</span>&gt;</span></span><br><span class=\"line\">            <span class=\"comment\">&lt;!-- 待收集的文件名 --&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">source</span>&gt;</span>LICENSE.txt<span class=\"tag\">&lt;/<span class=\"name\">source</span>&gt;</span></span><br><span class=\"line\">            <span class=\"comment\">&lt;!-- 收集到目标文件的相对路径 --&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">outputDirectory</span>&gt;</span>/<span class=\"tag\">&lt;/<span class=\"name\">outputDirectory</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">file</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">file</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">source</span>&gt;</span>NOTICE.txt<span class=\"tag\">&lt;/<span class=\"name\">source</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">outputDirectory</span>&gt;</span>/<span class=\"tag\">&lt;/<span class=\"name\">outputDirectory</span>&gt;</span></span><br><span class=\"line\">            <span class=\"comment\">&lt;!-- 将 $&#123;...&#125; 占位符 替换为实际的内容, 默认 false --&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">filtered</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">filtered</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">file</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">files</span>&gt;</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">&lt;!-- 目录的收集 --&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">fileSets</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">fileSet</span>&gt;</span></span><br><span class=\"line\">            <span class=\"comment\">&lt;!-- 目录名 --&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">directory</span>&gt;</span>$&#123;project.basedir&#125;/src/main/resources<span class=\"tag\">&lt;/<span class=\"name\">directory</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">outputDirectory</span>&gt;</span>/<span class=\"tag\">&lt;/<span class=\"name\">outputDirectory</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">fileSet</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">fileSet</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">directory</span>&gt;</span>$&#123;project.basedir&#125;/src/doc<span class=\"tag\">&lt;/<span class=\"name\">directory</span>&gt;</span></span><br><span class=\"line\">            <span class=\"comment\">&lt;!-- 是否使用默认的排除项, 排除范围包括版本控制程序产生的 metadata 等, 默认 true --&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">useDefaultExcludes</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">useDefaultExcludes</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">outputDirectory</span>&gt;</span>/doc<span class=\"tag\">&lt;/<span class=\"name\">outputDirectory</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">fileSet</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">fileSets</span>&gt;</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">&lt;!-- 依赖的收集 --&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">dependencySets</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">dependencySet</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">outputDirectory</span>&gt;</span>/lib<span class=\"tag\">&lt;/<span class=\"name\">outputDirectory</span>&gt;</span></span><br><span class=\"line\">            <span class=\"comment\">&lt;!-- 是否将本次构建过程中生成的 主构件 加入到依赖的收集中, 默认 true --&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">useProjectArtifact</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">useProjectArtifact</span>&gt;</span></span><br><span class=\"line\">            <span class=\"comment\">&lt;!-- 是否将本次构建过程中生成的 附加构件 也加入到依赖的收集中, 默认 false --&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">useProjectAttachments</span>&gt;</span>false<span class=\"tag\">&lt;/<span class=\"name\">useProjectAttachments</span>&gt;</span></span><br><span class=\"line\">            <span class=\"comment\">&lt;!-- 是否将依赖都解包为普通的目录文件放入 outputDirectory, 默认 false --&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">unpack</span>&gt;</span>false<span class=\"tag\">&lt;/<span class=\"name\">unpack</span>&gt;</span></span><br><span class=\"line\">            <span class=\"comment\">&lt;!--  --&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">scope</span>&gt;</span>runtime<span class=\"tag\">&lt;/<span class=\"name\">scope</span>&gt;</span></span><br><span class=\"line\">            <span class=\"comment\">&lt;!-- 是否让该 dependencySets 收集具有传递性, 即递归地将 dependency 间接依赖的 dependencies 都收集到打包文件中, 默认 true --&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">useTransitiveDependencies</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">useTransitiveDependencies</span>&gt;</span></span><br><span class=\"line\">            <span class=\"comment\">&lt;!-- </span></span><br><span class=\"line\"><span class=\"comment\">                includes/excludes 的格式:</span></span><br><span class=\"line\"><span class=\"comment\">                    groupId:artifactId:type:classifier</span></span><br><span class=\"line\"><span class=\"comment\">                    groupId:artifactId</span></span><br><span class=\"line\"><span class=\"comment\">                    groupId:artifactId:type:classifier:version</span></span><br><span class=\"line\"><span class=\"comment\">                支持使用 * 通配, * 可以完整匹配由多个 ':' 分割的 section;</span></span><br><span class=\"line\"><span class=\"comment\">            --&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">excludes</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">exclude</span>&gt;</span>org.apache.commons:commons-logging:jar<span class=\"tag\">&lt;/<span class=\"name\">exclude</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">exclude</span>&gt;</span>*:war<span class=\"tag\">&lt;/<span class=\"name\">exclude</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">excludes</span>&gt;</span></span><br><span class=\"line\">            <span class=\"comment\">&lt;!-- 是否让 includes/excludes 具有传递性, 即递归地让指定的 dependency 间接依赖的 dependencies 都被 include/exclude, 默认 false --&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">useTransitiveFiltering</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">useTransitiveFiltering</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">dependencySet</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">dependencySets</span>&gt;</span></span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">assembly</span>&gt;</span></span><br></pre></td></tr></table></figure></p>\n<p>&nbsp;</p>\n<h3 id=\"使用-assembly-的一些注意事项\"><a href=\"#使用-assembly-的一些注意事项\" class=\"headerlink\" title=\"使用 assembly 的一些注意事项\"></a><strong>使用 assembly 的一些注意事项</strong></h3><ul>\n<li>使用 assembly 打包成需要独立运行的 jar 时, 若无特殊需要显式定义 CLASSPATH,  则在核心配置文件中不应该定义 <code>baseDirectory</code>, 并将 <code>includeBaseDirectory</code> 置为 <code>false</code>;<br>因为 assembly 生成的 jar 包在 <code>/META-INF/MANIFEST.MF</code> 文件中默认不会定义 <code>Class-Path</code>, 即 CLASSPATH 默认就是 jar 中的基目录;</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># assembly 生成的 /META-INF/MANIFEST.MF</span></span><br><span class=\"line\">Manifest-Version: 1.0</span><br><span class=\"line\">Archiver-Version: Plexus Archiver</span><br><span class=\"line\">Created-By: 25.151-b12 (Oracle Corporation)</span><br></pre></td></tr></table></figure>\n<ul>\n<li>核心配置文件中的 <code>outputDirectory</code> 皆是以目标打包文件的根为相对路径的; 无论是否在路径最前面添加 <code>/</code>, 都不会有影响;</li>\n<li>assembly 2.2 之前的版本, 在涉及到一些复杂第三方依赖, 多个不同的 jar 包中含有同名的文件 (如 org.springframework) 时, 使用 assembly 打包时会遇到一个 bug:<br>assembly 只把第一次遇到的同名文件加入目标打包文件, 其后遇到的同名文件, 则被 skip 掉 ( 详见官方 issue: <a href=\"http://jira.codehaus.org/browse/MASSEMBLY-360\" target=\"_blank\" rel=\"noopener\">When using mulitple Spring dependencies, the files from META-INF (from the Spring jars) overwrite each other in an executable jar-with-dependencies</a> );<br>当然, 在这个 issue 当中, 触发此 bug 还有一个必要条件是将 dependencySet 中的 unpack 置为 true, 这样多个 spring artifact META-INF/ 中的 spring.handlers / spring.schemas / spring.tooling 等文件才会同名冲突;</li>\n</ul>\n<p>&nbsp;</p>\n<h3 id=\"关于-assembly-命令\"><a href=\"#关于-assembly-命令\" class=\"headerlink\" title=\"关于 assembly 命令\"></a><strong>关于 assembly 命令</strong></h3><p>除了上述以 配置文件 + maven core phase 回调的形式使用 assembly 插件之外, assembly 插件的 goals 也可以命令的形式执行:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mvn clean assembly:single</span><br><span class=\"line\">mvn assembly:<span class=\"built_in\">help</span></span><br></pre></td></tr></table></figure></p>\n<p>由于使用 assembly 命令的场景不多见, 此处不再详述, 详见 maven 官方介绍: <a href=\"http://maven.apache.org/plugins/maven-assembly-plugin/single-mojo.html\" target=\"_blank\" rel=\"noopener\">assembly:single</a></p>\n<p>&nbsp;</p>\n<h3 id=\"站内相关文章\"><a href=\"#站内相关文章\" class=\"headerlink\" title=\"站内相关文章\"></a><strong>站内相关文章</strong></h3><ul>\n<li><a href=\"\">在 Apache Spark 中使用 springframework 的一次实践</a></li>\n</ul>\n<p>&nbsp;</p>\n<h3 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a><strong>参考链接</strong></h3><ul>\n<li><a href=\"http://maven.apache.org/plugins/maven-assembly-plugin/assembly.html\" target=\"_blank\" rel=\"noopener\">Apache Maven Assembly Plugin: Assembly</a></li>\n<li><a href=\"https://maven.apache.org/plugins/maven-assembly-plugin/examples/single/filtering-some-distribution-files.html\" target=\"_blank\" rel=\"noopener\">Filtering Some Distribution Files</a></li>\n<li><a href=\"http://books.sonatype.com/mvnref-book/reference/assemblies-sect-controlling-contents.html\" target=\"_blank\" rel=\"noopener\">8.5. Controlling the Contents of an Assembly</a></li>\n<li><a href=\"https://maven.apache.org/plugins/maven-assembly-plugin/advanced-descriptor-topics.html\" target=\"_blank\" rel=\"noopener\">Quick Note on All includes and excludes Patterns</a></li>\n</ul>"},{"title":"git 忽略文件的特殊场景","date":"2016-07-14T15:17:24.000Z","_content":"\n> git 忽略文件, 其实有两种场景: 永久忽略 与 临时忽略;\n使用 `.gitignore` 在最刚开始时永久忽略指定文件是最常见的处理, 但是偶尔也会遇到特殊情况:\n1.一时疏忽, 将本该忽略的文件提交追踪了;\n2.需要临时忽略某指定文件, 一段时间后再继续追踪;\n本文将讨论以上两种情况下的 git 处理;\n\n<!--more-->\n\n------\n\n### **永远忽略已被跟踪的文件**\n适用场景:\n手误上传了不需要上传的文件, 希望斩草除根, 以后不让 git 追踪该文件;\n``` bash\n# first step\ngit rm --cached file_path/\n# second step\n更新 .gitignore 文件, exclude 目标文件\n```\n### **临时忽略已被跟踪的文件**\n适用场景:\n目标文件庞大, 每次修改保存时, git 计算文件的变化并更新 working directory, 触发磁盘IO瓶颈;\n所以需要临时忽略文件, 待修改完成 commit 时恢复跟踪;\n``` bash\n# first step\ngit update-index --assume-unchanged file_path/\n# second step\n编辑文件...\n# third step\ngit update-index --no-assume-unchanged file_path/\n```\n### **参考链接**\n- [git忽略已经被提交的文件](https://segmentfault.com/q/1010000000430426)\n\n","source":"_posts/tools-git--git忽略文件的特殊场景.md","raw":"---\ntitle: git 忽略文件的特殊场景\ndate: 2016-07-14 23:17:24\ncategories:\n - tools\n - git\ntags:\n - tools:git\n---\n\n> git 忽略文件, 其实有两种场景: 永久忽略 与 临时忽略;\n使用 `.gitignore` 在最刚开始时永久忽略指定文件是最常见的处理, 但是偶尔也会遇到特殊情况:\n1.一时疏忽, 将本该忽略的文件提交追踪了;\n2.需要临时忽略某指定文件, 一段时间后再继续追踪;\n本文将讨论以上两种情况下的 git 处理;\n\n<!--more-->\n\n------\n\n### **永远忽略已被跟踪的文件**\n适用场景:\n手误上传了不需要上传的文件, 希望斩草除根, 以后不让 git 追踪该文件;\n``` bash\n# first step\ngit rm --cached file_path/\n# second step\n更新 .gitignore 文件, exclude 目标文件\n```\n### **临时忽略已被跟踪的文件**\n适用场景:\n目标文件庞大, 每次修改保存时, git 计算文件的变化并更新 working directory, 触发磁盘IO瓶颈;\n所以需要临时忽略文件, 待修改完成 commit 时恢复跟踪;\n``` bash\n# first step\ngit update-index --assume-unchanged file_path/\n# second step\n编辑文件...\n# third step\ngit update-index --no-assume-unchanged file_path/\n```\n### **参考链接**\n- [git忽略已经被提交的文件](https://segmentfault.com/q/1010000000430426)\n\n","slug":"tools-git--git忽略文件的特殊场景","published":1,"updated":"2018-02-12T10:51:43.855Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cje24mxud000tj1jxk3tcq6uo","content":"<blockquote>\n<p>git 忽略文件, 其实有两种场景: 永久忽略 与 临时忽略;<br>使用 <code>.gitignore</code> 在最刚开始时永久忽略指定文件是最常见的处理, 但是偶尔也会遇到特殊情况:<br>1.一时疏忽, 将本该忽略的文件提交追踪了;<br>2.需要临时忽略某指定文件, 一段时间后再继续追踪;<br>本文将讨论以上两种情况下的 git 处理;</p>\n</blockquote>\n<a id=\"more\"></a>\n<hr>\n<h3 id=\"永远忽略已被跟踪的文件\"><a href=\"#永远忽略已被跟踪的文件\" class=\"headerlink\" title=\"永远忽略已被跟踪的文件\"></a><strong>永远忽略已被跟踪的文件</strong></h3><p>适用场景:<br>手误上传了不需要上传的文件, 希望斩草除根, 以后不让 git 追踪该文件;<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># first step</span></span><br><span class=\"line\">git rm --cached file_path/</span><br><span class=\"line\"><span class=\"comment\"># second step</span></span><br><span class=\"line\">更新 .gitignore 文件, exclude 目标文件</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"临时忽略已被跟踪的文件\"><a href=\"#临时忽略已被跟踪的文件\" class=\"headerlink\" title=\"临时忽略已被跟踪的文件\"></a><strong>临时忽略已被跟踪的文件</strong></h3><p>适用场景:<br>目标文件庞大, 每次修改保存时, git 计算文件的变化并更新 working directory, 触发磁盘IO瓶颈;<br>所以需要临时忽略文件, 待修改完成 commit 时恢复跟踪;<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># first step</span></span><br><span class=\"line\">git update-index --assume-unchanged file_path/</span><br><span class=\"line\"><span class=\"comment\"># second step</span></span><br><span class=\"line\">编辑文件...</span><br><span class=\"line\"><span class=\"comment\"># third step</span></span><br><span class=\"line\">git update-index --no-assume-unchanged file_path/</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a><strong>参考链接</strong></h3><ul>\n<li><a href=\"https://segmentfault.com/q/1010000000430426\" target=\"_blank\" rel=\"noopener\">git忽略已经被提交的文件</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>git 忽略文件, 其实有两种场景: 永久忽略 与 临时忽略;<br>使用 <code>.gitignore</code> 在最刚开始时永久忽略指定文件是最常见的处理, 但是偶尔也会遇到特殊情况:<br>1.一时疏忽, 将本该忽略的文件提交追踪了;<br>2.需要临时忽略某指定文件, 一段时间后再继续追踪;<br>本文将讨论以上两种情况下的 git 处理;</p>\n</blockquote>","more":"<hr>\n<h3 id=\"永远忽略已被跟踪的文件\"><a href=\"#永远忽略已被跟踪的文件\" class=\"headerlink\" title=\"永远忽略已被跟踪的文件\"></a><strong>永远忽略已被跟踪的文件</strong></h3><p>适用场景:<br>手误上传了不需要上传的文件, 希望斩草除根, 以后不让 git 追踪该文件;<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># first step</span></span><br><span class=\"line\">git rm --cached file_path/</span><br><span class=\"line\"><span class=\"comment\"># second step</span></span><br><span class=\"line\">更新 .gitignore 文件, exclude 目标文件</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"临时忽略已被跟踪的文件\"><a href=\"#临时忽略已被跟踪的文件\" class=\"headerlink\" title=\"临时忽略已被跟踪的文件\"></a><strong>临时忽略已被跟踪的文件</strong></h3><p>适用场景:<br>目标文件庞大, 每次修改保存时, git 计算文件的变化并更新 working directory, 触发磁盘IO瓶颈;<br>所以需要临时忽略文件, 待修改完成 commit 时恢复跟踪;<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># first step</span></span><br><span class=\"line\">git update-index --assume-unchanged file_path/</span><br><span class=\"line\"><span class=\"comment\"># second step</span></span><br><span class=\"line\">编辑文件...</span><br><span class=\"line\"><span class=\"comment\"># third step</span></span><br><span class=\"line\">git update-index --no-assume-unchanged file_path/</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a><strong>参考链接</strong></h3><ul>\n<li><a href=\"https://segmentfault.com/q/1010000000430426\" target=\"_blank\" rel=\"noopener\">git忽略已经被提交的文件</a></li>\n</ul>"},{"title":"财富先锋 2017 年各股池成绩单","date":"2017-12-31T14:00:00.000Z","_content":"\n> 综合来看, 同花顺财富先锋 2017 年的几个股池系统的年度收益率还是比较令人满意的;\n'热点轮动', '股东增持' 两个股池系统的收益率达到了 200%, '支撑压力' 股池系统的收益率超过 150%;\n不过 '多头趋势' 股池系统的表现比较糟糕, 2017 年净收益为负;\n另外还有 '深一度' 股池系统的收益率未显示相关指标, 暂无法统计;\n各个股池系统 2017 年度收益率的指标, 反映出了各个选股策略在 2017 年 A 股市场上的成效; 以此为鉴, 2018 年的中国资本市场, 我们继续前行;\n\n<!--more-->\n\n------\n\n### **支撑压力**\n![2017 支撑压力 final review](https://raw.githubusercontent.com/zshell-zhang/static-content/master/finance/rcmd_diary/2017_recommend_review_%E6%94%AF%E6%92%91%E5%8E%8B%E5%8A%9B.png)\n\n### **热点轮动**\n![2017 热点轮动 final review](https://raw.githubusercontent.com/zshell-zhang/static-content/master/finance/rcmd_diary/2017_recommend_review_%E7%83%AD%E7%82%B9%E8%BD%AE%E5%8A%A8.png)\n\n### **股东增持**\n![2017 股东增持 final review](https://raw.githubusercontent.com/zshell-zhang/static-content/master/finance/rcmd_diary/2017_recommend_review_%E8%82%A1%E4%B8%9C%E5%A2%9E%E6%8C%81.png)\n\n### **多头趋势**\n![2017 多头趋势 final review](https://raw.githubusercontent.com/zshell-zhang/static-content/master/finance/rcmd_diary/2017_recommend_review_多头趋势.png)\n","source":"_posts/证券-财富先锋--财富先锋2017年各股池成绩单.md","raw":"---\ntitle: 财富先锋 2017 年各股池成绩单\ndate: 2017-12-31 22:00:00\ntags:\n  - 证券:财富先锋\ncategories:\n  - 证券\n  - 财富先锋\n---\n\n> 综合来看, 同花顺财富先锋 2017 年的几个股池系统的年度收益率还是比较令人满意的;\n'热点轮动', '股东增持' 两个股池系统的收益率达到了 200%, '支撑压力' 股池系统的收益率超过 150%;\n不过 '多头趋势' 股池系统的表现比较糟糕, 2017 年净收益为负;\n另外还有 '深一度' 股池系统的收益率未显示相关指标, 暂无法统计;\n各个股池系统 2017 年度收益率的指标, 反映出了各个选股策略在 2017 年 A 股市场上的成效; 以此为鉴, 2018 年的中国资本市场, 我们继续前行;\n\n<!--more-->\n\n------\n\n### **支撑压力**\n![2017 支撑压力 final review](https://raw.githubusercontent.com/zshell-zhang/static-content/master/finance/rcmd_diary/2017_recommend_review_%E6%94%AF%E6%92%91%E5%8E%8B%E5%8A%9B.png)\n\n### **热点轮动**\n![2017 热点轮动 final review](https://raw.githubusercontent.com/zshell-zhang/static-content/master/finance/rcmd_diary/2017_recommend_review_%E7%83%AD%E7%82%B9%E8%BD%AE%E5%8A%A8.png)\n\n### **股东增持**\n![2017 股东增持 final review](https://raw.githubusercontent.com/zshell-zhang/static-content/master/finance/rcmd_diary/2017_recommend_review_%E8%82%A1%E4%B8%9C%E5%A2%9E%E6%8C%81.png)\n\n### **多头趋势**\n![2017 多头趋势 final review](https://raw.githubusercontent.com/zshell-zhang/static-content/master/finance/rcmd_diary/2017_recommend_review_多头趋势.png)\n","slug":"证券-财富先锋--财富先锋2017年各股池成绩单","published":1,"updated":"2018-01-27T14:53:07.581Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cje24mxuf000wj1jxqu2fniv4","content":"<blockquote>\n<p>综合来看, 同花顺财富先锋 2017 年的几个股池系统的年度收益率还是比较令人满意的;<br>‘热点轮动’, ‘股东增持’ 两个股池系统的收益率达到了 200%, ‘支撑压力’ 股池系统的收益率超过 150%;<br>不过 ‘多头趋势’ 股池系统的表现比较糟糕, 2017 年净收益为负;<br>另外还有 ‘深一度’ 股池系统的收益率未显示相关指标, 暂无法统计;<br>各个股池系统 2017 年度收益率的指标, 反映出了各个选股策略在 2017 年 A 股市场上的成效; 以此为鉴, 2018 年的中国资本市场, 我们继续前行;</p>\n</blockquote>\n<a id=\"more\"></a>\n<hr>\n<h3 id=\"支撑压力\"><a href=\"#支撑压力\" class=\"headerlink\" title=\"支撑压力\"></a><strong>支撑压力</strong></h3><figure class=\"image-bubble\">\n                <div class=\"img-lightbox\">\n                    <div class=\"overlay\"></div>\n                    <img src=\"https://raw.githubusercontent.com/zshell-zhang/static-content/master/finance/rcmd_diary/2017_recommend_review_%E6%94%AF%E6%92%91%E5%8E%8B%E5%8A%9B.png\" alt=\"2017 支撑压力 final review\" title=\"\">\n                </div>\n                <div class=\"image-caption\">2017 支撑压力 final review</div>\n            </figure>\n<h3 id=\"热点轮动\"><a href=\"#热点轮动\" class=\"headerlink\" title=\"热点轮动\"></a><strong>热点轮动</strong></h3><figure class=\"image-bubble\">\n                <div class=\"img-lightbox\">\n                    <div class=\"overlay\"></div>\n                    <img src=\"https://raw.githubusercontent.com/zshell-zhang/static-content/master/finance/rcmd_diary/2017_recommend_review_%E7%83%AD%E7%82%B9%E8%BD%AE%E5%8A%A8.png\" alt=\"2017 热点轮动 final review\" title=\"\">\n                </div>\n                <div class=\"image-caption\">2017 热点轮动 final review</div>\n            </figure>\n<h3 id=\"股东增持\"><a href=\"#股东增持\" class=\"headerlink\" title=\"股东增持\"></a><strong>股东增持</strong></h3><figure class=\"image-bubble\">\n                <div class=\"img-lightbox\">\n                    <div class=\"overlay\"></div>\n                    <img src=\"https://raw.githubusercontent.com/zshell-zhang/static-content/master/finance/rcmd_diary/2017_recommend_review_%E8%82%A1%E4%B8%9C%E5%A2%9E%E6%8C%81.png\" alt=\"2017 股东增持 final review\" title=\"\">\n                </div>\n                <div class=\"image-caption\">2017 股东增持 final review</div>\n            </figure>\n<h3 id=\"多头趋势\"><a href=\"#多头趋势\" class=\"headerlink\" title=\"多头趋势\"></a><strong>多头趋势</strong></h3><figure class=\"image-bubble\">\n                <div class=\"img-lightbox\">\n                    <div class=\"overlay\"></div>\n                    <img src=\"https://raw.githubusercontent.com/zshell-zhang/static-content/master/finance/rcmd_diary/2017_recommend_review_多头趋势.png\" alt=\"2017 多头趋势 final review\" title=\"\">\n                </div>\n                <div class=\"image-caption\">2017 多头趋势 final review</div>\n            </figure>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>综合来看, 同花顺财富先锋 2017 年的几个股池系统的年度收益率还是比较令人满意的;<br>‘热点轮动’, ‘股东增持’ 两个股池系统的收益率达到了 200%, ‘支撑压力’ 股池系统的收益率超过 150%;<br>不过 ‘多头趋势’ 股池系统的表现比较糟糕, 2017 年净收益为负;<br>另外还有 ‘深一度’ 股池系统的收益率未显示相关指标, 暂无法统计;<br>各个股池系统 2017 年度收益率的指标, 反映出了各个选股策略在 2017 年 A 股市场上的成效; 以此为鉴, 2018 年的中国资本市场, 我们继续前行;</p>\n</blockquote>","more":"<hr>\n<h3 id=\"支撑压力\"><a href=\"#支撑压力\" class=\"headerlink\" title=\"支撑压力\"></a><strong>支撑压力</strong></h3><figure class=\"image-bubble\">\n                <div class=\"img-lightbox\">\n                    <div class=\"overlay\"></div>\n                    <img src=\"https://raw.githubusercontent.com/zshell-zhang/static-content/master/finance/rcmd_diary/2017_recommend_review_%E6%94%AF%E6%92%91%E5%8E%8B%E5%8A%9B.png\" alt=\"2017 支撑压力 final review\" title=\"\">\n                </div>\n                <div class=\"image-caption\">2017 支撑压力 final review</div>\n            </figure>\n<h3 id=\"热点轮动\"><a href=\"#热点轮动\" class=\"headerlink\" title=\"热点轮动\"></a><strong>热点轮动</strong></h3><figure class=\"image-bubble\">\n                <div class=\"img-lightbox\">\n                    <div class=\"overlay\"></div>\n                    <img src=\"https://raw.githubusercontent.com/zshell-zhang/static-content/master/finance/rcmd_diary/2017_recommend_review_%E7%83%AD%E7%82%B9%E8%BD%AE%E5%8A%A8.png\" alt=\"2017 热点轮动 final review\" title=\"\">\n                </div>\n                <div class=\"image-caption\">2017 热点轮动 final review</div>\n            </figure>\n<h3 id=\"股东增持\"><a href=\"#股东增持\" class=\"headerlink\" title=\"股东增持\"></a><strong>股东增持</strong></h3><figure class=\"image-bubble\">\n                <div class=\"img-lightbox\">\n                    <div class=\"overlay\"></div>\n                    <img src=\"https://raw.githubusercontent.com/zshell-zhang/static-content/master/finance/rcmd_diary/2017_recommend_review_%E8%82%A1%E4%B8%9C%E5%A2%9E%E6%8C%81.png\" alt=\"2017 股东增持 final review\" title=\"\">\n                </div>\n                <div class=\"image-caption\">2017 股东增持 final review</div>\n            </figure>\n<h3 id=\"多头趋势\"><a href=\"#多头趋势\" class=\"headerlink\" title=\"多头趋势\"></a><strong>多头趋势</strong></h3><figure class=\"image-bubble\">\n                <div class=\"img-lightbox\">\n                    <div class=\"overlay\"></div>\n                    <img src=\"https://raw.githubusercontent.com/zshell-zhang/static-content/master/finance/rcmd_diary/2017_recommend_review_多头趋势.png\" alt=\"2017 多头趋势 final review\" title=\"\">\n                </div>\n                <div class=\"image-caption\">2017 多头趋势 final review</div>\n            </figure>"},{"title":"bash 结束死循环的方法","date":"2017-11-04T16:00:00.000Z","_content":"\n> linux 中有很多实用的工具, 采用了这样一种工作方式:\n定时执行(1/s, 1/3s 等)一次指定逻辑, 当用户按下 ctrl + c 发出 SIGINT 信号时, 结束进程; 如果接收不到 SIGINT/SIGTERM 等信号, 进程则会一直执行下去;\n类似的工具包括 ioutil, jmap 等;\n本文整理了实现上述逻辑的一些典型方法;\n\n<!--more-->\n\n### **方法1: 监听命令返回值**\n根据 [GNU 相关规范](http://www.gnu.org/software/bash/manual/bashref.html#Exit-Status), 如果一个进程是由于响应信号 signal 而终止, 其返回码必须是 128 + signal_number;\n那么, 可以通过判断其返回码 $? 是否大于 128 而判断 COMMAND 是否响应了信号;\n```\nwhile [ 1 ]; do\n    COMMAND\n    test $? -gt 128 && break\ndone\n```\n更精确的, 如果只想判断 COMMAND 是否响应了 SIGINT 信号, 可以直接判断:\n```\n# SIGINT = 2, 128 + SIGINT = 130\ntest $? -eq 130 && break\n```\n特殊的情况下, COMMAND 忽略了 SIGINT 信号, 可以使用 -e 选项强制其响应 SIGINT 信号:\n```\nwhile [ 1 ]; do\n    COMMAND -e\n    test $? -gt 128 && break\ndone\n```\n\n### **方法2: 命令返回值短路**\n方法2 是方法1 的简化版本:\n```\nwhile [ 1 ]; do\n    COMMAND -e || break\ndone\n```\n其本质是监听 COMMAND 的返回值 $? 是否为 0, 如果是 0, 那么 break 中断命令就被短路了; 如果是非 0, 便会执行 break, 跳出死循环;\n这种方法巧妙得使用 || 逻辑运算符简化了代码, 但是有一个缺陷: 当 COMMAND 并非因为响应 ctrl + c 而是其他错误返回了非 0 的状态时, 循环也会结束;\n这是方法2 相比 方法1 略显不精准的地方;\n\n### **方法3: 使用 trap 捕获信号**\n\n```\n# 捕获到 SIGINT 即 exit 0 正常退出\ntrap \"exit 0\" SIGINT\nwhile [ 1 ]; do\n    COMMAND -e\ndone\n```\n\n### **方法4: 使用 ctrl + z 配合 SIGTERM 信号**\n当命令运行在前台, 使用 ctrl + z 挂起进程, 会得到以下输出:\n``` bash\n# ^Z\n[1]+  Stopped                 COMMAND\n\n# 1 是挂起进程的作业号(job number), kill [job_number] 会向该作业发送 SIGtERM 信号\nkill %1\n# 发送 SIGTERM 信号给最近一次被挂起的进程\nkill %%\n\n# 执行的结果\n[1]+ Terminated               COMMAND\n```\n\n### **方法5: 使用 -e 选项**\n使用 set -e, 开启命令返回码校验功能, 一旦 COMMAND 返回非 0, 立即结束进程;\n```\n#!/bin/bash\nset -e\nwhile [ 1 ]; do\n    COMMAND -e\ndone\n```\n或者作为 bash 的参数:\n```\n#!/bin/bash -e\nwhile [ 1 ]; do\n    COMMAND -e\ndone\n```\n\n\n### **参考链接**\n- [Terminating an infinite loop](https://unix.stackexchange.com/questions/42287/terminating-an-infinite-loop)\n- [3.7.5 Exit Status](http://www.gnu.org/software/bash/manual/bashref.html#Exit-Status)\n- [How to stop the loop bash script in terminal](https://unix.stackexchange.com/questions/48425/how-to-stop-the-loop-bash-script-in-terminal/48465#48465)\n- [Unix/Linux 脚本中 “set -e” 的作用](http://blog.csdn.net/todd911/article/details/9954961)\n\n","source":"_posts/linux-shell--bash结束死循环的方法.md","raw":"---\ntitle: bash 结束死循环的方法\ndate: 2017-11-05\ntags:\n  - linux:shell\ncategories:\n  - linux\n  - shell\n---\n\n> linux 中有很多实用的工具, 采用了这样一种工作方式:\n定时执行(1/s, 1/3s 等)一次指定逻辑, 当用户按下 ctrl + c 发出 SIGINT 信号时, 结束进程; 如果接收不到 SIGINT/SIGTERM 等信号, 进程则会一直执行下去;\n类似的工具包括 ioutil, jmap 等;\n本文整理了实现上述逻辑的一些典型方法;\n\n<!--more-->\n\n### **方法1: 监听命令返回值**\n根据 [GNU 相关规范](http://www.gnu.org/software/bash/manual/bashref.html#Exit-Status), 如果一个进程是由于响应信号 signal 而终止, 其返回码必须是 128 + signal_number;\n那么, 可以通过判断其返回码 $? 是否大于 128 而判断 COMMAND 是否响应了信号;\n```\nwhile [ 1 ]; do\n    COMMAND\n    test $? -gt 128 && break\ndone\n```\n更精确的, 如果只想判断 COMMAND 是否响应了 SIGINT 信号, 可以直接判断:\n```\n# SIGINT = 2, 128 + SIGINT = 130\ntest $? -eq 130 && break\n```\n特殊的情况下, COMMAND 忽略了 SIGINT 信号, 可以使用 -e 选项强制其响应 SIGINT 信号:\n```\nwhile [ 1 ]; do\n    COMMAND -e\n    test $? -gt 128 && break\ndone\n```\n\n### **方法2: 命令返回值短路**\n方法2 是方法1 的简化版本:\n```\nwhile [ 1 ]; do\n    COMMAND -e || break\ndone\n```\n其本质是监听 COMMAND 的返回值 $? 是否为 0, 如果是 0, 那么 break 中断命令就被短路了; 如果是非 0, 便会执行 break, 跳出死循环;\n这种方法巧妙得使用 || 逻辑运算符简化了代码, 但是有一个缺陷: 当 COMMAND 并非因为响应 ctrl + c 而是其他错误返回了非 0 的状态时, 循环也会结束;\n这是方法2 相比 方法1 略显不精准的地方;\n\n### **方法3: 使用 trap 捕获信号**\n\n```\n# 捕获到 SIGINT 即 exit 0 正常退出\ntrap \"exit 0\" SIGINT\nwhile [ 1 ]; do\n    COMMAND -e\ndone\n```\n\n### **方法4: 使用 ctrl + z 配合 SIGTERM 信号**\n当命令运行在前台, 使用 ctrl + z 挂起进程, 会得到以下输出:\n``` bash\n# ^Z\n[1]+  Stopped                 COMMAND\n\n# 1 是挂起进程的作业号(job number), kill [job_number] 会向该作业发送 SIGtERM 信号\nkill %1\n# 发送 SIGTERM 信号给最近一次被挂起的进程\nkill %%\n\n# 执行的结果\n[1]+ Terminated               COMMAND\n```\n\n### **方法5: 使用 -e 选项**\n使用 set -e, 开启命令返回码校验功能, 一旦 COMMAND 返回非 0, 立即结束进程;\n```\n#!/bin/bash\nset -e\nwhile [ 1 ]; do\n    COMMAND -e\ndone\n```\n或者作为 bash 的参数:\n```\n#!/bin/bash -e\nwhile [ 1 ]; do\n    COMMAND -e\ndone\n```\n\n\n### **参考链接**\n- [Terminating an infinite loop](https://unix.stackexchange.com/questions/42287/terminating-an-infinite-loop)\n- [3.7.5 Exit Status](http://www.gnu.org/software/bash/manual/bashref.html#Exit-Status)\n- [How to stop the loop bash script in terminal](https://unix.stackexchange.com/questions/48425/how-to-stop-the-loop-bash-script-in-terminal/48465#48465)\n- [Unix/Linux 脚本中 “set -e” 的作用](http://blog.csdn.net/todd911/article/details/9954961)\n\n","slug":"linux-shell--bash结束死循环的方法","published":1,"updated":"2018-01-02T15:41:21.515Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cje24mxuh0010j1jxxdhv0m8y","content":"<blockquote>\n<p>linux 中有很多实用的工具, 采用了这样一种工作方式:<br>定时执行(1/s, 1/3s 等)一次指定逻辑, 当用户按下 ctrl + c 发出 SIGINT 信号时, 结束进程; 如果接收不到 SIGINT/SIGTERM 等信号, 进程则会一直执行下去;<br>类似的工具包括 ioutil, jmap 等;<br>本文整理了实现上述逻辑的一些典型方法;</p>\n</blockquote>\n<a id=\"more\"></a>\n<h3 id=\"方法1-监听命令返回值\"><a href=\"#方法1-监听命令返回值\" class=\"headerlink\" title=\"方法1: 监听命令返回值\"></a><strong>方法1: 监听命令返回值</strong></h3><p>根据 <a href=\"http://www.gnu.org/software/bash/manual/bashref.html#Exit-Status\" target=\"_blank\" rel=\"noopener\">GNU 相关规范</a>, 如果一个进程是由于响应信号 signal 而终止, 其返回码必须是 128 + signal_number;<br>那么, 可以通过判断其返回码 $? 是否大于 128 而判断 COMMAND 是否响应了信号;<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">while [ 1 ]; do</span><br><span class=\"line\">    COMMAND</span><br><span class=\"line\">    test $? -gt 128 &amp;&amp; break</span><br><span class=\"line\">done</span><br></pre></td></tr></table></figure></p>\n<p>更精确的, 如果只想判断 COMMAND 是否响应了 SIGINT 信号, 可以直接判断:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># SIGINT = 2, 128 + SIGINT = 130</span><br><span class=\"line\">test $? -eq 130 &amp;&amp; break</span><br></pre></td></tr></table></figure></p>\n<p>特殊的情况下, COMMAND 忽略了 SIGINT 信号, 可以使用 -e 选项强制其响应 SIGINT 信号:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">while [ 1 ]; do</span><br><span class=\"line\">    COMMAND -e</span><br><span class=\"line\">    test $? -gt 128 &amp;&amp; break</span><br><span class=\"line\">done</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"方法2-命令返回值短路\"><a href=\"#方法2-命令返回值短路\" class=\"headerlink\" title=\"方法2: 命令返回值短路\"></a><strong>方法2: 命令返回值短路</strong></h3><p>方法2 是方法1 的简化版本:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">while [ 1 ]; do</span><br><span class=\"line\">    COMMAND -e || break</span><br><span class=\"line\">done</span><br></pre></td></tr></table></figure></p>\n<p>其本质是监听 COMMAND 的返回值 $? 是否为 0, 如果是 0, 那么 break 中断命令就被短路了; 如果是非 0, 便会执行 break, 跳出死循环;<br>这种方法巧妙得使用 || 逻辑运算符简化了代码, 但是有一个缺陷: 当 COMMAND 并非因为响应 ctrl + c 而是其他错误返回了非 0 的状态时, 循环也会结束;<br>这是方法2 相比 方法1 略显不精准的地方;</p>\n<h3 id=\"方法3-使用-trap-捕获信号\"><a href=\"#方法3-使用-trap-捕获信号\" class=\"headerlink\" title=\"方法3: 使用 trap 捕获信号\"></a><strong>方法3: 使用 trap 捕获信号</strong></h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 捕获到 SIGINT 即 exit 0 正常退出</span><br><span class=\"line\">trap &quot;exit 0&quot; SIGINT</span><br><span class=\"line\">while [ 1 ]; do</span><br><span class=\"line\">    COMMAND -e</span><br><span class=\"line\">done</span><br></pre></td></tr></table></figure>\n<h3 id=\"方法4-使用-ctrl-z-配合-SIGTERM-信号\"><a href=\"#方法4-使用-ctrl-z-配合-SIGTERM-信号\" class=\"headerlink\" title=\"方法4: 使用 ctrl + z 配合 SIGTERM 信号\"></a><strong>方法4: 使用 ctrl + z 配合 SIGTERM 信号</strong></h3><p>当命令运行在前台, 使用 ctrl + z 挂起进程, 会得到以下输出:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># ^Z</span></span><br><span class=\"line\">[1]+  Stopped                 COMMAND</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 1 是挂起进程的作业号(job number), kill [job_number] 会向该作业发送 SIGtERM 信号</span></span><br><span class=\"line\"><span class=\"built_in\">kill</span> %1</span><br><span class=\"line\"><span class=\"comment\"># 发送 SIGTERM 信号给最近一次被挂起的进程</span></span><br><span class=\"line\"><span class=\"built_in\">kill</span> %%</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 执行的结果</span></span><br><span class=\"line\">[1]+ Terminated               COMMAND</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"方法5-使用-e-选项\"><a href=\"#方法5-使用-e-选项\" class=\"headerlink\" title=\"方法5: 使用 -e 选项\"></a><strong>方法5: 使用 -e 选项</strong></h3><p>使用 set -e, 开启命令返回码校验功能, 一旦 COMMAND 返回非 0, 立即结束进程;<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#!/bin/bash</span><br><span class=\"line\">set -e</span><br><span class=\"line\">while [ 1 ]; do</span><br><span class=\"line\">    COMMAND -e</span><br><span class=\"line\">done</span><br></pre></td></tr></table></figure></p>\n<p>或者作为 bash 的参数:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#!/bin/bash -e</span><br><span class=\"line\">while [ 1 ]; do</span><br><span class=\"line\">    COMMAND -e</span><br><span class=\"line\">done</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a><strong>参考链接</strong></h3><ul>\n<li><a href=\"https://unix.stackexchange.com/questions/42287/terminating-an-infinite-loop\" target=\"_blank\" rel=\"noopener\">Terminating an infinite loop</a></li>\n<li><a href=\"http://www.gnu.org/software/bash/manual/bashref.html#Exit-Status\" target=\"_blank\" rel=\"noopener\">3.7.5 Exit Status</a></li>\n<li><a href=\"https://unix.stackexchange.com/questions/48425/how-to-stop-the-loop-bash-script-in-terminal/48465#48465\" target=\"_blank\" rel=\"noopener\">How to stop the loop bash script in terminal</a></li>\n<li><a href=\"http://blog.csdn.net/todd911/article/details/9954961\" target=\"_blank\" rel=\"noopener\">Unix/Linux 脚本中 “set -e” 的作用</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>linux 中有很多实用的工具, 采用了这样一种工作方式:<br>定时执行(1/s, 1/3s 等)一次指定逻辑, 当用户按下 ctrl + c 发出 SIGINT 信号时, 结束进程; 如果接收不到 SIGINT/SIGTERM 等信号, 进程则会一直执行下去;<br>类似的工具包括 ioutil, jmap 等;<br>本文整理了实现上述逻辑的一些典型方法;</p>\n</blockquote>","more":"<h3 id=\"方法1-监听命令返回值\"><a href=\"#方法1-监听命令返回值\" class=\"headerlink\" title=\"方法1: 监听命令返回值\"></a><strong>方法1: 监听命令返回值</strong></h3><p>根据 <a href=\"http://www.gnu.org/software/bash/manual/bashref.html#Exit-Status\" target=\"_blank\" rel=\"noopener\">GNU 相关规范</a>, 如果一个进程是由于响应信号 signal 而终止, 其返回码必须是 128 + signal_number;<br>那么, 可以通过判断其返回码 $? 是否大于 128 而判断 COMMAND 是否响应了信号;<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">while [ 1 ]; do</span><br><span class=\"line\">    COMMAND</span><br><span class=\"line\">    test $? -gt 128 &amp;&amp; break</span><br><span class=\"line\">done</span><br></pre></td></tr></table></figure></p>\n<p>更精确的, 如果只想判断 COMMAND 是否响应了 SIGINT 信号, 可以直接判断:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># SIGINT = 2, 128 + SIGINT = 130</span><br><span class=\"line\">test $? -eq 130 &amp;&amp; break</span><br></pre></td></tr></table></figure></p>\n<p>特殊的情况下, COMMAND 忽略了 SIGINT 信号, 可以使用 -e 选项强制其响应 SIGINT 信号:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">while [ 1 ]; do</span><br><span class=\"line\">    COMMAND -e</span><br><span class=\"line\">    test $? -gt 128 &amp;&amp; break</span><br><span class=\"line\">done</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"方法2-命令返回值短路\"><a href=\"#方法2-命令返回值短路\" class=\"headerlink\" title=\"方法2: 命令返回值短路\"></a><strong>方法2: 命令返回值短路</strong></h3><p>方法2 是方法1 的简化版本:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">while [ 1 ]; do</span><br><span class=\"line\">    COMMAND -e || break</span><br><span class=\"line\">done</span><br></pre></td></tr></table></figure></p>\n<p>其本质是监听 COMMAND 的返回值 $? 是否为 0, 如果是 0, 那么 break 中断命令就被短路了; 如果是非 0, 便会执行 break, 跳出死循环;<br>这种方法巧妙得使用 || 逻辑运算符简化了代码, 但是有一个缺陷: 当 COMMAND 并非因为响应 ctrl + c 而是其他错误返回了非 0 的状态时, 循环也会结束;<br>这是方法2 相比 方法1 略显不精准的地方;</p>\n<h3 id=\"方法3-使用-trap-捕获信号\"><a href=\"#方法3-使用-trap-捕获信号\" class=\"headerlink\" title=\"方法3: 使用 trap 捕获信号\"></a><strong>方法3: 使用 trap 捕获信号</strong></h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 捕获到 SIGINT 即 exit 0 正常退出</span><br><span class=\"line\">trap &quot;exit 0&quot; SIGINT</span><br><span class=\"line\">while [ 1 ]; do</span><br><span class=\"line\">    COMMAND -e</span><br><span class=\"line\">done</span><br></pre></td></tr></table></figure>\n<h3 id=\"方法4-使用-ctrl-z-配合-SIGTERM-信号\"><a href=\"#方法4-使用-ctrl-z-配合-SIGTERM-信号\" class=\"headerlink\" title=\"方法4: 使用 ctrl + z 配合 SIGTERM 信号\"></a><strong>方法4: 使用 ctrl + z 配合 SIGTERM 信号</strong></h3><p>当命令运行在前台, 使用 ctrl + z 挂起进程, 会得到以下输出:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># ^Z</span></span><br><span class=\"line\">[1]+  Stopped                 COMMAND</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 1 是挂起进程的作业号(job number), kill [job_number] 会向该作业发送 SIGtERM 信号</span></span><br><span class=\"line\"><span class=\"built_in\">kill</span> %1</span><br><span class=\"line\"><span class=\"comment\"># 发送 SIGTERM 信号给最近一次被挂起的进程</span></span><br><span class=\"line\"><span class=\"built_in\">kill</span> %%</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 执行的结果</span></span><br><span class=\"line\">[1]+ Terminated               COMMAND</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"方法5-使用-e-选项\"><a href=\"#方法5-使用-e-选项\" class=\"headerlink\" title=\"方法5: 使用 -e 选项\"></a><strong>方法5: 使用 -e 选项</strong></h3><p>使用 set -e, 开启命令返回码校验功能, 一旦 COMMAND 返回非 0, 立即结束进程;<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#!/bin/bash</span><br><span class=\"line\">set -e</span><br><span class=\"line\">while [ 1 ]; do</span><br><span class=\"line\">    COMMAND -e</span><br><span class=\"line\">done</span><br></pre></td></tr></table></figure></p>\n<p>或者作为 bash 的参数:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#!/bin/bash -e</span><br><span class=\"line\">while [ 1 ]; do</span><br><span class=\"line\">    COMMAND -e</span><br><span class=\"line\">done</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a><strong>参考链接</strong></h3><ul>\n<li><a href=\"https://unix.stackexchange.com/questions/42287/terminating-an-infinite-loop\" target=\"_blank\" rel=\"noopener\">Terminating an infinite loop</a></li>\n<li><a href=\"http://www.gnu.org/software/bash/manual/bashref.html#Exit-Status\" target=\"_blank\" rel=\"noopener\">3.7.5 Exit Status</a></li>\n<li><a href=\"https://unix.stackexchange.com/questions/48425/how-to-stop-the-loop-bash-script-in-terminal/48465#48465\" target=\"_blank\" rel=\"noopener\">How to stop the loop bash script in terminal</a></li>\n<li><a href=\"http://blog.csdn.net/todd911/article/details/9954961\" target=\"_blank\" rel=\"noopener\">Unix/Linux 脚本中 “set -e” 的作用</a></li>\n</ul>"},{"title":"一个 dev 的拙劣前端笔记: 使用 jQuery ajax 上传文件","date":"2018-02-03T13:48:08.000Z","_content":"\n> 从传统的刷新提交到 ajax 提交, 从间接的 iframe 刷新 ajax 提交到真正意义上的 ajax 提交, 关于前端文件上传的方法, 伴随着 web 技术与标准的演进, 不断推陈出新;\n本文整理了从传统方式到 ajax 方式上传文件的各种方法;\n\n<!--more-->\n\n------\n\n### **传统的上传文件方式**\nform 表单有三种可能的 MIME 编码类型: 默认的 `application/x-www-form-urlencoded`, 不对字符编码而保留原始信息的 `multipart/form-data`, 以及纯文本 `text/plain`;\n如果没有异步刷新的需求, 只需要将 form 表单的 enctype 属性设置为 `multipart/form-data`, 便可以二进制的方式提交表单内容, 以达到上传文件的目的:\n``` html\n<form id=\"form_id\" enctype=\"multipart/form-data\">  \n    <input type=\"text\" name=\"str\" />  \n    <input type=\"file\" name=\"fileAttach\" />  \n    <input type=\"submit\" value=\"upload\" />  \n</form> \n```\n关于 MIME 类型 `multipart/form-data` 的更多内容, 请参见: [一个 dev 的拙劣前端笔记: content-type 之 multipart/form-data 规范整理]();\n&nbsp;\n**下面来讨论如何使用 ajax 实现文件上传;**\n\n### **使用 jQuery ajaxFileUpload 插件实现文件上传**\najax 默认使用的 MIME 类型是 `application/x-www-form-urlencoded`, 这种方式只适用于传输普通字符串类型的数据; 由于在 HTML4 时代, 没有对 javascript 提供文件读取的接口, 使用 `document.getElementById('field_id').value` 也只能获得文件的 name, 并不能拿到文件的二进制数据; 所以, 想直接使用 ajax 无刷新提交表单是无法做到的;\n所以只能采用间接的方案, 比如基于 jQuery 拓展的 ajaxFileUpload 插件, 其代码逻辑大致如下: \n\n1. function createUploadIframe():\n   创建一个独立的 iframe, 并追加到 body 中;\n2. function createUploadForm(file_elem_id):\n   创建一个独立的 form, 设置 enctype 为 `multipart/form-data`;\n   根据 file_elem_id 找到页面里的目标 `<input type=\"file\" />` 对象, 使用 jQuery.clone 方法, 将新的克隆对象替换到目标对象的位置, 而将原目标对象追加到新建的 form 中(偷梁换柱);\n   最后将新创建的 form 追加到 body 中;\n3. function addOtherRequestsToForm(data, new_form):\n   将页面中目标表单的其他元素数据, 一并追加到新创建的 form 里;\n4. function ajaxFileUpload: \n   调用 createUploadForm 方法创建新 form;\n   调用 addOtherRequestsToForm 方法捎带除 file 之外的其余元素数据;\n   调用 createUploadIFrame 方法创建 iframe;\n   将新 form 的 target 属性设置为新创建 iframe 的 id, 以实现间接的无刷新;\n   submit 提交新 form;\n\n&nbsp;\najaxFileUpload 的实现逻辑并不复杂, 类似这样的插件在 github 上有各种各样的版本, 我选取了一个比较典型的实现: [carlcarl/AjaxFileUpload/ajaxfileupload.js](https://github.com/carlcarl/AjaxFileUpload/blob/master/ajaxfileupload.js);\n然后开发者在实际使用时需要调用的是 `jQuery.ajaxFileUpload` 方法, 设置一些参数与回调方法:\n``` javascript\nfunction ajax_submit(field_id) {\n    $.ajaxFileUpload({\n        fileElementId: field_id,    // <input id=\"field_id\" type=\"file\">, 对应元素的 id\n        data: fetch_form_data('form_id'),   // 捎带其余元素的数据\n        url: '/xxx/yyy/upload'\n        type: 'post',\n        dataType: 'json',\n        secureuri: false,   //是否启用安全提交，默认为false\n        async : true,   //是否是异步\n        success: function(data) {\n            if (data['status'] == 0) {\n                window.location.reload();\n                alert(\"提交成功\");\n            } else {\n                window.location.reload();\n                alert(\"提交失败:\" + data['message']);\n            }\n        },\n        error: function(data, status, e) {\n            window.location.reload();\n            alert(\"提交失败:\" + data['message']);\n        }\n    });\n}\n// 将给定的表单数据转为对象\nfunction fetch_form_data(form_id) {\n    var params = $('#' + form_id).serializeArray();  \n    var values = {};  \n    for( x in params ) {  \n        values[params[x].name] = params[x].value;  \n    }  \n    return values\n}\n```\n抛开 iframe 的性能影响不谈, 看起来这样的 api 还是相当友好的, 与 jQuery.ajax 同样方便, 还解决了 ajax 不能传输二进制流的问题;\n另外, 由于这种方式真正提交的表单完全是 javascript 创建出来的, 页面上自己写的那个表单, 只作为数据 clone 的载体, 所以只需要确保表单和其中的 file input 元素有自己的 id, 最后提交按钮的 onclick 事件指向了目标方法即可;\n``` html\n<form id=\"form_id\">\n    <input type=\"text\" name=\"str\" />\n    <input id=\"file_attach\" type=\"file\" name=\"fileAttach\" />\n    <input type=\"button\" onclick=\"ajax_submit('file_attach')\"  value=\"upload\" />\n</form>\n```\n\n### **使用 jQuery ajax 结合 HTML5 API 实现文件上传**\n使用 ajaxFileUplaod 插件, 无论怎么优化改造, 其需要使用 iframe 作间接无刷新的逻辑是没法绕开的; 而使用 iframe 必然会带来额外资源的消耗, 如果有更原生直接的解决方案, 我们一定乐于在项目中取代 ajaxFileUpload;\n于是, 在 HTML5 时代, 出现了一个新的接口: `FormData`, 它给出了完美的解决方案;\n``` javascript\nvar form_content = new FormData(document.getElementById(\"form_id\"));\n```\n这行代码便拿到了目标表单对象的所有信息; 我们只需要确保表单的 enctype 属性为 `multipart/form-data`, 通过该接口获得的 FormData 对象, 便是完整的二进制序列化信息:\n``` html\n<form id=\"form_id\" enctype=\"multipart/form-data\">\n    <input type=\"text\" name=\"str\" />\n    <input type=\"file\" name=\"fileAttach\" />\n    <input type=\"button\" onclick=\"upload_file()\"  value=\"upload\" />\n</form>\n```\n这样, 一个 onclick 事件触发 upload_file 方法, 使用原生的 jQuery ajax 就实现了上传文件的功能了, 同时表单内的其他字符串数据, 也一并以 multi part 的形式上传上去了;\n对应的 javascript upload_file 方法如下: \n``` javascript\nfunction uplaod_file() {\n    var form_content = new FormData(document.getElementById('form_id'));\n    $.ajax({\n        type: 'POST',\n        url: '/xxx/yyy/upload',\n        data: form_content,\n        processData: false,     // 阻止默认的 application/x-www-form-urlencoded 对象处理方法\n        contentType: false,     // 与 processData 保持一直, 不使用默认的 application/x-www-form-urlencoded\n        success: function (data) {\n            if (data['status'] == 0) {\n                window.location.reload();\n                alert(\"提交成功\");\n            } else {\n                window.location.reload();\n                alert(\"提交失败:\" + data['message']);\n            }\n        },\n        fail: function (data) {\n            window.location.reload();\n            alert(\"提交失败:\" + data['message']);\n        }\n    });\n}\n```\n以上代码需要注意的是:\n`processData` 参数默认为 true, 即将 data 转为 url 键值对形式, 这里已经是序列化后的二进制数据, 不需要再次处理,  所以应主动设置其为 false;\n同时, `contentType` 默认为 `application/x-www-form-urlencoded`, 这里不应该使用默认值;\n关于 jQuery ajax 方法, 更多的内容请参见: [jQuery ajax 阅读与理解]();\n&nbsp;\n这便是 HTML5 时代下,  ajax 异步上传文件的最佳实践;\n\n### **站内相关文章**\n- [一个 dev 的拙劣前端笔记: content-type 之 multipart/form-data 规范整理]()\n- [jQuery ajax 阅读与理解]()\n\n### **参考链接**\n- [jquery Ajax提交表单(使用jquery Ajax上传附件)](http://blog.csdn.net/qq_33556185/article/details/51086114)\n- [JQuery的ajaxFileUpload的使用](https://www.cnblogs.com/zhanghaoliang/p/6513964.html)\n- [carlcarl/AjaxFileUpload/ajaxfileupload.js](https://github.com/carlcarl/AjaxFileUpload/blob/master/ajaxfileupload.js)\n- [jquery插件--ajaxfileupload.js上传文件原理分析](http://blog.csdn.net/it_man/article/details/43800957)\n\n","source":"_posts/web--一个dev的拙劣前端笔记_使用jQuery_ajax上传文件.md","raw":"---\ntitle: '一个 dev 的拙劣前端笔记: 使用 jQuery ajax 上传文件'\ndate: 2018-02-03 21:48:08\ncategories:\n - web\ntags:\n - ajax\n - jQuery\n - 文件上传\n---\n\n> 从传统的刷新提交到 ajax 提交, 从间接的 iframe 刷新 ajax 提交到真正意义上的 ajax 提交, 关于前端文件上传的方法, 伴随着 web 技术与标准的演进, 不断推陈出新;\n本文整理了从传统方式到 ajax 方式上传文件的各种方法;\n\n<!--more-->\n\n------\n\n### **传统的上传文件方式**\nform 表单有三种可能的 MIME 编码类型: 默认的 `application/x-www-form-urlencoded`, 不对字符编码而保留原始信息的 `multipart/form-data`, 以及纯文本 `text/plain`;\n如果没有异步刷新的需求, 只需要将 form 表单的 enctype 属性设置为 `multipart/form-data`, 便可以二进制的方式提交表单内容, 以达到上传文件的目的:\n``` html\n<form id=\"form_id\" enctype=\"multipart/form-data\">  \n    <input type=\"text\" name=\"str\" />  \n    <input type=\"file\" name=\"fileAttach\" />  \n    <input type=\"submit\" value=\"upload\" />  \n</form> \n```\n关于 MIME 类型 `multipart/form-data` 的更多内容, 请参见: [一个 dev 的拙劣前端笔记: content-type 之 multipart/form-data 规范整理]();\n&nbsp;\n**下面来讨论如何使用 ajax 实现文件上传;**\n\n### **使用 jQuery ajaxFileUpload 插件实现文件上传**\najax 默认使用的 MIME 类型是 `application/x-www-form-urlencoded`, 这种方式只适用于传输普通字符串类型的数据; 由于在 HTML4 时代, 没有对 javascript 提供文件读取的接口, 使用 `document.getElementById('field_id').value` 也只能获得文件的 name, 并不能拿到文件的二进制数据; 所以, 想直接使用 ajax 无刷新提交表单是无法做到的;\n所以只能采用间接的方案, 比如基于 jQuery 拓展的 ajaxFileUpload 插件, 其代码逻辑大致如下: \n\n1. function createUploadIframe():\n   创建一个独立的 iframe, 并追加到 body 中;\n2. function createUploadForm(file_elem_id):\n   创建一个独立的 form, 设置 enctype 为 `multipart/form-data`;\n   根据 file_elem_id 找到页面里的目标 `<input type=\"file\" />` 对象, 使用 jQuery.clone 方法, 将新的克隆对象替换到目标对象的位置, 而将原目标对象追加到新建的 form 中(偷梁换柱);\n   最后将新创建的 form 追加到 body 中;\n3. function addOtherRequestsToForm(data, new_form):\n   将页面中目标表单的其他元素数据, 一并追加到新创建的 form 里;\n4. function ajaxFileUpload: \n   调用 createUploadForm 方法创建新 form;\n   调用 addOtherRequestsToForm 方法捎带除 file 之外的其余元素数据;\n   调用 createUploadIFrame 方法创建 iframe;\n   将新 form 的 target 属性设置为新创建 iframe 的 id, 以实现间接的无刷新;\n   submit 提交新 form;\n\n&nbsp;\najaxFileUpload 的实现逻辑并不复杂, 类似这样的插件在 github 上有各种各样的版本, 我选取了一个比较典型的实现: [carlcarl/AjaxFileUpload/ajaxfileupload.js](https://github.com/carlcarl/AjaxFileUpload/blob/master/ajaxfileupload.js);\n然后开发者在实际使用时需要调用的是 `jQuery.ajaxFileUpload` 方法, 设置一些参数与回调方法:\n``` javascript\nfunction ajax_submit(field_id) {\n    $.ajaxFileUpload({\n        fileElementId: field_id,    // <input id=\"field_id\" type=\"file\">, 对应元素的 id\n        data: fetch_form_data('form_id'),   // 捎带其余元素的数据\n        url: '/xxx/yyy/upload'\n        type: 'post',\n        dataType: 'json',\n        secureuri: false,   //是否启用安全提交，默认为false\n        async : true,   //是否是异步\n        success: function(data) {\n            if (data['status'] == 0) {\n                window.location.reload();\n                alert(\"提交成功\");\n            } else {\n                window.location.reload();\n                alert(\"提交失败:\" + data['message']);\n            }\n        },\n        error: function(data, status, e) {\n            window.location.reload();\n            alert(\"提交失败:\" + data['message']);\n        }\n    });\n}\n// 将给定的表单数据转为对象\nfunction fetch_form_data(form_id) {\n    var params = $('#' + form_id).serializeArray();  \n    var values = {};  \n    for( x in params ) {  \n        values[params[x].name] = params[x].value;  \n    }  \n    return values\n}\n```\n抛开 iframe 的性能影响不谈, 看起来这样的 api 还是相当友好的, 与 jQuery.ajax 同样方便, 还解决了 ajax 不能传输二进制流的问题;\n另外, 由于这种方式真正提交的表单完全是 javascript 创建出来的, 页面上自己写的那个表单, 只作为数据 clone 的载体, 所以只需要确保表单和其中的 file input 元素有自己的 id, 最后提交按钮的 onclick 事件指向了目标方法即可;\n``` html\n<form id=\"form_id\">\n    <input type=\"text\" name=\"str\" />\n    <input id=\"file_attach\" type=\"file\" name=\"fileAttach\" />\n    <input type=\"button\" onclick=\"ajax_submit('file_attach')\"  value=\"upload\" />\n</form>\n```\n\n### **使用 jQuery ajax 结合 HTML5 API 实现文件上传**\n使用 ajaxFileUplaod 插件, 无论怎么优化改造, 其需要使用 iframe 作间接无刷新的逻辑是没法绕开的; 而使用 iframe 必然会带来额外资源的消耗, 如果有更原生直接的解决方案, 我们一定乐于在项目中取代 ajaxFileUpload;\n于是, 在 HTML5 时代, 出现了一个新的接口: `FormData`, 它给出了完美的解决方案;\n``` javascript\nvar form_content = new FormData(document.getElementById(\"form_id\"));\n```\n这行代码便拿到了目标表单对象的所有信息; 我们只需要确保表单的 enctype 属性为 `multipart/form-data`, 通过该接口获得的 FormData 对象, 便是完整的二进制序列化信息:\n``` html\n<form id=\"form_id\" enctype=\"multipart/form-data\">\n    <input type=\"text\" name=\"str\" />\n    <input type=\"file\" name=\"fileAttach\" />\n    <input type=\"button\" onclick=\"upload_file()\"  value=\"upload\" />\n</form>\n```\n这样, 一个 onclick 事件触发 upload_file 方法, 使用原生的 jQuery ajax 就实现了上传文件的功能了, 同时表单内的其他字符串数据, 也一并以 multi part 的形式上传上去了;\n对应的 javascript upload_file 方法如下: \n``` javascript\nfunction uplaod_file() {\n    var form_content = new FormData(document.getElementById('form_id'));\n    $.ajax({\n        type: 'POST',\n        url: '/xxx/yyy/upload',\n        data: form_content,\n        processData: false,     // 阻止默认的 application/x-www-form-urlencoded 对象处理方法\n        contentType: false,     // 与 processData 保持一直, 不使用默认的 application/x-www-form-urlencoded\n        success: function (data) {\n            if (data['status'] == 0) {\n                window.location.reload();\n                alert(\"提交成功\");\n            } else {\n                window.location.reload();\n                alert(\"提交失败:\" + data['message']);\n            }\n        },\n        fail: function (data) {\n            window.location.reload();\n            alert(\"提交失败:\" + data['message']);\n        }\n    });\n}\n```\n以上代码需要注意的是:\n`processData` 参数默认为 true, 即将 data 转为 url 键值对形式, 这里已经是序列化后的二进制数据, 不需要再次处理,  所以应主动设置其为 false;\n同时, `contentType` 默认为 `application/x-www-form-urlencoded`, 这里不应该使用默认值;\n关于 jQuery ajax 方法, 更多的内容请参见: [jQuery ajax 阅读与理解]();\n&nbsp;\n这便是 HTML5 时代下,  ajax 异步上传文件的最佳实践;\n\n### **站内相关文章**\n- [一个 dev 的拙劣前端笔记: content-type 之 multipart/form-data 规范整理]()\n- [jQuery ajax 阅读与理解]()\n\n### **参考链接**\n- [jquery Ajax提交表单(使用jquery Ajax上传附件)](http://blog.csdn.net/qq_33556185/article/details/51086114)\n- [JQuery的ajaxFileUpload的使用](https://www.cnblogs.com/zhanghaoliang/p/6513964.html)\n- [carlcarl/AjaxFileUpload/ajaxfileupload.js](https://github.com/carlcarl/AjaxFileUpload/blob/master/ajaxfileupload.js)\n- [jquery插件--ajaxfileupload.js上传文件原理分析](http://blog.csdn.net/it_man/article/details/43800957)\n\n","slug":"web--一个dev的拙劣前端笔记_使用jQuery_ajax上传文件","published":1,"updated":"2018-02-07T15:43:29.215Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cje24mxuj0014j1jx1g8s78go","content":"<blockquote>\n<p>从传统的刷新提交到 ajax 提交, 从间接的 iframe 刷新 ajax 提交到真正意义上的 ajax 提交, 关于前端文件上传的方法, 伴随着 web 技术与标准的演进, 不断推陈出新;<br>本文整理了从传统方式到 ajax 方式上传文件的各种方法;</p>\n</blockquote>\n<a id=\"more\"></a>\n<hr>\n<h3 id=\"传统的上传文件方式\"><a href=\"#传统的上传文件方式\" class=\"headerlink\" title=\"传统的上传文件方式\"></a><strong>传统的上传文件方式</strong></h3><p>form 表单有三种可能的 MIME 编码类型: 默认的 <code>application/x-www-form-urlencoded</code>, 不对字符编码而保留原始信息的 <code>multipart/form-data</code>, 以及纯文本 <code>text/plain</code>;<br>如果没有异步刷新的需求, 只需要将 form 表单的 enctype 属性设置为 <code>multipart/form-data</code>, 便可以二进制的方式提交表单内容, 以达到上传文件的目的:<br><figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">form</span> <span class=\"attr\">id</span>=<span class=\"string\">\"form_id\"</span> <span class=\"attr\">enctype</span>=<span class=\"string\">\"multipart/form-data\"</span>&gt;</span>  </span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"text\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"str\"</span> /&gt;</span>  </span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"file\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"fileAttach\"</span> /&gt;</span>  </span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"submit\"</span> <span class=\"attr\">value</span>=<span class=\"string\">\"upload\"</span> /&gt;</span>  </span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">form</span>&gt;</span></span><br></pre></td></tr></table></figure></p>\n<p>关于 MIME 类型 <code>multipart/form-data</code> 的更多内容, 请参见: <a href=\"\">一个 dev 的拙劣前端笔记: content-type 之 multipart/form-data 规范整理</a>;<br>&nbsp;<br><strong>下面来讨论如何使用 ajax 实现文件上传;</strong></p>\n<h3 id=\"使用-jQuery-ajaxFileUpload-插件实现文件上传\"><a href=\"#使用-jQuery-ajaxFileUpload-插件实现文件上传\" class=\"headerlink\" title=\"使用 jQuery ajaxFileUpload 插件实现文件上传\"></a><strong>使用 jQuery ajaxFileUpload 插件实现文件上传</strong></h3><p>ajax 默认使用的 MIME 类型是 <code>application/x-www-form-urlencoded</code>, 这种方式只适用于传输普通字符串类型的数据; 由于在 HTML4 时代, 没有对 javascript 提供文件读取的接口, 使用 <code>document.getElementById(&#39;field_id&#39;).value</code> 也只能获得文件的 name, 并不能拿到文件的二进制数据; 所以, 想直接使用 ajax 无刷新提交表单是无法做到的;<br>所以只能采用间接的方案, 比如基于 jQuery 拓展的 ajaxFileUpload 插件, 其代码逻辑大致如下: </p>\n<ol>\n<li>function createUploadIframe():<br>创建一个独立的 iframe, 并追加到 body 中;</li>\n<li>function createUploadForm(file_elem_id):<br>创建一个独立的 form, 设置 enctype 为 <code>multipart/form-data</code>;<br>根据 file_elem_id 找到页面里的目标 <code>&lt;input type=&quot;file&quot; /&gt;</code> 对象, 使用 jQuery.clone 方法, 将新的克隆对象替换到目标对象的位置, 而将原目标对象追加到新建的 form 中(偷梁换柱);<br>最后将新创建的 form 追加到 body 中;</li>\n<li>function addOtherRequestsToForm(data, new_form):<br>将页面中目标表单的其他元素数据, 一并追加到新创建的 form 里;</li>\n<li>function ajaxFileUpload:<br>调用 createUploadForm 方法创建新 form;<br>调用 addOtherRequestsToForm 方法捎带除 file 之外的其余元素数据;<br>调用 createUploadIFrame 方法创建 iframe;<br>将新 form 的 target 属性设置为新创建 iframe 的 id, 以实现间接的无刷新;<br>submit 提交新 form;</li>\n</ol>\n<p>&nbsp;<br>ajaxFileUpload 的实现逻辑并不复杂, 类似这样的插件在 github 上有各种各样的版本, 我选取了一个比较典型的实现: <a href=\"https://github.com/carlcarl/AjaxFileUpload/blob/master/ajaxfileupload.js\" target=\"_blank\" rel=\"noopener\">carlcarl/AjaxFileUpload/ajaxfileupload.js</a>;<br>然后开发者在实际使用时需要调用的是 <code>jQuery.ajaxFileUpload</code> 方法, 设置一些参数与回调方法:<br><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">ajax_submit</span>(<span class=\"params\">field_id</span>) </span>&#123;</span><br><span class=\"line\">    $.ajaxFileUpload(&#123;</span><br><span class=\"line\">        fileElementId: field_id,    <span class=\"comment\">// &lt;input id=\"field_id\" type=\"file\"&gt;, 对应元素的 id</span></span><br><span class=\"line\">        data: fetch_form_data(<span class=\"string\">'form_id'</span>),   <span class=\"comment\">// 捎带其余元素的数据</span></span><br><span class=\"line\">        url: <span class=\"string\">'/xxx/yyy/upload'</span></span><br><span class=\"line\">        type: <span class=\"string\">'post'</span>,</span><br><span class=\"line\">        dataType: <span class=\"string\">'json'</span>,</span><br><span class=\"line\">        secureuri: <span class=\"literal\">false</span>,   <span class=\"comment\">//是否启用安全提交，默认为false</span></span><br><span class=\"line\">        <span class=\"keyword\">async</span> : <span class=\"literal\">true</span>,   <span class=\"comment\">//是否是异步</span></span><br><span class=\"line\">        success: <span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\">data</span>) </span>&#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (data[<span class=\"string\">'status'</span>] == <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">                <span class=\"built_in\">window</span>.location.reload();</span><br><span class=\"line\">                alert(<span class=\"string\">\"提交成功\"</span>);</span><br><span class=\"line\">            &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                <span class=\"built_in\">window</span>.location.reload();</span><br><span class=\"line\">                alert(<span class=\"string\">\"提交失败:\"</span> + data[<span class=\"string\">'message'</span>]);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        error: <span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\">data, status, e</span>) </span>&#123;</span><br><span class=\"line\">            <span class=\"built_in\">window</span>.location.reload();</span><br><span class=\"line\">            alert(<span class=\"string\">\"提交失败:\"</span> + data[<span class=\"string\">'message'</span>]);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">// 将给定的表单数据转为对象</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">fetch_form_data</span>(<span class=\"params\">form_id</span>) </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">var</span> params = $(<span class=\"string\">'#'</span> + form_id).serializeArray();  </span><br><span class=\"line\">    <span class=\"keyword\">var</span> values = &#123;&#125;;  </span><br><span class=\"line\">    <span class=\"keyword\">for</span>( x <span class=\"keyword\">in</span> params ) &#123;  </span><br><span class=\"line\">        values[params[x].name] = params[x].value;  </span><br><span class=\"line\">    &#125;  </span><br><span class=\"line\">    <span class=\"keyword\">return</span> values</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>抛开 iframe 的性能影响不谈, 看起来这样的 api 还是相当友好的, 与 jQuery.ajax 同样方便, 还解决了 ajax 不能传输二进制流的问题;<br>另外, 由于这种方式真正提交的表单完全是 javascript 创建出来的, 页面上自己写的那个表单, 只作为数据 clone 的载体, 所以只需要确保表单和其中的 file input 元素有自己的 id, 最后提交按钮的 onclick 事件指向了目标方法即可;<br><figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">form</span> <span class=\"attr\">id</span>=<span class=\"string\">\"form_id\"</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"text\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"str\"</span> /&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">id</span>=<span class=\"string\">\"file_attach\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"file\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"fileAttach\"</span> /&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"button\"</span> <span class=\"attr\">onclick</span>=<span class=\"string\">\"ajax_submit('file_attach')\"</span>  <span class=\"attr\">value</span>=<span class=\"string\">\"upload\"</span> /&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">form</span>&gt;</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"使用-jQuery-ajax-结合-HTML5-API-实现文件上传\"><a href=\"#使用-jQuery-ajax-结合-HTML5-API-实现文件上传\" class=\"headerlink\" title=\"使用 jQuery ajax 结合 HTML5 API 实现文件上传\"></a><strong>使用 jQuery ajax 结合 HTML5 API 实现文件上传</strong></h3><p>使用 ajaxFileUplaod 插件, 无论怎么优化改造, 其需要使用 iframe 作间接无刷新的逻辑是没法绕开的; 而使用 iframe 必然会带来额外资源的消耗, 如果有更原生直接的解决方案, 我们一定乐于在项目中取代 ajaxFileUpload;<br>于是, 在 HTML5 时代, 出现了一个新的接口: <code>FormData</code>, 它给出了完美的解决方案;<br><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> form_content = <span class=\"keyword\">new</span> FormData(<span class=\"built_in\">document</span>.getElementById(<span class=\"string\">\"form_id\"</span>));</span><br></pre></td></tr></table></figure></p>\n<p>这行代码便拿到了目标表单对象的所有信息; 我们只需要确保表单的 enctype 属性为 <code>multipart/form-data</code>, 通过该接口获得的 FormData 对象, 便是完整的二进制序列化信息:<br><figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">form</span> <span class=\"attr\">id</span>=<span class=\"string\">\"form_id\"</span> <span class=\"attr\">enctype</span>=<span class=\"string\">\"multipart/form-data\"</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"text\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"str\"</span> /&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"file\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"fileAttach\"</span> /&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"button\"</span> <span class=\"attr\">onclick</span>=<span class=\"string\">\"upload_file()\"</span>  <span class=\"attr\">value</span>=<span class=\"string\">\"upload\"</span> /&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">form</span>&gt;</span></span><br></pre></td></tr></table></figure></p>\n<p>这样, 一个 onclick 事件触发 upload_file 方法, 使用原生的 jQuery ajax 就实现了上传文件的功能了, 同时表单内的其他字符串数据, 也一并以 multi part 的形式上传上去了;<br>对应的 javascript upload_file 方法如下:<br><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">uplaod_file</span>(<span class=\"params\"></span>) </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">var</span> form_content = <span class=\"keyword\">new</span> FormData(<span class=\"built_in\">document</span>.getElementById(<span class=\"string\">'form_id'</span>));</span><br><span class=\"line\">    $.ajax(&#123;</span><br><span class=\"line\">        type: <span class=\"string\">'POST'</span>,</span><br><span class=\"line\">        url: <span class=\"string\">'/xxx/yyy/upload'</span>,</span><br><span class=\"line\">        data: form_content,</span><br><span class=\"line\">        processData: <span class=\"literal\">false</span>,     <span class=\"comment\">// 阻止默认的 application/x-www-form-urlencoded 对象处理方法</span></span><br><span class=\"line\">        contentType: <span class=\"literal\">false</span>,     <span class=\"comment\">// 与 processData 保持一直, 不使用默认的 application/x-www-form-urlencoded</span></span><br><span class=\"line\">        success: <span class=\"function\"><span class=\"keyword\">function</span> (<span class=\"params\">data</span>) </span>&#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (data[<span class=\"string\">'status'</span>] == <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">                <span class=\"built_in\">window</span>.location.reload();</span><br><span class=\"line\">                alert(<span class=\"string\">\"提交成功\"</span>);</span><br><span class=\"line\">            &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                <span class=\"built_in\">window</span>.location.reload();</span><br><span class=\"line\">                alert(<span class=\"string\">\"提交失败:\"</span> + data[<span class=\"string\">'message'</span>]);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        fail: <span class=\"function\"><span class=\"keyword\">function</span> (<span class=\"params\">data</span>) </span>&#123;</span><br><span class=\"line\">            <span class=\"built_in\">window</span>.location.reload();</span><br><span class=\"line\">            alert(<span class=\"string\">\"提交失败:\"</span> + data[<span class=\"string\">'message'</span>]);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>以上代码需要注意的是:<br><code>processData</code> 参数默认为 true, 即将 data 转为 url 键值对形式, 这里已经是序列化后的二进制数据, 不需要再次处理,  所以应主动设置其为 false;<br>同时, <code>contentType</code> 默认为 <code>application/x-www-form-urlencoded</code>, 这里不应该使用默认值;<br>关于 jQuery ajax 方法, 更多的内容请参见: <a href=\"\">jQuery ajax 阅读与理解</a>;<br>&nbsp;<br>这便是 HTML5 时代下,  ajax 异步上传文件的最佳实践;</p>\n<h3 id=\"站内相关文章\"><a href=\"#站内相关文章\" class=\"headerlink\" title=\"站内相关文章\"></a><strong>站内相关文章</strong></h3><ul>\n<li><a href=\"\">一个 dev 的拙劣前端笔记: content-type 之 multipart/form-data 规范整理</a></li>\n<li><a href=\"\">jQuery ajax 阅读与理解</a></li>\n</ul>\n<h3 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a><strong>参考链接</strong></h3><ul>\n<li><a href=\"http://blog.csdn.net/qq_33556185/article/details/51086114\" target=\"_blank\" rel=\"noopener\">jquery Ajax提交表单(使用jquery Ajax上传附件)</a></li>\n<li><a href=\"https://www.cnblogs.com/zhanghaoliang/p/6513964.html\" target=\"_blank\" rel=\"noopener\">JQuery的ajaxFileUpload的使用</a></li>\n<li><a href=\"https://github.com/carlcarl/AjaxFileUpload/blob/master/ajaxfileupload.js\" target=\"_blank\" rel=\"noopener\">carlcarl/AjaxFileUpload/ajaxfileupload.js</a></li>\n<li><a href=\"http://blog.csdn.net/it_man/article/details/43800957\" target=\"_blank\" rel=\"noopener\">jquery插件–ajaxfileupload.js上传文件原理分析</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>从传统的刷新提交到 ajax 提交, 从间接的 iframe 刷新 ajax 提交到真正意义上的 ajax 提交, 关于前端文件上传的方法, 伴随着 web 技术与标准的演进, 不断推陈出新;<br>本文整理了从传统方式到 ajax 方式上传文件的各种方法;</p>\n</blockquote>","more":"<hr>\n<h3 id=\"传统的上传文件方式\"><a href=\"#传统的上传文件方式\" class=\"headerlink\" title=\"传统的上传文件方式\"></a><strong>传统的上传文件方式</strong></h3><p>form 表单有三种可能的 MIME 编码类型: 默认的 <code>application/x-www-form-urlencoded</code>, 不对字符编码而保留原始信息的 <code>multipart/form-data</code>, 以及纯文本 <code>text/plain</code>;<br>如果没有异步刷新的需求, 只需要将 form 表单的 enctype 属性设置为 <code>multipart/form-data</code>, 便可以二进制的方式提交表单内容, 以达到上传文件的目的:<br><figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">form</span> <span class=\"attr\">id</span>=<span class=\"string\">\"form_id\"</span> <span class=\"attr\">enctype</span>=<span class=\"string\">\"multipart/form-data\"</span>&gt;</span>  </span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"text\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"str\"</span> /&gt;</span>  </span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"file\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"fileAttach\"</span> /&gt;</span>  </span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"submit\"</span> <span class=\"attr\">value</span>=<span class=\"string\">\"upload\"</span> /&gt;</span>  </span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">form</span>&gt;</span></span><br></pre></td></tr></table></figure></p>\n<p>关于 MIME 类型 <code>multipart/form-data</code> 的更多内容, 请参见: <a href=\"\">一个 dev 的拙劣前端笔记: content-type 之 multipart/form-data 规范整理</a>;<br>&nbsp;<br><strong>下面来讨论如何使用 ajax 实现文件上传;</strong></p>\n<h3 id=\"使用-jQuery-ajaxFileUpload-插件实现文件上传\"><a href=\"#使用-jQuery-ajaxFileUpload-插件实现文件上传\" class=\"headerlink\" title=\"使用 jQuery ajaxFileUpload 插件实现文件上传\"></a><strong>使用 jQuery ajaxFileUpload 插件实现文件上传</strong></h3><p>ajax 默认使用的 MIME 类型是 <code>application/x-www-form-urlencoded</code>, 这种方式只适用于传输普通字符串类型的数据; 由于在 HTML4 时代, 没有对 javascript 提供文件读取的接口, 使用 <code>document.getElementById(&#39;field_id&#39;).value</code> 也只能获得文件的 name, 并不能拿到文件的二进制数据; 所以, 想直接使用 ajax 无刷新提交表单是无法做到的;<br>所以只能采用间接的方案, 比如基于 jQuery 拓展的 ajaxFileUpload 插件, 其代码逻辑大致如下: </p>\n<ol>\n<li>function createUploadIframe():<br>创建一个独立的 iframe, 并追加到 body 中;</li>\n<li>function createUploadForm(file_elem_id):<br>创建一个独立的 form, 设置 enctype 为 <code>multipart/form-data</code>;<br>根据 file_elem_id 找到页面里的目标 <code>&lt;input type=&quot;file&quot; /&gt;</code> 对象, 使用 jQuery.clone 方法, 将新的克隆对象替换到目标对象的位置, 而将原目标对象追加到新建的 form 中(偷梁换柱);<br>最后将新创建的 form 追加到 body 中;</li>\n<li>function addOtherRequestsToForm(data, new_form):<br>将页面中目标表单的其他元素数据, 一并追加到新创建的 form 里;</li>\n<li>function ajaxFileUpload:<br>调用 createUploadForm 方法创建新 form;<br>调用 addOtherRequestsToForm 方法捎带除 file 之外的其余元素数据;<br>调用 createUploadIFrame 方法创建 iframe;<br>将新 form 的 target 属性设置为新创建 iframe 的 id, 以实现间接的无刷新;<br>submit 提交新 form;</li>\n</ol>\n<p>&nbsp;<br>ajaxFileUpload 的实现逻辑并不复杂, 类似这样的插件在 github 上有各种各样的版本, 我选取了一个比较典型的实现: <a href=\"https://github.com/carlcarl/AjaxFileUpload/blob/master/ajaxfileupload.js\" target=\"_blank\" rel=\"noopener\">carlcarl/AjaxFileUpload/ajaxfileupload.js</a>;<br>然后开发者在实际使用时需要调用的是 <code>jQuery.ajaxFileUpload</code> 方法, 设置一些参数与回调方法:<br><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">ajax_submit</span>(<span class=\"params\">field_id</span>) </span>&#123;</span><br><span class=\"line\">    $.ajaxFileUpload(&#123;</span><br><span class=\"line\">        fileElementId: field_id,    <span class=\"comment\">// &lt;input id=\"field_id\" type=\"file\"&gt;, 对应元素的 id</span></span><br><span class=\"line\">        data: fetch_form_data(<span class=\"string\">'form_id'</span>),   <span class=\"comment\">// 捎带其余元素的数据</span></span><br><span class=\"line\">        url: <span class=\"string\">'/xxx/yyy/upload'</span></span><br><span class=\"line\">        type: <span class=\"string\">'post'</span>,</span><br><span class=\"line\">        dataType: <span class=\"string\">'json'</span>,</span><br><span class=\"line\">        secureuri: <span class=\"literal\">false</span>,   <span class=\"comment\">//是否启用安全提交，默认为false</span></span><br><span class=\"line\">        <span class=\"keyword\">async</span> : <span class=\"literal\">true</span>,   <span class=\"comment\">//是否是异步</span></span><br><span class=\"line\">        success: <span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\">data</span>) </span>&#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (data[<span class=\"string\">'status'</span>] == <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">                <span class=\"built_in\">window</span>.location.reload();</span><br><span class=\"line\">                alert(<span class=\"string\">\"提交成功\"</span>);</span><br><span class=\"line\">            &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                <span class=\"built_in\">window</span>.location.reload();</span><br><span class=\"line\">                alert(<span class=\"string\">\"提交失败:\"</span> + data[<span class=\"string\">'message'</span>]);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        error: <span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\">data, status, e</span>) </span>&#123;</span><br><span class=\"line\">            <span class=\"built_in\">window</span>.location.reload();</span><br><span class=\"line\">            alert(<span class=\"string\">\"提交失败:\"</span> + data[<span class=\"string\">'message'</span>]);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">// 将给定的表单数据转为对象</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">fetch_form_data</span>(<span class=\"params\">form_id</span>) </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">var</span> params = $(<span class=\"string\">'#'</span> + form_id).serializeArray();  </span><br><span class=\"line\">    <span class=\"keyword\">var</span> values = &#123;&#125;;  </span><br><span class=\"line\">    <span class=\"keyword\">for</span>( x <span class=\"keyword\">in</span> params ) &#123;  </span><br><span class=\"line\">        values[params[x].name] = params[x].value;  </span><br><span class=\"line\">    &#125;  </span><br><span class=\"line\">    <span class=\"keyword\">return</span> values</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>抛开 iframe 的性能影响不谈, 看起来这样的 api 还是相当友好的, 与 jQuery.ajax 同样方便, 还解决了 ajax 不能传输二进制流的问题;<br>另外, 由于这种方式真正提交的表单完全是 javascript 创建出来的, 页面上自己写的那个表单, 只作为数据 clone 的载体, 所以只需要确保表单和其中的 file input 元素有自己的 id, 最后提交按钮的 onclick 事件指向了目标方法即可;<br><figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">form</span> <span class=\"attr\">id</span>=<span class=\"string\">\"form_id\"</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"text\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"str\"</span> /&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">id</span>=<span class=\"string\">\"file_attach\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"file\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"fileAttach\"</span> /&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"button\"</span> <span class=\"attr\">onclick</span>=<span class=\"string\">\"ajax_submit('file_attach')\"</span>  <span class=\"attr\">value</span>=<span class=\"string\">\"upload\"</span> /&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">form</span>&gt;</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"使用-jQuery-ajax-结合-HTML5-API-实现文件上传\"><a href=\"#使用-jQuery-ajax-结合-HTML5-API-实现文件上传\" class=\"headerlink\" title=\"使用 jQuery ajax 结合 HTML5 API 实现文件上传\"></a><strong>使用 jQuery ajax 结合 HTML5 API 实现文件上传</strong></h3><p>使用 ajaxFileUplaod 插件, 无论怎么优化改造, 其需要使用 iframe 作间接无刷新的逻辑是没法绕开的; 而使用 iframe 必然会带来额外资源的消耗, 如果有更原生直接的解决方案, 我们一定乐于在项目中取代 ajaxFileUpload;<br>于是, 在 HTML5 时代, 出现了一个新的接口: <code>FormData</code>, 它给出了完美的解决方案;<br><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> form_content = <span class=\"keyword\">new</span> FormData(<span class=\"built_in\">document</span>.getElementById(<span class=\"string\">\"form_id\"</span>));</span><br></pre></td></tr></table></figure></p>\n<p>这行代码便拿到了目标表单对象的所有信息; 我们只需要确保表单的 enctype 属性为 <code>multipart/form-data</code>, 通过该接口获得的 FormData 对象, 便是完整的二进制序列化信息:<br><figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">form</span> <span class=\"attr\">id</span>=<span class=\"string\">\"form_id\"</span> <span class=\"attr\">enctype</span>=<span class=\"string\">\"multipart/form-data\"</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"text\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"str\"</span> /&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"file\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"fileAttach\"</span> /&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"button\"</span> <span class=\"attr\">onclick</span>=<span class=\"string\">\"upload_file()\"</span>  <span class=\"attr\">value</span>=<span class=\"string\">\"upload\"</span> /&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">form</span>&gt;</span></span><br></pre></td></tr></table></figure></p>\n<p>这样, 一个 onclick 事件触发 upload_file 方法, 使用原生的 jQuery ajax 就实现了上传文件的功能了, 同时表单内的其他字符串数据, 也一并以 multi part 的形式上传上去了;<br>对应的 javascript upload_file 方法如下:<br><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">uplaod_file</span>(<span class=\"params\"></span>) </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">var</span> form_content = <span class=\"keyword\">new</span> FormData(<span class=\"built_in\">document</span>.getElementById(<span class=\"string\">'form_id'</span>));</span><br><span class=\"line\">    $.ajax(&#123;</span><br><span class=\"line\">        type: <span class=\"string\">'POST'</span>,</span><br><span class=\"line\">        url: <span class=\"string\">'/xxx/yyy/upload'</span>,</span><br><span class=\"line\">        data: form_content,</span><br><span class=\"line\">        processData: <span class=\"literal\">false</span>,     <span class=\"comment\">// 阻止默认的 application/x-www-form-urlencoded 对象处理方法</span></span><br><span class=\"line\">        contentType: <span class=\"literal\">false</span>,     <span class=\"comment\">// 与 processData 保持一直, 不使用默认的 application/x-www-form-urlencoded</span></span><br><span class=\"line\">        success: <span class=\"function\"><span class=\"keyword\">function</span> (<span class=\"params\">data</span>) </span>&#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (data[<span class=\"string\">'status'</span>] == <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">                <span class=\"built_in\">window</span>.location.reload();</span><br><span class=\"line\">                alert(<span class=\"string\">\"提交成功\"</span>);</span><br><span class=\"line\">            &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                <span class=\"built_in\">window</span>.location.reload();</span><br><span class=\"line\">                alert(<span class=\"string\">\"提交失败:\"</span> + data[<span class=\"string\">'message'</span>]);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        fail: <span class=\"function\"><span class=\"keyword\">function</span> (<span class=\"params\">data</span>) </span>&#123;</span><br><span class=\"line\">            <span class=\"built_in\">window</span>.location.reload();</span><br><span class=\"line\">            alert(<span class=\"string\">\"提交失败:\"</span> + data[<span class=\"string\">'message'</span>]);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>以上代码需要注意的是:<br><code>processData</code> 参数默认为 true, 即将 data 转为 url 键值对形式, 这里已经是序列化后的二进制数据, 不需要再次处理,  所以应主动设置其为 false;<br>同时, <code>contentType</code> 默认为 <code>application/x-www-form-urlencoded</code>, 这里不应该使用默认值;<br>关于 jQuery ajax 方法, 更多的内容请参见: <a href=\"\">jQuery ajax 阅读与理解</a>;<br>&nbsp;<br>这便是 HTML5 时代下,  ajax 异步上传文件的最佳实践;</p>\n<h3 id=\"站内相关文章\"><a href=\"#站内相关文章\" class=\"headerlink\" title=\"站内相关文章\"></a><strong>站内相关文章</strong></h3><ul>\n<li><a href=\"\">一个 dev 的拙劣前端笔记: content-type 之 multipart/form-data 规范整理</a></li>\n<li><a href=\"\">jQuery ajax 阅读与理解</a></li>\n</ul>\n<h3 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a><strong>参考链接</strong></h3><ul>\n<li><a href=\"http://blog.csdn.net/qq_33556185/article/details/51086114\" target=\"_blank\" rel=\"noopener\">jquery Ajax提交表单(使用jquery Ajax上传附件)</a></li>\n<li><a href=\"https://www.cnblogs.com/zhanghaoliang/p/6513964.html\" target=\"_blank\" rel=\"noopener\">JQuery的ajaxFileUpload的使用</a></li>\n<li><a href=\"https://github.com/carlcarl/AjaxFileUpload/blob/master/ajaxfileupload.js\" target=\"_blank\" rel=\"noopener\">carlcarl/AjaxFileUpload/ajaxfileupload.js</a></li>\n<li><a href=\"http://blog.csdn.net/it_man/article/details/43800957\" target=\"_blank\" rel=\"noopener\">jquery插件–ajaxfileupload.js上传文件原理分析</a></li>\n</ul>"},{"title":"python module 使用总结: MySQLdb","date":"2017-08-01T15:06:08.000Z","_content":"\n> `MySQLdb` 模块是 python 与 mysql 交互的较为底层的接口, 不过它依然是在更为底层的 `_mysql` 模块之上又作了一层包装;\n`_mysql` 才是真正的直接面向 mysql 原生 C 接口的简单适配层, 而 `MySQLdb` 则在 `_mysql` 之上作了更多的关于类型转换等抽象包装;\n考虑到 `MySQLdb` 模块与一些 python ORM 框架的关系, `MySQLdb` 与 python 的关系可以类比为 jdbc 之于 java;\n如果是复杂的系统, 我们肯定会选择 ORM 框架, 不过对于一些简单的小工具, 定时小任务等, 本身没什么复杂的数据库操作, 那就用 MySQLdb 最方便了;\n本文基于 `MySQL-python 1.2.5` 对 MySQLdb 作一些使用上的总结;\n\n<!--more-->\n\n------\n\n### **MySQLdb 的基本操作**\n``` python\nimport MySQLdb\n# 获得 mysql 的一个连接\nconn = MySQLdb.connect(host='10.64.0.11', user='xxx', passwd='yyy', db=\"zzz\", port=3306, charset=\"utf8\")\ntry:\n    # cursor 游标, 是 MySQLdb 中与 mysql 增删改查数据交互的对象\n    cur = conn.cursor()\n    # 数据库操作\n    cur.execute(\"...sql...\")\n    ...\n    # 提交事务\n    conn.commit()\nexcept Exception, e:\n    # 回滚\n    conn.rollback()\nfinally:\n    # 关闭连接, 释放资源\n    conn.close()\n```\n以上是一个 MySQLdb 使用的完整流程, 下面是具体的使用细节与注意点总结;\n\n### **MySQLdb cursor.execute / cursor.executemany 方法**\n#### **cursor.execute 方法**\nMySQLdb 执行数据操纵的关键点就在于 cursor.execute 方法, 所有包括增删改查在内皆是以此方法执行的, 以下是该方法的代码:\n``` python\ndef execute(self, query, args=None):\n    del self.messages[:]\n    db = self._get_db()\n    if isinstance(query, unicode):\n        query = query.encode(db.unicode_literal.charset)\n    if args is not None:\n        # 针对 args 为 dict 的特殊情况处理\n        if isinstance(args, dict):\n            query = query % dict((key, db.literal(item)) for key, item in args.iteritems())\n        # 其余的情况: args 为 tuple 或单个 value\n        else:\n            query = query % tuple([db.literal(item) for item in args])\n    try:\n        r = None\n        r = self._query(query)\n    except TypeError, m:\n        if m.args[0] in (\"not enough arguments for format string\", \"not all arguments converted\"):\n            self.messages.append((ProgrammingError, m.args[0]))\n            self.errorhandler(self, ProgrammingError, m.args[0])\n        else:\n            self.messages.append((TypeError, m)) \n            self.errorhandler(self, TypeError, m)\n    except (SystemExit, KeyboardInterrupt):\n        raise\n    except:\n        exc, value, tb = sys.exc_info()\n        del tb\n        self.messages.append((exc, value))\n        self.errorhandler(self, exc, value)\n    self._executed = query\n    if not self._defer_warnings: self._warning_check()\n    return r\n```\n该方法接收一个名为 `query` 的 sql 字符串, 另外还可选附带参数 `args`, 所以该方法存在两种主要的用法:\n1.预先格式化好 sql 字符串, 然后不带参数直接 execute:\n``` python\nsql = \"select * from xxx where update_time = %s\" % datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\ncursor.execute(sql)\n```\n这种是保守的方法, 参数处理完全由 python 原生的格式化字符串完成, cursor.execute 方法只管执行 sql 就好;\n这种方法的优点是省事, 坑少;\n&nbsp;\n2.将参数传给 execute 方法的 `args`, 这种使用方法有几个坑, 需要注意一下;\n该方法有一段注释, 我单独提了出来, 注释中对 args 参数有如下描述:\n``` python\n\"\"\"\n    args -- optional sequence or mapping, parameters to use with query.\n\n    Note: If args is a sequence, then %s must be used as the\n    parameter placeholder in the query. If a mapping is used,\n    %(key)s must be used as the placeholder.\n\"\"\"\n```\n(1) 注释中提到的坑, 就是说无论传的参数是一个 list/tuple, 还是 dict, 参数占位符类型都必须是字符串(%s | %(key)s ):\n``` python\n# 不能是 id = %d, 只能是 id = %s\nsql = 'select * from xxx where id  = %s'\n```\n因为 execute 方法里处理参数时, 会对参数作 `db.literal(item)` 处理, 将参数首先转为字符串, 这时占位符如果是 %d 等其他类型, 就报错了;\n\n&nbsp;\n(2) 注释中另一个隐型的坑, 是这个 `args` 必须是 list / tuple / dict 中的一个, 哪怕只有一个占位数据, 也必须写成 list 或 tuple 类型:\n``` python\ncursor.execute(sql, (2,))\ncursor.execute(sql, [2])\n```\n如果希望以 tuple 形式表示唯一一个参数, 必须注意加上 逗号, 因为不加逗号就算外面包了括号也会识别为其本身的类型:\n``` python\n>>> print type((1))\n<type 'int'>\n>>> print type(('1'))\n<type 'str'>\n>>> print type((1,))\n<type 'tuple'>\n>>> print type(('1',))\n<type 'tuple'>\n```\n其实这个坑是在 MySQL-python 1.2.5 版本中出现的问题; 在 1.2.3 版本中, execute 方法的逻辑是这么写的:\n``` python\nif args is not None:\n    query = query % db.literal(args)\n```\n只要 args 非空, 就一律把它 to string; 而至于参数怎么转, 转成什么样, 就看参数自己了;\n这么做确实灵活了, 但是也可能带来一些不确定性, 1.2.5 的版本将参数限定为 list / tuple / dict, 然后对集合内的每个元素再针对性 to string, 一定程度上控制了参数的规范性;\n&nbsp;\n#### **cursor.executemany 方法**\nexecutemany 方法是 execute 方法的批量化, 这个方法的有效使用范围其实很狭窄, 仅针对 insert 操作有性能提升, 其余操作在性能上均与 execute 无异;\n下面是该方法的代码:\n``` python\n        del self.messages[:]\n        db = self._get_db()\n        if not args: return\n        if isinstance(query, unicode):\n            query = query.encode(db.unicode_literal.charset)\n        # 正则匹配 insert 操作\n        m = insert_values.search(query)\n        # 不是 insert 操作, 那就 for 循环挨个执行而已\n        if not m:\n            r = 0\n            for a in args:\n                r = r + self.execute(query, a)\n            return r\n        p = m.start(1)\n        e = m.end(1)\n        qv = m.group(1)\n        # 下面是针对 insert 的处理\n        try:\n            q = []\n            for a in args:\n                if isinstance(a, dict):\n                    q.append(qv % dict((key, db.literal(item))\n                                       for key, item in a.iteritems()))\n                else:\n                    q.append(qv % tuple([db.literal(item) for item in a]))\n        except TypeError, msg:\n            if msg.args[0] in (\"not enough arguments for format string\",\n                               \"not all arguments converted\"):\n                self.errorhandler(self, ProgrammingError, msg.args[0])\n            else:\n                self.errorhandler(self, TypeError, msg)\n        except (SystemExit, KeyboardInterrupt):\n            raise\n        except:\n            exc, value, tb = sys.exc_info()\n            del tb\n            self.errorhandler(self, exc, value)\n        # 批量化执行, 提高处理性能\n        r = self._query('\\n'.join([query[:p], ',\\n'.join(q), query[e:]]))\n        if not self._defer_warnings: self._warning_check()\n        return r\n```\n从代码里可以看到, 方法先对传入的 sql 语句作一次匹配, 判断其是否是 insert 操作, 其中 insert_values 是一个 regex, 专门匹配 insert 语句:\n``` python\nrestr = r\"\\svalues\\s*(\\([^()']*(?:(?:(?:\\(.*\\))|'[^\\\\']*(?:\\\\.[^\\\\']*)*')[^()']*)*\\))\"\ninsert_values = re.compile(restr, re.S | re.I | re.X)\n```\n针对 insert 语句, 其最后的执行是批量的, 以提高执行效率:\n``` python\nr = self._query('\\n'.join([query[:p], ',\\n'.join(q), query[e:]]))\n```\n但是而其他的语句, 却只能在一个 for 循环里, 挨个执行 execute 方法, 这就没什么优势了;\n不过这个方法还有一个大坑: 对于 update 和 delete 操作, 使用 executemany 至少不会比 execute 差, 但是对于 query, 它批量执行完一堆 query 操作后去 fetch 结果集, 只能拿到最后执行的 query 的结果, 前面的都被覆盖了; 所以, query 操作不能使用 executemany 方法;\n&nbsp;\n在使用方面, executemany 的坑和 execute 是差不多的, 下面是一个例子:\n``` python\n# executemany 传入的 args 可以是 list 也可以是 tuple\ncur.executemany('select * from xxx where yyy = %s', [(1,), (2,)])\n```\n\n### **MySQLdb 的 query 结果集操作**\nMySQLdb 的 query 操作, 主要有以下三种结果集的获取方法:\n``` python\ncursor.execute(\"...sql...\")\n\n# 获得所有的 tuple 结果集的一个 list\n@return list[tuple(elem1, elem2, elem3 ...)]\ntuple_data_list = cursor.fetchall()\nfor tuple_data in tuple_data_list:\n    xxx = tuple_data[0]\n    yyy = tuple_data[1]\n    ...\n    \n\n# 采用迭代器的方式, 返回当前游标所对应的 tuple 结果集, 迭代到最后方法返回 None\n@return tuple(elem1, elem2, elem3 ...)\ntuple_data = cursor.fetchone()\nwhile tuple_data:\n    # deal with tuple_data\n    ...\n    tuple_data = cursor.fetchone()\n    \n    \n# 折中的一种方法, 指定返回 size 个 tuple 结果集 组成一个 list;\n# 若 指定 size 小于 总的结果集数量, 则返回全部数据集;\n@return list[tuple(elem1, elem2, elem3 ...)]\ntuple_data_list = cursor.fetchmany(size)\n...\n```\n\n### **MySQLdb 的事务操作**\nMySQLdb 默认不会自动 commit, 所有的增删改操作都必须手动 commit 才能真正写回数据库;\n``` python\nconn = MySQLdb.connect(host='10.64.0.11', user='xxx', passwd='yyy', db=\"zzz\", port=3306, charset=\"utf8\")\nSQL = 'update xxx set yyy = zzz'\ncur = conn.cursor()\ntry:\n    cur.execute(SQL,(2,))\n    # 手动 commit 提交事务\n    conn.commit()\nexcept Exception, e:\n    # 手动回滚\n    conn.rollback()\nfinally:\n    cur.close()\n    conn.close()\n```\n\n### **参考链接**\n- [MySQLdb的安装与使用](https://www.cnblogs.com/franknihao/p/7267182.html)\n\n","source":"_posts/python-module--python_module_MySQLdb使用总结.md","raw":"---\ntitle: 'python module 使用总结: MySQLdb'\ndate: 2017-08-01 23:06:08\ncategories:\n - python\n - module\ntags:\n - python:module\n---\n\n> `MySQLdb` 模块是 python 与 mysql 交互的较为底层的接口, 不过它依然是在更为底层的 `_mysql` 模块之上又作了一层包装;\n`_mysql` 才是真正的直接面向 mysql 原生 C 接口的简单适配层, 而 `MySQLdb` 则在 `_mysql` 之上作了更多的关于类型转换等抽象包装;\n考虑到 `MySQLdb` 模块与一些 python ORM 框架的关系, `MySQLdb` 与 python 的关系可以类比为 jdbc 之于 java;\n如果是复杂的系统, 我们肯定会选择 ORM 框架, 不过对于一些简单的小工具, 定时小任务等, 本身没什么复杂的数据库操作, 那就用 MySQLdb 最方便了;\n本文基于 `MySQL-python 1.2.5` 对 MySQLdb 作一些使用上的总结;\n\n<!--more-->\n\n------\n\n### **MySQLdb 的基本操作**\n``` python\nimport MySQLdb\n# 获得 mysql 的一个连接\nconn = MySQLdb.connect(host='10.64.0.11', user='xxx', passwd='yyy', db=\"zzz\", port=3306, charset=\"utf8\")\ntry:\n    # cursor 游标, 是 MySQLdb 中与 mysql 增删改查数据交互的对象\n    cur = conn.cursor()\n    # 数据库操作\n    cur.execute(\"...sql...\")\n    ...\n    # 提交事务\n    conn.commit()\nexcept Exception, e:\n    # 回滚\n    conn.rollback()\nfinally:\n    # 关闭连接, 释放资源\n    conn.close()\n```\n以上是一个 MySQLdb 使用的完整流程, 下面是具体的使用细节与注意点总结;\n\n### **MySQLdb cursor.execute / cursor.executemany 方法**\n#### **cursor.execute 方法**\nMySQLdb 执行数据操纵的关键点就在于 cursor.execute 方法, 所有包括增删改查在内皆是以此方法执行的, 以下是该方法的代码:\n``` python\ndef execute(self, query, args=None):\n    del self.messages[:]\n    db = self._get_db()\n    if isinstance(query, unicode):\n        query = query.encode(db.unicode_literal.charset)\n    if args is not None:\n        # 针对 args 为 dict 的特殊情况处理\n        if isinstance(args, dict):\n            query = query % dict((key, db.literal(item)) for key, item in args.iteritems())\n        # 其余的情况: args 为 tuple 或单个 value\n        else:\n            query = query % tuple([db.literal(item) for item in args])\n    try:\n        r = None\n        r = self._query(query)\n    except TypeError, m:\n        if m.args[0] in (\"not enough arguments for format string\", \"not all arguments converted\"):\n            self.messages.append((ProgrammingError, m.args[0]))\n            self.errorhandler(self, ProgrammingError, m.args[0])\n        else:\n            self.messages.append((TypeError, m)) \n            self.errorhandler(self, TypeError, m)\n    except (SystemExit, KeyboardInterrupt):\n        raise\n    except:\n        exc, value, tb = sys.exc_info()\n        del tb\n        self.messages.append((exc, value))\n        self.errorhandler(self, exc, value)\n    self._executed = query\n    if not self._defer_warnings: self._warning_check()\n    return r\n```\n该方法接收一个名为 `query` 的 sql 字符串, 另外还可选附带参数 `args`, 所以该方法存在两种主要的用法:\n1.预先格式化好 sql 字符串, 然后不带参数直接 execute:\n``` python\nsql = \"select * from xxx where update_time = %s\" % datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\ncursor.execute(sql)\n```\n这种是保守的方法, 参数处理完全由 python 原生的格式化字符串完成, cursor.execute 方法只管执行 sql 就好;\n这种方法的优点是省事, 坑少;\n&nbsp;\n2.将参数传给 execute 方法的 `args`, 这种使用方法有几个坑, 需要注意一下;\n该方法有一段注释, 我单独提了出来, 注释中对 args 参数有如下描述:\n``` python\n\"\"\"\n    args -- optional sequence or mapping, parameters to use with query.\n\n    Note: If args is a sequence, then %s must be used as the\n    parameter placeholder in the query. If a mapping is used,\n    %(key)s must be used as the placeholder.\n\"\"\"\n```\n(1) 注释中提到的坑, 就是说无论传的参数是一个 list/tuple, 还是 dict, 参数占位符类型都必须是字符串(%s | %(key)s ):\n``` python\n# 不能是 id = %d, 只能是 id = %s\nsql = 'select * from xxx where id  = %s'\n```\n因为 execute 方法里处理参数时, 会对参数作 `db.literal(item)` 处理, 将参数首先转为字符串, 这时占位符如果是 %d 等其他类型, 就报错了;\n\n&nbsp;\n(2) 注释中另一个隐型的坑, 是这个 `args` 必须是 list / tuple / dict 中的一个, 哪怕只有一个占位数据, 也必须写成 list 或 tuple 类型:\n``` python\ncursor.execute(sql, (2,))\ncursor.execute(sql, [2])\n```\n如果希望以 tuple 形式表示唯一一个参数, 必须注意加上 逗号, 因为不加逗号就算外面包了括号也会识别为其本身的类型:\n``` python\n>>> print type((1))\n<type 'int'>\n>>> print type(('1'))\n<type 'str'>\n>>> print type((1,))\n<type 'tuple'>\n>>> print type(('1',))\n<type 'tuple'>\n```\n其实这个坑是在 MySQL-python 1.2.5 版本中出现的问题; 在 1.2.3 版本中, execute 方法的逻辑是这么写的:\n``` python\nif args is not None:\n    query = query % db.literal(args)\n```\n只要 args 非空, 就一律把它 to string; 而至于参数怎么转, 转成什么样, 就看参数自己了;\n这么做确实灵活了, 但是也可能带来一些不确定性, 1.2.5 的版本将参数限定为 list / tuple / dict, 然后对集合内的每个元素再针对性 to string, 一定程度上控制了参数的规范性;\n&nbsp;\n#### **cursor.executemany 方法**\nexecutemany 方法是 execute 方法的批量化, 这个方法的有效使用范围其实很狭窄, 仅针对 insert 操作有性能提升, 其余操作在性能上均与 execute 无异;\n下面是该方法的代码:\n``` python\n        del self.messages[:]\n        db = self._get_db()\n        if not args: return\n        if isinstance(query, unicode):\n            query = query.encode(db.unicode_literal.charset)\n        # 正则匹配 insert 操作\n        m = insert_values.search(query)\n        # 不是 insert 操作, 那就 for 循环挨个执行而已\n        if not m:\n            r = 0\n            for a in args:\n                r = r + self.execute(query, a)\n            return r\n        p = m.start(1)\n        e = m.end(1)\n        qv = m.group(1)\n        # 下面是针对 insert 的处理\n        try:\n            q = []\n            for a in args:\n                if isinstance(a, dict):\n                    q.append(qv % dict((key, db.literal(item))\n                                       for key, item in a.iteritems()))\n                else:\n                    q.append(qv % tuple([db.literal(item) for item in a]))\n        except TypeError, msg:\n            if msg.args[0] in (\"not enough arguments for format string\",\n                               \"not all arguments converted\"):\n                self.errorhandler(self, ProgrammingError, msg.args[0])\n            else:\n                self.errorhandler(self, TypeError, msg)\n        except (SystemExit, KeyboardInterrupt):\n            raise\n        except:\n            exc, value, tb = sys.exc_info()\n            del tb\n            self.errorhandler(self, exc, value)\n        # 批量化执行, 提高处理性能\n        r = self._query('\\n'.join([query[:p], ',\\n'.join(q), query[e:]]))\n        if not self._defer_warnings: self._warning_check()\n        return r\n```\n从代码里可以看到, 方法先对传入的 sql 语句作一次匹配, 判断其是否是 insert 操作, 其中 insert_values 是一个 regex, 专门匹配 insert 语句:\n``` python\nrestr = r\"\\svalues\\s*(\\([^()']*(?:(?:(?:\\(.*\\))|'[^\\\\']*(?:\\\\.[^\\\\']*)*')[^()']*)*\\))\"\ninsert_values = re.compile(restr, re.S | re.I | re.X)\n```\n针对 insert 语句, 其最后的执行是批量的, 以提高执行效率:\n``` python\nr = self._query('\\n'.join([query[:p], ',\\n'.join(q), query[e:]]))\n```\n但是而其他的语句, 却只能在一个 for 循环里, 挨个执行 execute 方法, 这就没什么优势了;\n不过这个方法还有一个大坑: 对于 update 和 delete 操作, 使用 executemany 至少不会比 execute 差, 但是对于 query, 它批量执行完一堆 query 操作后去 fetch 结果集, 只能拿到最后执行的 query 的结果, 前面的都被覆盖了; 所以, query 操作不能使用 executemany 方法;\n&nbsp;\n在使用方面, executemany 的坑和 execute 是差不多的, 下面是一个例子:\n``` python\n# executemany 传入的 args 可以是 list 也可以是 tuple\ncur.executemany('select * from xxx where yyy = %s', [(1,), (2,)])\n```\n\n### **MySQLdb 的 query 结果集操作**\nMySQLdb 的 query 操作, 主要有以下三种结果集的获取方法:\n``` python\ncursor.execute(\"...sql...\")\n\n# 获得所有的 tuple 结果集的一个 list\n@return list[tuple(elem1, elem2, elem3 ...)]\ntuple_data_list = cursor.fetchall()\nfor tuple_data in tuple_data_list:\n    xxx = tuple_data[0]\n    yyy = tuple_data[1]\n    ...\n    \n\n# 采用迭代器的方式, 返回当前游标所对应的 tuple 结果集, 迭代到最后方法返回 None\n@return tuple(elem1, elem2, elem3 ...)\ntuple_data = cursor.fetchone()\nwhile tuple_data:\n    # deal with tuple_data\n    ...\n    tuple_data = cursor.fetchone()\n    \n    \n# 折中的一种方法, 指定返回 size 个 tuple 结果集 组成一个 list;\n# 若 指定 size 小于 总的结果集数量, 则返回全部数据集;\n@return list[tuple(elem1, elem2, elem3 ...)]\ntuple_data_list = cursor.fetchmany(size)\n...\n```\n\n### **MySQLdb 的事务操作**\nMySQLdb 默认不会自动 commit, 所有的增删改操作都必须手动 commit 才能真正写回数据库;\n``` python\nconn = MySQLdb.connect(host='10.64.0.11', user='xxx', passwd='yyy', db=\"zzz\", port=3306, charset=\"utf8\")\nSQL = 'update xxx set yyy = zzz'\ncur = conn.cursor()\ntry:\n    cur.execute(SQL,(2,))\n    # 手动 commit 提交事务\n    conn.commit()\nexcept Exception, e:\n    # 手动回滚\n    conn.rollback()\nfinally:\n    cur.close()\n    conn.close()\n```\n\n### **参考链接**\n- [MySQLdb的安装与使用](https://www.cnblogs.com/franknihao/p/7267182.html)\n\n","slug":"python-module--python_module_MySQLdb使用总结","published":1,"updated":"2018-02-02T14:54:17.624Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cje24mxul0018j1jx6st5alc5","content":"<blockquote>\n<p><code>MySQLdb</code> 模块是 python 与 mysql 交互的较为底层的接口, 不过它依然是在更为底层的 <code>_mysql</code> 模块之上又作了一层包装;<br><code>_mysql</code> 才是真正的直接面向 mysql 原生 C 接口的简单适配层, 而 <code>MySQLdb</code> 则在 <code>_mysql</code> 之上作了更多的关于类型转换等抽象包装;<br>考虑到 <code>MySQLdb</code> 模块与一些 python ORM 框架的关系, <code>MySQLdb</code> 与 python 的关系可以类比为 jdbc 之于 java;<br>如果是复杂的系统, 我们肯定会选择 ORM 框架, 不过对于一些简单的小工具, 定时小任务等, 本身没什么复杂的数据库操作, 那就用 MySQLdb 最方便了;<br>本文基于 <code>MySQL-python 1.2.5</code> 对 MySQLdb 作一些使用上的总结;</p>\n</blockquote>\n<a id=\"more\"></a>\n<hr>\n<h3 id=\"MySQLdb-的基本操作\"><a href=\"#MySQLdb-的基本操作\" class=\"headerlink\" title=\"MySQLdb 的基本操作\"></a><strong>MySQLdb 的基本操作</strong></h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> MySQLdb</span><br><span class=\"line\"><span class=\"comment\"># 获得 mysql 的一个连接</span></span><br><span class=\"line\">conn = MySQLdb.connect(host=<span class=\"string\">'10.64.0.11'</span>, user=<span class=\"string\">'xxx'</span>, passwd=<span class=\"string\">'yyy'</span>, db=<span class=\"string\">\"zzz\"</span>, port=<span class=\"number\">3306</span>, charset=<span class=\"string\">\"utf8\"</span>)</span><br><span class=\"line\"><span class=\"keyword\">try</span>:</span><br><span class=\"line\">    <span class=\"comment\"># cursor 游标, 是 MySQLdb 中与 mysql 增删改查数据交互的对象</span></span><br><span class=\"line\">    cur = conn.cursor()</span><br><span class=\"line\">    <span class=\"comment\"># 数据库操作</span></span><br><span class=\"line\">    cur.execute(<span class=\"string\">\"...sql...\"</span>)</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    <span class=\"comment\"># 提交事务</span></span><br><span class=\"line\">    conn.commit()</span><br><span class=\"line\"><span class=\"keyword\">except</span> Exception, e:</span><br><span class=\"line\">    <span class=\"comment\"># 回滚</span></span><br><span class=\"line\">    conn.rollback()</span><br><span class=\"line\"><span class=\"keyword\">finally</span>:</span><br><span class=\"line\">    <span class=\"comment\"># 关闭连接, 释放资源</span></span><br><span class=\"line\">    conn.close()</span><br></pre></td></tr></table></figure>\n<p>以上是一个 MySQLdb 使用的完整流程, 下面是具体的使用细节与注意点总结;</p>\n<h3 id=\"MySQLdb-cursor-execute-cursor-executemany-方法\"><a href=\"#MySQLdb-cursor-execute-cursor-executemany-方法\" class=\"headerlink\" title=\"MySQLdb cursor.execute / cursor.executemany 方法\"></a><strong>MySQLdb cursor.execute / cursor.executemany 方法</strong></h3><h4 id=\"cursor-execute-方法\"><a href=\"#cursor-execute-方法\" class=\"headerlink\" title=\"cursor.execute 方法\"></a><strong>cursor.execute 方法</strong></h4><p>MySQLdb 执行数据操纵的关键点就在于 cursor.execute 方法, 所有包括增删改查在内皆是以此方法执行的, 以下是该方法的代码:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">execute</span><span class=\"params\">(self, query, args=None)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">del</span> self.messages[:]</span><br><span class=\"line\">    db = self._get_db()</span><br><span class=\"line\">    <span class=\"keyword\">if</span> isinstance(query, unicode):</span><br><span class=\"line\">        query = query.encode(db.unicode_literal.charset)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> args <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"keyword\">None</span>:</span><br><span class=\"line\">        <span class=\"comment\"># 针对 args 为 dict 的特殊情况处理</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> isinstance(args, dict):</span><br><span class=\"line\">            query = query % dict((key, db.literal(item)) <span class=\"keyword\">for</span> key, item <span class=\"keyword\">in</span> args.iteritems())</span><br><span class=\"line\">        <span class=\"comment\"># 其余的情况: args 为 tuple 或单个 value</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            query = query % tuple([db.literal(item) <span class=\"keyword\">for</span> item <span class=\"keyword\">in</span> args])</span><br><span class=\"line\">    <span class=\"keyword\">try</span>:</span><br><span class=\"line\">        r = <span class=\"keyword\">None</span></span><br><span class=\"line\">        r = self._query(query)</span><br><span class=\"line\">    <span class=\"keyword\">except</span> TypeError, m:</span><br><span class=\"line\">        <span class=\"keyword\">if</span> m.args[<span class=\"number\">0</span>] <span class=\"keyword\">in</span> (<span class=\"string\">\"not enough arguments for format string\"</span>, <span class=\"string\">\"not all arguments converted\"</span>):</span><br><span class=\"line\">            self.messages.append((ProgrammingError, m.args[<span class=\"number\">0</span>]))</span><br><span class=\"line\">            self.errorhandler(self, ProgrammingError, m.args[<span class=\"number\">0</span>])</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            self.messages.append((TypeError, m)) </span><br><span class=\"line\">            self.errorhandler(self, TypeError, m)</span><br><span class=\"line\">    <span class=\"keyword\">except</span> (SystemExit, KeyboardInterrupt):</span><br><span class=\"line\">        <span class=\"keyword\">raise</span></span><br><span class=\"line\">    <span class=\"keyword\">except</span>:</span><br><span class=\"line\">        exc, value, tb = sys.exc_info()</span><br><span class=\"line\">        <span class=\"keyword\">del</span> tb</span><br><span class=\"line\">        self.messages.append((exc, value))</span><br><span class=\"line\">        self.errorhandler(self, exc, value)</span><br><span class=\"line\">    self._executed = query</span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> self._defer_warnings: self._warning_check()</span><br><span class=\"line\">    <span class=\"keyword\">return</span> r</span><br></pre></td></tr></table></figure></p>\n<p>该方法接收一个名为 <code>query</code> 的 sql 字符串, 另外还可选附带参数 <code>args</code>, 所以该方法存在两种主要的用法:<br>1.预先格式化好 sql 字符串, 然后不带参数直接 execute:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sql = <span class=\"string\">\"select * from xxx where update_time = %s\"</span> % datetime.datetime.now().strftime(<span class=\"string\">\"%Y-%m-%d %H:%M:%S\"</span>)</span><br><span class=\"line\">cursor.execute(sql)</span><br></pre></td></tr></table></figure></p>\n<p>这种是保守的方法, 参数处理完全由 python 原生的格式化字符串完成, cursor.execute 方法只管执行 sql 就好;<br>这种方法的优点是省事, 坑少;<br>&nbsp;<br>2.将参数传给 execute 方法的 <code>args</code>, 这种使用方法有几个坑, 需要注意一下;<br>该方法有一段注释, 我单独提了出来, 注释中对 args 参数有如下描述:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    args -- optional sequence or mapping, parameters to use with query.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Note: If args is a sequence, then %s must be used as the</span></span><br><span class=\"line\"><span class=\"string\">    parameter placeholder in the query. If a mapping is used,</span></span><br><span class=\"line\"><span class=\"string\">    %(key)s must be used as the placeholder.</span></span><br><span class=\"line\"><span class=\"string\">\"\"\"</span></span><br></pre></td></tr></table></figure></p>\n<p>(1) 注释中提到的坑, 就是说无论传的参数是一个 list/tuple, 还是 dict, 参数占位符类型都必须是字符串(%s | %(key)s ):<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 不能是 id = %d, 只能是 id = %s</span></span><br><span class=\"line\">sql = <span class=\"string\">'select * from xxx where id  = %s'</span></span><br></pre></td></tr></table></figure></p>\n<p>因为 execute 方法里处理参数时, 会对参数作 <code>db.literal(item)</code> 处理, 将参数首先转为字符串, 这时占位符如果是 %d 等其他类型, 就报错了;</p>\n<p>&nbsp;<br>(2) 注释中另一个隐型的坑, 是这个 <code>args</code> 必须是 list / tuple / dict 中的一个, 哪怕只有一个占位数据, 也必须写成 list 或 tuple 类型:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cursor.execute(sql, (<span class=\"number\">2</span>,))</span><br><span class=\"line\">cursor.execute(sql, [<span class=\"number\">2</span>])</span><br></pre></td></tr></table></figure></p>\n<p>如果希望以 tuple 形式表示唯一一个参数, 必须注意加上 逗号, 因为不加逗号就算外面包了括号也会识别为其本身的类型:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">print</span> type((<span class=\"number\">1</span>))</span><br><span class=\"line\">&lt;type <span class=\"string\">'int'</span>&gt;</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">print</span> type((<span class=\"string\">'1'</span>))</span><br><span class=\"line\">&lt;type <span class=\"string\">'str'</span>&gt;</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">print</span> type((<span class=\"number\">1</span>,))</span><br><span class=\"line\">&lt;type <span class=\"string\">'tuple'</span>&gt;</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">print</span> type((<span class=\"string\">'1'</span>,))</span><br><span class=\"line\">&lt;type <span class=\"string\">'tuple'</span>&gt;</span><br></pre></td></tr></table></figure></p>\n<p>其实这个坑是在 MySQL-python 1.2.5 版本中出现的问题; 在 1.2.3 版本中, execute 方法的逻辑是这么写的:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> args <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"keyword\">None</span>:</span><br><span class=\"line\">    query = query % db.literal(args)</span><br></pre></td></tr></table></figure></p>\n<p>只要 args 非空, 就一律把它 to string; 而至于参数怎么转, 转成什么样, 就看参数自己了;<br>这么做确实灵活了, 但是也可能带来一些不确定性, 1.2.5 的版本将参数限定为 list / tuple / dict, 然后对集合内的每个元素再针对性 to string, 一定程度上控制了参数的规范性;<br>&nbsp;</p>\n<h4 id=\"cursor-executemany-方法\"><a href=\"#cursor-executemany-方法\" class=\"headerlink\" title=\"cursor.executemany 方法\"></a><strong>cursor.executemany 方法</strong></h4><p>executemany 方法是 execute 方法的批量化, 这个方法的有效使用范围其实很狭窄, 仅针对 insert 操作有性能提升, 其余操作在性能上均与 execute 无异;<br>下面是该方法的代码:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">del</span> self.messages[:]</span><br><span class=\"line\">db = self._get_db()</span><br><span class=\"line\"><span class=\"keyword\">if</span> <span class=\"keyword\">not</span> args: <span class=\"keyword\">return</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> isinstance(query, unicode):</span><br><span class=\"line\">    query = query.encode(db.unicode_literal.charset)</span><br><span class=\"line\"><span class=\"comment\"># 正则匹配 insert 操作</span></span><br><span class=\"line\">m = insert_values.search(query)</span><br><span class=\"line\"><span class=\"comment\"># 不是 insert 操作, 那就 for 循环挨个执行而已</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> <span class=\"keyword\">not</span> m:</span><br><span class=\"line\">    r = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> a <span class=\"keyword\">in</span> args:</span><br><span class=\"line\">        r = r + self.execute(query, a)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> r</span><br><span class=\"line\">p = m.start(<span class=\"number\">1</span>)</span><br><span class=\"line\">e = m.end(<span class=\"number\">1</span>)</span><br><span class=\"line\">qv = m.group(<span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"comment\"># 下面是针对 insert 的处理</span></span><br><span class=\"line\"><span class=\"keyword\">try</span>:</span><br><span class=\"line\">    q = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> a <span class=\"keyword\">in</span> args:</span><br><span class=\"line\">        <span class=\"keyword\">if</span> isinstance(a, dict):</span><br><span class=\"line\">            q.append(qv % dict((key, db.literal(item))</span><br><span class=\"line\">                               <span class=\"keyword\">for</span> key, item <span class=\"keyword\">in</span> a.iteritems()))</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            q.append(qv % tuple([db.literal(item) <span class=\"keyword\">for</span> item <span class=\"keyword\">in</span> a]))</span><br><span class=\"line\"><span class=\"keyword\">except</span> TypeError, msg:</span><br><span class=\"line\">    <span class=\"keyword\">if</span> msg.args[<span class=\"number\">0</span>] <span class=\"keyword\">in</span> (<span class=\"string\">\"not enough arguments for format string\"</span>,</span><br><span class=\"line\">                       <span class=\"string\">\"not all arguments converted\"</span>):</span><br><span class=\"line\">        self.errorhandler(self, ProgrammingError, msg.args[<span class=\"number\">0</span>])</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        self.errorhandler(self, TypeError, msg)</span><br><span class=\"line\"><span class=\"keyword\">except</span> (SystemExit, KeyboardInterrupt):</span><br><span class=\"line\">    <span class=\"keyword\">raise</span></span><br><span class=\"line\"><span class=\"keyword\">except</span>:</span><br><span class=\"line\">    exc, value, tb = sys.exc_info()</span><br><span class=\"line\">    <span class=\"keyword\">del</span> tb</span><br><span class=\"line\">    self.errorhandler(self, exc, value)</span><br><span class=\"line\"><span class=\"comment\"># 批量化执行, 提高处理性能</span></span><br><span class=\"line\">r = self._query(<span class=\"string\">'\\n'</span>.join([query[:p], <span class=\"string\">',\\n'</span>.join(q), query[e:]]))</span><br><span class=\"line\"><span class=\"keyword\">if</span> <span class=\"keyword\">not</span> self._defer_warnings: self._warning_check()</span><br><span class=\"line\"><span class=\"keyword\">return</span> r</span><br></pre></td></tr></table></figure></p>\n<p>从代码里可以看到, 方法先对传入的 sql 语句作一次匹配, 判断其是否是 insert 操作, 其中 insert_values 是一个 regex, 专门匹配 insert 语句:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">restr = <span class=\"string\">r\"\\svalues\\s*(\\([^()']*(?:(?:(?:\\(.*\\))|'[^\\\\']*(?:\\\\.[^\\\\']*)*')[^()']*)*\\))\"</span></span><br><span class=\"line\">insert_values = re.compile(restr, re.S | re.I | re.X)</span><br></pre></td></tr></table></figure></p>\n<p>针对 insert 语句, 其最后的执行是批量的, 以提高执行效率:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">r = self._query(<span class=\"string\">'\\n'</span>.join([query[:p], <span class=\"string\">',\\n'</span>.join(q), query[e:]]))</span><br></pre></td></tr></table></figure></p>\n<p>但是而其他的语句, 却只能在一个 for 循环里, 挨个执行 execute 方法, 这就没什么优势了;<br>不过这个方法还有一个大坑: 对于 update 和 delete 操作, 使用 executemany 至少不会比 execute 差, 但是对于 query, 它批量执行完一堆 query 操作后去 fetch 结果集, 只能拿到最后执行的 query 的结果, 前面的都被覆盖了; 所以, query 操作不能使用 executemany 方法;<br>&nbsp;<br>在使用方面, executemany 的坑和 execute 是差不多的, 下面是一个例子:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># executemany 传入的 args 可以是 list 也可以是 tuple</span></span><br><span class=\"line\">cur.executemany(<span class=\"string\">'select * from xxx where yyy = %s'</span>, [(<span class=\"number\">1</span>,), (<span class=\"number\">2</span>,)])</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"MySQLdb-的-query-结果集操作\"><a href=\"#MySQLdb-的-query-结果集操作\" class=\"headerlink\" title=\"MySQLdb 的 query 结果集操作\"></a><strong>MySQLdb 的 query 结果集操作</strong></h3><p>MySQLdb 的 query 操作, 主要有以下三种结果集的获取方法:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cursor.execute(<span class=\"string\">\"...sql...\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 获得所有的 tuple 结果集的一个 list</span></span><br><span class=\"line\"><span class=\"meta\">@return list[tuple(elem1, elem2, elem3 ...)]</span></span><br><span class=\"line\">tuple_data_list = cursor.fetchall()</span><br><span class=\"line\"><span class=\"keyword\">for</span> tuple_data <span class=\"keyword\">in</span> tuple_data_list:</span><br><span class=\"line\">    xxx = tuple_data[<span class=\"number\">0</span>]</span><br><span class=\"line\">    yyy = tuple_data[<span class=\"number\">1</span>]</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 采用迭代器的方式, 返回当前游标所对应的 tuple 结果集, 迭代到最后方法返回 None</span></span><br><span class=\"line\"><span class=\"meta\">@return tuple(elem1, elem2, elem3 ...)</span></span><br><span class=\"line\">tuple_data = cursor.fetchone()</span><br><span class=\"line\"><span class=\"keyword\">while</span> tuple_data:</span><br><span class=\"line\">    <span class=\"comment\"># deal with tuple_data</span></span><br><span class=\"line\">    ...</span><br><span class=\"line\">    tuple_data = cursor.fetchone()</span><br><span class=\"line\">    </span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"comment\"># 折中的一种方法, 指定返回 size 个 tuple 结果集 组成一个 list;</span></span><br><span class=\"line\"><span class=\"comment\"># 若 指定 size 小于 总的结果集数量, 则返回全部数据集;</span></span><br><span class=\"line\"><span class=\"meta\">@return list[tuple(elem1, elem2, elem3 ...)]</span></span><br><span class=\"line\">tuple_data_list = cursor.fetchmany(size)</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"MySQLdb-的事务操作\"><a href=\"#MySQLdb-的事务操作\" class=\"headerlink\" title=\"MySQLdb 的事务操作\"></a><strong>MySQLdb 的事务操作</strong></h3><p>MySQLdb 默认不会自动 commit, 所有的增删改操作都必须手动 commit 才能真正写回数据库;<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conn = MySQLdb.connect(host=<span class=\"string\">'10.64.0.11'</span>, user=<span class=\"string\">'xxx'</span>, passwd=<span class=\"string\">'yyy'</span>, db=<span class=\"string\">\"zzz\"</span>, port=<span class=\"number\">3306</span>, charset=<span class=\"string\">\"utf8\"</span>)</span><br><span class=\"line\">SQL = <span class=\"string\">'update xxx set yyy = zzz'</span></span><br><span class=\"line\">cur = conn.cursor()</span><br><span class=\"line\"><span class=\"keyword\">try</span>:</span><br><span class=\"line\">    cur.execute(SQL,(<span class=\"number\">2</span>,))</span><br><span class=\"line\">    <span class=\"comment\"># 手动 commit 提交事务</span></span><br><span class=\"line\">    conn.commit()</span><br><span class=\"line\"><span class=\"keyword\">except</span> Exception, e:</span><br><span class=\"line\">    <span class=\"comment\"># 手动回滚</span></span><br><span class=\"line\">    conn.rollback()</span><br><span class=\"line\"><span class=\"keyword\">finally</span>:</span><br><span class=\"line\">    cur.close()</span><br><span class=\"line\">    conn.close()</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a><strong>参考链接</strong></h3><ul>\n<li><a href=\"https://www.cnblogs.com/franknihao/p/7267182.html\" target=\"_blank\" rel=\"noopener\">MySQLdb的安装与使用</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p><code>MySQLdb</code> 模块是 python 与 mysql 交互的较为底层的接口, 不过它依然是在更为底层的 <code>_mysql</code> 模块之上又作了一层包装;<br><code>_mysql</code> 才是真正的直接面向 mysql 原生 C 接口的简单适配层, 而 <code>MySQLdb</code> 则在 <code>_mysql</code> 之上作了更多的关于类型转换等抽象包装;<br>考虑到 <code>MySQLdb</code> 模块与一些 python ORM 框架的关系, <code>MySQLdb</code> 与 python 的关系可以类比为 jdbc 之于 java;<br>如果是复杂的系统, 我们肯定会选择 ORM 框架, 不过对于一些简单的小工具, 定时小任务等, 本身没什么复杂的数据库操作, 那就用 MySQLdb 最方便了;<br>本文基于 <code>MySQL-python 1.2.5</code> 对 MySQLdb 作一些使用上的总结;</p>\n</blockquote>","more":"<hr>\n<h3 id=\"MySQLdb-的基本操作\"><a href=\"#MySQLdb-的基本操作\" class=\"headerlink\" title=\"MySQLdb 的基本操作\"></a><strong>MySQLdb 的基本操作</strong></h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> MySQLdb</span><br><span class=\"line\"><span class=\"comment\"># 获得 mysql 的一个连接</span></span><br><span class=\"line\">conn = MySQLdb.connect(host=<span class=\"string\">'10.64.0.11'</span>, user=<span class=\"string\">'xxx'</span>, passwd=<span class=\"string\">'yyy'</span>, db=<span class=\"string\">\"zzz\"</span>, port=<span class=\"number\">3306</span>, charset=<span class=\"string\">\"utf8\"</span>)</span><br><span class=\"line\"><span class=\"keyword\">try</span>:</span><br><span class=\"line\">    <span class=\"comment\"># cursor 游标, 是 MySQLdb 中与 mysql 增删改查数据交互的对象</span></span><br><span class=\"line\">    cur = conn.cursor()</span><br><span class=\"line\">    <span class=\"comment\"># 数据库操作</span></span><br><span class=\"line\">    cur.execute(<span class=\"string\">\"...sql...\"</span>)</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    <span class=\"comment\"># 提交事务</span></span><br><span class=\"line\">    conn.commit()</span><br><span class=\"line\"><span class=\"keyword\">except</span> Exception, e:</span><br><span class=\"line\">    <span class=\"comment\"># 回滚</span></span><br><span class=\"line\">    conn.rollback()</span><br><span class=\"line\"><span class=\"keyword\">finally</span>:</span><br><span class=\"line\">    <span class=\"comment\"># 关闭连接, 释放资源</span></span><br><span class=\"line\">    conn.close()</span><br></pre></td></tr></table></figure>\n<p>以上是一个 MySQLdb 使用的完整流程, 下面是具体的使用细节与注意点总结;</p>\n<h3 id=\"MySQLdb-cursor-execute-cursor-executemany-方法\"><a href=\"#MySQLdb-cursor-execute-cursor-executemany-方法\" class=\"headerlink\" title=\"MySQLdb cursor.execute / cursor.executemany 方法\"></a><strong>MySQLdb cursor.execute / cursor.executemany 方法</strong></h3><h4 id=\"cursor-execute-方法\"><a href=\"#cursor-execute-方法\" class=\"headerlink\" title=\"cursor.execute 方法\"></a><strong>cursor.execute 方法</strong></h4><p>MySQLdb 执行数据操纵的关键点就在于 cursor.execute 方法, 所有包括增删改查在内皆是以此方法执行的, 以下是该方法的代码:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">execute</span><span class=\"params\">(self, query, args=None)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">del</span> self.messages[:]</span><br><span class=\"line\">    db = self._get_db()</span><br><span class=\"line\">    <span class=\"keyword\">if</span> isinstance(query, unicode):</span><br><span class=\"line\">        query = query.encode(db.unicode_literal.charset)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> args <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"keyword\">None</span>:</span><br><span class=\"line\">        <span class=\"comment\"># 针对 args 为 dict 的特殊情况处理</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> isinstance(args, dict):</span><br><span class=\"line\">            query = query % dict((key, db.literal(item)) <span class=\"keyword\">for</span> key, item <span class=\"keyword\">in</span> args.iteritems())</span><br><span class=\"line\">        <span class=\"comment\"># 其余的情况: args 为 tuple 或单个 value</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            query = query % tuple([db.literal(item) <span class=\"keyword\">for</span> item <span class=\"keyword\">in</span> args])</span><br><span class=\"line\">    <span class=\"keyword\">try</span>:</span><br><span class=\"line\">        r = <span class=\"keyword\">None</span></span><br><span class=\"line\">        r = self._query(query)</span><br><span class=\"line\">    <span class=\"keyword\">except</span> TypeError, m:</span><br><span class=\"line\">        <span class=\"keyword\">if</span> m.args[<span class=\"number\">0</span>] <span class=\"keyword\">in</span> (<span class=\"string\">\"not enough arguments for format string\"</span>, <span class=\"string\">\"not all arguments converted\"</span>):</span><br><span class=\"line\">            self.messages.append((ProgrammingError, m.args[<span class=\"number\">0</span>]))</span><br><span class=\"line\">            self.errorhandler(self, ProgrammingError, m.args[<span class=\"number\">0</span>])</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            self.messages.append((TypeError, m)) </span><br><span class=\"line\">            self.errorhandler(self, TypeError, m)</span><br><span class=\"line\">    <span class=\"keyword\">except</span> (SystemExit, KeyboardInterrupt):</span><br><span class=\"line\">        <span class=\"keyword\">raise</span></span><br><span class=\"line\">    <span class=\"keyword\">except</span>:</span><br><span class=\"line\">        exc, value, tb = sys.exc_info()</span><br><span class=\"line\">        <span class=\"keyword\">del</span> tb</span><br><span class=\"line\">        self.messages.append((exc, value))</span><br><span class=\"line\">        self.errorhandler(self, exc, value)</span><br><span class=\"line\">    self._executed = query</span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> self._defer_warnings: self._warning_check()</span><br><span class=\"line\">    <span class=\"keyword\">return</span> r</span><br></pre></td></tr></table></figure></p>\n<p>该方法接收一个名为 <code>query</code> 的 sql 字符串, 另外还可选附带参数 <code>args</code>, 所以该方法存在两种主要的用法:<br>1.预先格式化好 sql 字符串, 然后不带参数直接 execute:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sql = <span class=\"string\">\"select * from xxx where update_time = %s\"</span> % datetime.datetime.now().strftime(<span class=\"string\">\"%Y-%m-%d %H:%M:%S\"</span>)</span><br><span class=\"line\">cursor.execute(sql)</span><br></pre></td></tr></table></figure></p>\n<p>这种是保守的方法, 参数处理完全由 python 原生的格式化字符串完成, cursor.execute 方法只管执行 sql 就好;<br>这种方法的优点是省事, 坑少;<br>&nbsp;<br>2.将参数传给 execute 方法的 <code>args</code>, 这种使用方法有几个坑, 需要注意一下;<br>该方法有一段注释, 我单独提了出来, 注释中对 args 参数有如下描述:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    args -- optional sequence or mapping, parameters to use with query.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Note: If args is a sequence, then %s must be used as the</span></span><br><span class=\"line\"><span class=\"string\">    parameter placeholder in the query. If a mapping is used,</span></span><br><span class=\"line\"><span class=\"string\">    %(key)s must be used as the placeholder.</span></span><br><span class=\"line\"><span class=\"string\">\"\"\"</span></span><br></pre></td></tr></table></figure></p>\n<p>(1) 注释中提到的坑, 就是说无论传的参数是一个 list/tuple, 还是 dict, 参数占位符类型都必须是字符串(%s | %(key)s ):<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 不能是 id = %d, 只能是 id = %s</span></span><br><span class=\"line\">sql = <span class=\"string\">'select * from xxx where id  = %s'</span></span><br></pre></td></tr></table></figure></p>\n<p>因为 execute 方法里处理参数时, 会对参数作 <code>db.literal(item)</code> 处理, 将参数首先转为字符串, 这时占位符如果是 %d 等其他类型, 就报错了;</p>\n<p>&nbsp;<br>(2) 注释中另一个隐型的坑, 是这个 <code>args</code> 必须是 list / tuple / dict 中的一个, 哪怕只有一个占位数据, 也必须写成 list 或 tuple 类型:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cursor.execute(sql, (<span class=\"number\">2</span>,))</span><br><span class=\"line\">cursor.execute(sql, [<span class=\"number\">2</span>])</span><br></pre></td></tr></table></figure></p>\n<p>如果希望以 tuple 形式表示唯一一个参数, 必须注意加上 逗号, 因为不加逗号就算外面包了括号也会识别为其本身的类型:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">print</span> type((<span class=\"number\">1</span>))</span><br><span class=\"line\">&lt;type <span class=\"string\">'int'</span>&gt;</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">print</span> type((<span class=\"string\">'1'</span>))</span><br><span class=\"line\">&lt;type <span class=\"string\">'str'</span>&gt;</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">print</span> type((<span class=\"number\">1</span>,))</span><br><span class=\"line\">&lt;type <span class=\"string\">'tuple'</span>&gt;</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">print</span> type((<span class=\"string\">'1'</span>,))</span><br><span class=\"line\">&lt;type <span class=\"string\">'tuple'</span>&gt;</span><br></pre></td></tr></table></figure></p>\n<p>其实这个坑是在 MySQL-python 1.2.5 版本中出现的问题; 在 1.2.3 版本中, execute 方法的逻辑是这么写的:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> args <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"keyword\">None</span>:</span><br><span class=\"line\">    query = query % db.literal(args)</span><br></pre></td></tr></table></figure></p>\n<p>只要 args 非空, 就一律把它 to string; 而至于参数怎么转, 转成什么样, 就看参数自己了;<br>这么做确实灵活了, 但是也可能带来一些不确定性, 1.2.5 的版本将参数限定为 list / tuple / dict, 然后对集合内的每个元素再针对性 to string, 一定程度上控制了参数的规范性;<br>&nbsp;</p>\n<h4 id=\"cursor-executemany-方法\"><a href=\"#cursor-executemany-方法\" class=\"headerlink\" title=\"cursor.executemany 方法\"></a><strong>cursor.executemany 方法</strong></h4><p>executemany 方法是 execute 方法的批量化, 这个方法的有效使用范围其实很狭窄, 仅针对 insert 操作有性能提升, 其余操作在性能上均与 execute 无异;<br>下面是该方法的代码:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">del</span> self.messages[:]</span><br><span class=\"line\">db = self._get_db()</span><br><span class=\"line\"><span class=\"keyword\">if</span> <span class=\"keyword\">not</span> args: <span class=\"keyword\">return</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> isinstance(query, unicode):</span><br><span class=\"line\">    query = query.encode(db.unicode_literal.charset)</span><br><span class=\"line\"><span class=\"comment\"># 正则匹配 insert 操作</span></span><br><span class=\"line\">m = insert_values.search(query)</span><br><span class=\"line\"><span class=\"comment\"># 不是 insert 操作, 那就 for 循环挨个执行而已</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> <span class=\"keyword\">not</span> m:</span><br><span class=\"line\">    r = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> a <span class=\"keyword\">in</span> args:</span><br><span class=\"line\">        r = r + self.execute(query, a)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> r</span><br><span class=\"line\">p = m.start(<span class=\"number\">1</span>)</span><br><span class=\"line\">e = m.end(<span class=\"number\">1</span>)</span><br><span class=\"line\">qv = m.group(<span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"comment\"># 下面是针对 insert 的处理</span></span><br><span class=\"line\"><span class=\"keyword\">try</span>:</span><br><span class=\"line\">    q = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> a <span class=\"keyword\">in</span> args:</span><br><span class=\"line\">        <span class=\"keyword\">if</span> isinstance(a, dict):</span><br><span class=\"line\">            q.append(qv % dict((key, db.literal(item))</span><br><span class=\"line\">                               <span class=\"keyword\">for</span> key, item <span class=\"keyword\">in</span> a.iteritems()))</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            q.append(qv % tuple([db.literal(item) <span class=\"keyword\">for</span> item <span class=\"keyword\">in</span> a]))</span><br><span class=\"line\"><span class=\"keyword\">except</span> TypeError, msg:</span><br><span class=\"line\">    <span class=\"keyword\">if</span> msg.args[<span class=\"number\">0</span>] <span class=\"keyword\">in</span> (<span class=\"string\">\"not enough arguments for format string\"</span>,</span><br><span class=\"line\">                       <span class=\"string\">\"not all arguments converted\"</span>):</span><br><span class=\"line\">        self.errorhandler(self, ProgrammingError, msg.args[<span class=\"number\">0</span>])</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        self.errorhandler(self, TypeError, msg)</span><br><span class=\"line\"><span class=\"keyword\">except</span> (SystemExit, KeyboardInterrupt):</span><br><span class=\"line\">    <span class=\"keyword\">raise</span></span><br><span class=\"line\"><span class=\"keyword\">except</span>:</span><br><span class=\"line\">    exc, value, tb = sys.exc_info()</span><br><span class=\"line\">    <span class=\"keyword\">del</span> tb</span><br><span class=\"line\">    self.errorhandler(self, exc, value)</span><br><span class=\"line\"><span class=\"comment\"># 批量化执行, 提高处理性能</span></span><br><span class=\"line\">r = self._query(<span class=\"string\">'\\n'</span>.join([query[:p], <span class=\"string\">',\\n'</span>.join(q), query[e:]]))</span><br><span class=\"line\"><span class=\"keyword\">if</span> <span class=\"keyword\">not</span> self._defer_warnings: self._warning_check()</span><br><span class=\"line\"><span class=\"keyword\">return</span> r</span><br></pre></td></tr></table></figure></p>\n<p>从代码里可以看到, 方法先对传入的 sql 语句作一次匹配, 判断其是否是 insert 操作, 其中 insert_values 是一个 regex, 专门匹配 insert 语句:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">restr = <span class=\"string\">r\"\\svalues\\s*(\\([^()']*(?:(?:(?:\\(.*\\))|'[^\\\\']*(?:\\\\.[^\\\\']*)*')[^()']*)*\\))\"</span></span><br><span class=\"line\">insert_values = re.compile(restr, re.S | re.I | re.X)</span><br></pre></td></tr></table></figure></p>\n<p>针对 insert 语句, 其最后的执行是批量的, 以提高执行效率:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">r = self._query(<span class=\"string\">'\\n'</span>.join([query[:p], <span class=\"string\">',\\n'</span>.join(q), query[e:]]))</span><br></pre></td></tr></table></figure></p>\n<p>但是而其他的语句, 却只能在一个 for 循环里, 挨个执行 execute 方法, 这就没什么优势了;<br>不过这个方法还有一个大坑: 对于 update 和 delete 操作, 使用 executemany 至少不会比 execute 差, 但是对于 query, 它批量执行完一堆 query 操作后去 fetch 结果集, 只能拿到最后执行的 query 的结果, 前面的都被覆盖了; 所以, query 操作不能使用 executemany 方法;<br>&nbsp;<br>在使用方面, executemany 的坑和 execute 是差不多的, 下面是一个例子:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># executemany 传入的 args 可以是 list 也可以是 tuple</span></span><br><span class=\"line\">cur.executemany(<span class=\"string\">'select * from xxx where yyy = %s'</span>, [(<span class=\"number\">1</span>,), (<span class=\"number\">2</span>,)])</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"MySQLdb-的-query-结果集操作\"><a href=\"#MySQLdb-的-query-结果集操作\" class=\"headerlink\" title=\"MySQLdb 的 query 结果集操作\"></a><strong>MySQLdb 的 query 结果集操作</strong></h3><p>MySQLdb 的 query 操作, 主要有以下三种结果集的获取方法:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cursor.execute(<span class=\"string\">\"...sql...\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 获得所有的 tuple 结果集的一个 list</span></span><br><span class=\"line\"><span class=\"meta\">@return list[tuple(elem1, elem2, elem3 ...)]</span></span><br><span class=\"line\">tuple_data_list = cursor.fetchall()</span><br><span class=\"line\"><span class=\"keyword\">for</span> tuple_data <span class=\"keyword\">in</span> tuple_data_list:</span><br><span class=\"line\">    xxx = tuple_data[<span class=\"number\">0</span>]</span><br><span class=\"line\">    yyy = tuple_data[<span class=\"number\">1</span>]</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 采用迭代器的方式, 返回当前游标所对应的 tuple 结果集, 迭代到最后方法返回 None</span></span><br><span class=\"line\"><span class=\"meta\">@return tuple(elem1, elem2, elem3 ...)</span></span><br><span class=\"line\">tuple_data = cursor.fetchone()</span><br><span class=\"line\"><span class=\"keyword\">while</span> tuple_data:</span><br><span class=\"line\">    <span class=\"comment\"># deal with tuple_data</span></span><br><span class=\"line\">    ...</span><br><span class=\"line\">    tuple_data = cursor.fetchone()</span><br><span class=\"line\">    </span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"comment\"># 折中的一种方法, 指定返回 size 个 tuple 结果集 组成一个 list;</span></span><br><span class=\"line\"><span class=\"comment\"># 若 指定 size 小于 总的结果集数量, 则返回全部数据集;</span></span><br><span class=\"line\"><span class=\"meta\">@return list[tuple(elem1, elem2, elem3 ...)]</span></span><br><span class=\"line\">tuple_data_list = cursor.fetchmany(size)</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"MySQLdb-的事务操作\"><a href=\"#MySQLdb-的事务操作\" class=\"headerlink\" title=\"MySQLdb 的事务操作\"></a><strong>MySQLdb 的事务操作</strong></h3><p>MySQLdb 默认不会自动 commit, 所有的增删改操作都必须手动 commit 才能真正写回数据库;<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conn = MySQLdb.connect(host=<span class=\"string\">'10.64.0.11'</span>, user=<span class=\"string\">'xxx'</span>, passwd=<span class=\"string\">'yyy'</span>, db=<span class=\"string\">\"zzz\"</span>, port=<span class=\"number\">3306</span>, charset=<span class=\"string\">\"utf8\"</span>)</span><br><span class=\"line\">SQL = <span class=\"string\">'update xxx set yyy = zzz'</span></span><br><span class=\"line\">cur = conn.cursor()</span><br><span class=\"line\"><span class=\"keyword\">try</span>:</span><br><span class=\"line\">    cur.execute(SQL,(<span class=\"number\">2</span>,))</span><br><span class=\"line\">    <span class=\"comment\"># 手动 commit 提交事务</span></span><br><span class=\"line\">    conn.commit()</span><br><span class=\"line\"><span class=\"keyword\">except</span> Exception, e:</span><br><span class=\"line\">    <span class=\"comment\"># 手动回滚</span></span><br><span class=\"line\">    conn.rollback()</span><br><span class=\"line\"><span class=\"keyword\">finally</span>:</span><br><span class=\"line\">    cur.close()</span><br><span class=\"line\">    conn.close()</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a><strong>参考链接</strong></h3><ul>\n<li><a href=\"https://www.cnblogs.com/franknihao/p/7267182.html\" target=\"_blank\" rel=\"noopener\">MySQLdb的安装与使用</a></li>\n</ul>"}],"PostAsset":[],"PostCategory":[{"post_id":"cje24mxtr0005j1jxx2uwlh9n","category_id":"cje24mxtn0002j1jxj90g2ae2","_id":"cje24mxuc000qj1jxjvsjuwje"},{"post_id":"cje24mxtr0005j1jxx2uwlh9n","category_id":"cje24mxu4000hj1jxcteeydhf","_id":"cje24mxue000uj1jxbl5k56w9"},{"post_id":"cje24mxte0000j1jx8urpkd78","category_id":"cje24mxtn0002j1jxj90g2ae2","_id":"cje24mxuh000xj1jxijqu7jg0"},{"post_id":"cje24mxte0000j1jx8urpkd78","category_id":"cje24mxu8000mj1jx9414sur9","_id":"cje24mxuj0012j1jx32hh5nkz"},{"post_id":"cje24mxts0006j1jx10eq3zja","category_id":"cje24mxtn0002j1jxj90g2ae2","_id":"cje24mxul0016j1jx37bbp0zq"},{"post_id":"cje24mxts0006j1jx10eq3zja","category_id":"cje24mxud000rj1jxmfvnp7j6","_id":"cje24mxum001aj1jxlw1papf6"},{"post_id":"cje24mxuh0010j1jxxdhv0m8y","category_id":"cje24mxtn0002j1jxj90g2ae2","_id":"cje24mxun001dj1jxfipvjkjs"},{"post_id":"cje24mxuh0010j1jxxdhv0m8y","category_id":"cje24mxud000rj1jxmfvnp7j6","_id":"cje24mxuo001fj1jxp0sxlma9"},{"post_id":"cje24mxtw000aj1jx4sfjjmjr","category_id":"cje24mxtn0002j1jxj90g2ae2","_id":"cje24mxup001hj1jxmc8hsm2y"},{"post_id":"cje24mxtw000aj1jx4sfjjmjr","category_id":"cje24mxud000rj1jxmfvnp7j6","_id":"cje24mxup001kj1jx4m1ynl6m"},{"post_id":"cje24mxtl0001j1jxctoeax8d","category_id":"cje24mxtn0002j1jxj90g2ae2","_id":"cje24mxuq001mj1jxl6uuv7es"},{"post_id":"cje24mxtl0001j1jxctoeax8d","category_id":"cje24mxu4000hj1jxcteeydhf","_id":"cje24mxur001oj1jxqezjskrw"},{"post_id":"cje24mxtz000bj1jxha7xg6kp","category_id":"cje24mxtn0002j1jxj90g2ae2","_id":"cje24mxur001rj1jx4nzkg5mv"},{"post_id":"cje24mxtz000bj1jxha7xg6kp","category_id":"cje24mxun001cj1jxxrff4ihu","_id":"cje24mxus001tj1jxdvnfpni9"},{"post_id":"cje24mxu1000ej1jxyui2n0jf","category_id":"cje24mxup001ij1jx2lrg0b19","_id":"cje24mxut001vj1jxlpicjsnl"},{"post_id":"cje24mxtp0004j1jxrke44zon","category_id":"cje24mxtn0002j1jxj90g2ae2","_id":"cje24mxut001yj1jxfidq84ni"},{"post_id":"cje24mxtp0004j1jxrke44zon","category_id":"cje24mxu4000hj1jxcteeydhf","_id":"cje24mxut0020j1jxpqgjq5se"},{"post_id":"cje24mxu3000gj1jxjfg2tuuf","category_id":"cje24mxtn0002j1jxj90g2ae2","_id":"cje24mxuu0022j1jxziq9s17t"},{"post_id":"cje24mxu3000gj1jxjfg2tuuf","category_id":"cje24mxus001sj1jxnmrmlpf7","_id":"cje24mxuu0024j1jxc9vdd687"},{"post_id":"cje24mxu5000jj1jxeuengj70","category_id":"cje24mxut001xj1jxry2fcarf","_id":"cje24mxuu0026j1jxsp5lw519"},{"post_id":"cje24mxu7000lj1jxynelkfy4","category_id":"cje24mxuu0021j1jxd4xi5a4k","_id":"cje24mxuv002bj1jxahw68j2o"},{"post_id":"cje24mxu9000oj1jxtox3q59e","category_id":"cje24mxtn0002j1jxj90g2ae2","_id":"cje24mxux002gj1jxoisdtzgz"},{"post_id":"cje24mxu9000oj1jxtox3q59e","category_id":"cje24mxuu0027j1jxquydklsv","_id":"cje24mxuy002ij1jxbj1vlwf3"},{"post_id":"cje24mxuj0014j1jx1g8s78go","category_id":"cje24mxuz002oj1jxa4qphb3d","_id":"cje24mxv2002tj1jx3pzh73sh"},{"post_id":"cje24mxub000pj1jxs4giahxo","category_id":"cje24mxuv002cj1jxi1gveuvc","_id":"cje24mxv4002zj1jxvzwwf0s2"},{"post_id":"cje24mxub000pj1jxs4giahxo","category_id":"cje24mxv2002sj1jxrczv87mp","_id":"cje24mxv40032j1jxq6x0svgx"},{"post_id":"cje24mxud000tj1jxk3tcq6uo","category_id":"cje24mxuv002cj1jxi1gveuvc","_id":"cje24mxv50033j1jx3e2kaz0o"},{"post_id":"cje24mxud000tj1jxk3tcq6uo","category_id":"cje24mxv3002wj1jxs18kw17h","_id":"cje24mxv50035j1jx2brxhan8"},{"post_id":"cje24mxuf000wj1jxqu2fniv4","category_id":"cje24mxuy002lj1jxs5y2b1c7","_id":"cje24mxv50036j1jx8pj4mu9u"},{"post_id":"cje24mxuf000wj1jxqu2fniv4","category_id":"cje24mxv40030j1jxmvnh6llc","_id":"cje24mxv50037j1jxitro3lr6"},{"post_id":"cje24mxul0018j1jx6st5alc5","category_id":"cje24mxup001ij1jx2lrg0b19","_id":"cje24mxv60038j1jx7cpqafif"},{"post_id":"cje24mxul0018j1jx6st5alc5","category_id":"cje24mxv50034j1jxx5cq7pxf","_id":"cje24mxv60039j1jxv49dqvo5"}],"PostTag":[{"post_id":"cje24mxte0000j1jx8urpkd78","tag_id":"cje24mxtp0003j1jx2tzk2a8f","_id":"cje24mxtw0009j1jxvrhzc82q"},{"post_id":"cje24mxtl0001j1jxctoeax8d","tag_id":"cje24mxtu0008j1jx55ml2h6z","_id":"cje24mxu2000fj1jxzw3a6r26"},{"post_id":"cje24mxtp0004j1jxrke44zon","tag_id":"cje24mxu1000dj1jxg2kc25mi","_id":"cje24mxu7000kj1jx1ds54zw3"},{"post_id":"cje24mxtr0005j1jxx2uwlh9n","tag_id":"cje24mxu4000ij1jxxz1ypq8u","_id":"cje24mxuf000vj1jx0eeinoba"},{"post_id":"cje24mxtr0005j1jxx2uwlh9n","tag_id":"cje24mxtu0008j1jx55ml2h6z","_id":"cje24mxuh000yj1jxdm4aq981"},{"post_id":"cje24mxts0006j1jx10eq3zja","tag_id":"cje24mxud000sj1jxpttbmjtc","_id":"cje24mxuj0013j1jxv5s3yrwk"},{"post_id":"cje24mxuh0010j1jxxdhv0m8y","tag_id":"cje24mxud000sj1jxpttbmjtc","_id":"cje24mxul0017j1jxxt4l1956"},{"post_id":"cje24mxtw000aj1jx4sfjjmjr","tag_id":"cje24mxud000sj1jxpttbmjtc","_id":"cje24mxun001bj1jxta58p5oh"},{"post_id":"cje24mxtz000bj1jxha7xg6kp","tag_id":"cje24mxum0019j1jxbjl49vlu","_id":"cje24mxuo001gj1jx94n6usrt"},{"post_id":"cje24mxu1000ej1jxyui2n0jf","tag_id":"cje24mxuo001ej1jxou0mss2w","_id":"cje24mxuq001lj1jxjoepsnfj"},{"post_id":"cje24mxu3000gj1jxjfg2tuuf","tag_id":"cje24mxup001jj1jxecue7igc","_id":"cje24mxur001qj1jxm4yk8nx0"},{"post_id":"cje24mxu5000jj1jxeuengj70","tag_id":"cje24mxur001pj1jx5a9o3nm4","_id":"cje24mxut001wj1jxupalur00"},{"post_id":"cje24mxu7000lj1jxynelkfy4","tag_id":"cje24mxus001uj1jx6c9va3xs","_id":"cje24mxuu0025j1jxic7l4i3q"},{"post_id":"cje24mxu7000lj1jxynelkfy4","tag_id":"cje24mxu1000dj1jxg2kc25mi","_id":"cje24mxuv0028j1jxt6en1j8x"},{"post_id":"cje24mxu7000lj1jxynelkfy4","tag_id":"cje24mxut001zj1jx4iu5xtcm","_id":"cje24mxuv002aj1jxf3eq5rxt"},{"post_id":"cje24mxu9000oj1jxtox3q59e","tag_id":"cje24mxuu0023j1jxz302w2kb","_id":"cje24mxuw002dj1jxjhjcr785"},{"post_id":"cje24mxub000pj1jxs4giahxo","tag_id":"cje24mxuv0029j1jxf25sjdvd","_id":"cje24mxux002fj1jxsb1vfi4x"},{"post_id":"cje24mxud000tj1jxk3tcq6uo","tag_id":"cje24mxuw002ej1jx7sxcufud","_id":"cje24mxuy002kj1jxoxibdha5"},{"post_id":"cje24mxuf000wj1jxqu2fniv4","tag_id":"cje24mxuy002jj1jxolaek6m7","_id":"cje24mxuz002nj1jxrs3pus2k"},{"post_id":"cje24mxuj0014j1jx1g8s78go","tag_id":"cje24mxuz002mj1jxmrya0gfq","_id":"cje24mxv3002vj1jxzaf9d010"},{"post_id":"cje24mxuj0014j1jx1g8s78go","tag_id":"cje24mxuz002pj1jx64kj508l","_id":"cje24mxv4002xj1jxza19j7ef"},{"post_id":"cje24mxuj0014j1jx1g8s78go","tag_id":"cje24mxv2002rj1jxgrycpikz","_id":"cje24mxv4002yj1jxylu5ep9c"},{"post_id":"cje24mxul0018j1jx6st5alc5","tag_id":"cje24mxuo001ej1jxou0mss2w","_id":"cje24mxv40031j1jxucg9mgeg"}],"Tag":[{"name":"linux:conf","_id":"cje24mxtp0003j1jx2tzk2a8f"},{"name":"linux:disk","_id":"cje24mxtu0008j1jx55ml2h6z"},{"name":"cheat sheet","_id":"cje24mxu1000dj1jxg2kc25mi"},{"name":"linux:net","_id":"cje24mxu4000ij1jxxz1ypq8u"},{"name":"linux:shell","_id":"cje24mxud000sj1jxpttbmjtc"},{"name":"linux:varlog","_id":"cje24mxum0019j1jxbjl49vlu"},{"name":"python:module","_id":"cje24mxuo001ej1jxou0mss2w"},{"name":"linux:process","_id":"cje24mxup001jj1jxecue7igc"},{"name":"rsync","_id":"cje24mxur001pj1jx5a9o3nm4"},{"name":"saltstack","_id":"cje24mxus001uj1jx6c9va3xs"},{"name":"运维自动化","_id":"cje24mxut001zj1jx4iu5xtcm"},{"name":"linux:text","_id":"cje24mxuu0023j1jxz302w2kb"},{"name":"mvn:plugins","_id":"cje24mxuv0029j1jxf25sjdvd"},{"name":"tools:git","_id":"cje24mxuw002ej1jx7sxcufud"},{"name":"证券:财富先锋","_id":"cje24mxuy002jj1jxolaek6m7"},{"name":"ajax","_id":"cje24mxuz002mj1jxmrya0gfq"},{"name":"jQuery","_id":"cje24mxuz002pj1jx64kj508l"},{"name":"文件上传","_id":"cje24mxv2002rj1jxgrycpikz"}]}}